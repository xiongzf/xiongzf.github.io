{"meta":{"title":"KNOWLEDGE IS POWER","subtitle":null,"description":"来自一个菜鸟的记录","author":"菜鸟先生","url":"http://yoursite.com"},"pages":[{"title":"404","date":"2018-09-12T12:08:32.000Z","updated":"2019-07-22T08:48:19.762Z","comments":true,"path":"/404.html","permalink":"http://yoursite.com//404.html","excerpt":"","text":"&lt;!DOCTYPE html&gt; 404"},{"title":"categories","date":"2018-09-12T06:19:22.000Z","updated":"2019-07-22T08:48:19.752Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2018-09-12T06:19:48.000Z","updated":"2019-07-22T08:48:19.783Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-09-12T06:19:01.000Z","updated":"2019-07-22T08:48:19.774Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Dubbo Admin 新版","slug":"Dubbo-Admin-新版","date":"2019-07-23T05:58:54.000Z","updated":"2019-07-23T07:35:27.124Z","comments":true,"path":"Dubbo-Admin-新版/","link":"","permalink":"http://yoursite.com/Dubbo-Admin-新版/","excerpt":"","text":"dubbo-admin: dubbo的管理控制台，我们通过 dubbo 控制台可以查看 service 的 provider 以及 customer。 dubbo 已经被阿里捐赠给了 Apache。 新版的 dubbo-admin 该如何上手呢？ 上手 dubbo-admin新版的 dubbo-admin 已经被剥离出来了，地址看这里 1、下载 dubbo-admin 代码到本地1git clone https://github.com/apache/dubbo-admin.git 目录结构如下： 后端代码放在：`dubbo-admin-service` 目录下 前端代码放在：`dubbo-admin-ui` 目录下 2、运行后端代码在 ide 里打开后端代码，会自动引入依赖 jar 包。完成后启动服务。本地启动时遇到了 8080 端口被占用的问题。 第一种解决 8080 被占用的方法由于用的 mac，基于 mac 的操作：打开终端，输入如下指令 1lsof -i tcp:8080 可以查到如下结果： 然后输入kill -9 357 即可杀死相关的进程。然后重新启动即可。 第二种如果你不想杀死原进程，你可以修改 dubbo-admin-service 里的配置文件你可以只添加端口，也可以配置 context-path。 3、运行前端代码1、如果你改了后台服务的端口号，记得修改前端代码的配置：图中 1 对应的就是服务端的 url图中 2 对应的是你访问前端的页面的端口号，可以手动修改。 2、打开 终端 进入到 dubbo-admin-ui 目录下，输入如下指令： 1npm install 添加相关的依赖。 3、输入 npm run dev 启动项目 启动完成之后，在浏览器输入对应的地址，即可访问 dubbo-admin。 注意你也可以使用 mvn clean package 指令打包后台服务。当时我使用指令打包的时候，发现在 iTerm 里输入 mvn 无效。本地的 maven 也安装过。原因就是：mac 上装的 iTerm + zsh, 而我的 mvn 环境变量配置在了系统的 ~/.bash_profile 里，所以，需要在 ~/.zshrc 里加上一行source ~/.bash_profile，即可。","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"http://yoursite.com/tags/dubbo/"}]},{"title":"kafka","slug":"kafka","date":"2019-05-10T03:58:42.000Z","updated":"2019-07-30T09:03:18.865Z","comments":true,"path":"kafka/","link":"","permalink":"http://yoursite.com/kafka/","excerpt":"","text":"官网 Kafka is a distributed, partitioned, replicated commit logservice。它提供了类似于 JMS 的特性，但是在实现上完全不同，此外它并不是 JMS 规范的实现。kafka 对消息保存时根据 Topic 进行归类，发送消息者成为 Producer,消息接受者成为 Consumer,此外 kafka 集群有多个 kafka 实例组成，每个实例()成为 broker。无论是 kafka 集群，还是 producer 和 consumer 都依赖于 zookeeper 来保证系统可用性集群保存一些 meta 信息。 Topics/logs一个 Topic 可以认为是一类消息，每个 topic 将被分成多个 partition(区),每个 partition 在存储层面是 append log 文件。任何发布到此 partition 的消息都会被直接追加到 log 文件的尾部，每条消息在文件中的位置称为 offset（偏移量），offset 为一个long 型数字，它是唯一标记一条消息。它唯一的标记一条消息。kafka 并没有提供其他额外的索引机制来存储 offset，因为在 kafka 中几乎不允许对消息进行“随机读写”。 kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.日志文件将会根据broker中的配置要求,保留一定的时间之后删除;比如log文件保留2天,那么两天后,文件会被清除,无论其中的消息是否被消费.kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支. 对于 consumer 而言,它需要保存消费消息的 offset,对于 offset 的保存和使用,有 consumer 来控制;当consumer正常消费消息时, offset 将会”线性”的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将 offset 重置为任意值..(offset将会保存在zookeeper中,参见下文) kafka 集群几乎不需要维护任何 consumer 和 producer 状态信息,这些信息有 zookeeper 保存;因此 producer 和 consumer 的实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响. partitions 的目的有多个.最根本原因是 kafka 基于文件存储.通过分区,可以将日志内容分散到多个上,来避免文件尺寸达到单机磁盘的上限,每个 partiton 都会被当前 server(kafka实例)保存;可以将一个 topic 切分多任意多个 partitions,来消息保存/消费的效率.此外越多的 partitions 意味着可以容纳更多的 consumer,有效提升并发消费的能力. Distribution一个 Topic 的多个 partitions,被分布在 kafka 集群中的多个 server 上;每个 server (kafka 实例)负责 partitions 中消息的读写操作;此外 kafka 还可以配置 partitions 需要备份的个数(replicas),每个 partition 将会被备份到多台机器上,以提高可用性. 基于 replicated 方案,那么就意味着需要对多个备份进行调度;每个 partition 都有一个为 “leader” ; leader 负责所有的读写操作,如果 leader 失效,那么将会有其他 follower 来接管(成为新的leader);follower 只是单调的和 leader 跟进,同步消息即可.由此可见作为 leader 的 server 承载了全部的请求压力,因此从集群的整体考虑,有多少个 partitions 就意味着有多少个 “leader” , kafka 会将 “leader” 均衡的分散在每个实例上,来确保整体的性能稳定. ProducersProducer 将消息发布到指定的 Topic 中,同时 Producer 也能决定将此消息归属于哪个 partition ;比如基于 “round-robin” 方式或者通过其他的一些算法等. Consumers本质上 kafka 只支持 Topic.每个 consumer 属于一个 consumer group;反过来说,每个 group 中可以有多个 consumer.发送到 Topic 的消息,只会被订阅此 Topic 的每个 group 中的一个 consumer 消费. 如果所有的 consumer 都具有相同的 group,这种情况和 queue 模式很像;消息将会在 consumers 之间负载均衡. 如果所有的 consumer 都具有不同的 group,那这就是”发布-订阅”;消息将会广播给所有的消费者. 在 kafka 中,一个 partition 中的消息只会被 group 中的一个 consumer 消费;每个 group 中 consumer 消息消费互相独立;我们可以认为一个 group 是一个”订阅”者,一个 Topic 中的每个 partions,只会被一个”订阅者”中的一个 consumer 消费,不过一个 consumer 可以消费多个 partitions 中的消息. kafka 只能保证一个 partition 中的消息被某个 consumer 消费时,消息是顺序的.事实上,从 Topic 角度来说,消息仍不是有序的. kafka 的原理决定,对于一个 topic,同一个 group 中不能有多于 partitions 个数的 consumer 同时消费,否则将意味着某些 consumer 将无法得到消息. Guarantees 1) 发送到 partitions 中的消息将会按照它接收的顺序追加到日志中 2) 对于消费者而言,它们消费消息的顺序和日志中消息顺序一致. 3) 如果 Topic 的 &quot;replicationfactor&quot; 为 N,那么允许 N-1 个 kafka 实例失效. 使用场景1、Messaging 对于一些常规的消息系统,kafka 是个不错的选择;partitons/replication 和容错,可以使 kafka 具有良好的扩展性和性能优势. 不过到目前为止,我们应该很清楚认识到,kafka 并没有提供 JMS 中的&quot;事务性&quot;&quot;消息传输担保(消息确认机制)&quot;&quot;消息分组&quot;等企业级特性; kafka 只能使用作为&quot;常规&quot;的消息系统,在一定程度上,尚未确保消息的发送与接收绝对可靠(比如,消息重发,消息发送丢失等) 2、Websit activity tracking kafka 可以作为&quot;网站活性跟踪&quot;的最佳工具;可以将网页/用户操作等信息发送到kafka中.并实时监控,或者离线统计分析等 3、Log Aggregation kafka 的特性决定它非常适合作为&quot;日志收集中心&quot;;application 可以将操作日志&quot;批量&quot;&quot;异步&quot;的发送到 kafka 集群中,而不是保存在本地或者 DB 中; kafka 可以批量提交消息/压缩消息等,这对 producer 端而言,几乎感觉不到性能的开支.此时 consumer 端可以使 hadoop 等其他系统化的存储和分析系统. 设计原理kafka 的初衷是希望作为一个统一的信息收集平台,能够实时的收集反馈信息,并需要能够支撑较大的数据量,且具备良好的容错能力. 1、持久性kafka 使用文件存储消息,这就直接决定 kafka 在性能上严重依赖文件系统的本身特性.且无论任何 OS 下,对文件系统本身的优化几乎没有可能.文件缓存/直接内存映射等是常用的手段. 因为 kafka 是对日志文件进行 append 操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker 会将消息暂时 buffer 起来,当消息的个数(或尺寸)达到一定阀值时,再 flush 到磁盘,这样减少了磁盘 IO 调用的次数. 2、性能需要考虑的影响性能点很多,除磁盘 IO 之外,我们还需要考虑网络 IO,这直接关系到 kafka 的吞吐量问题.kafka 并没有提供太多高超的技巧; 对于 producer 端,可以将消息 buffer 起来,当消息的条数达到一定阀值时,批量发送给 broker; 对于 consumer 端也是一样,批量 fetch 多条消息.不过消息量的大小可以通过配置文件来指定. 对于 kafka broker 端,似乎有个 sendfile 系统调用可以潜在的提升网络 IO 的性能:将文件的数据映射到系统内存中,socket 直接读取相应的内存区域即可,而无需进程再次copy 和交换. 其实对于 producer/consumer/broker 三者而言,CPU 的开支应该都不大,因此启用消息压缩机制是一个良好的策略;压缩需要消耗少量的 CPU 资源,不过对于 kafka 而言,网络 IO 更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.kafka 支持 gzip/snappy 等多种压缩方式. 3、生产者负载均衡: producer 将会和 Topic 下所有 partition leader 保持 socket 连接;消息由 producer 直接通过 socket 发送到 broker,中间不会经过任何”路由层”.事实上,消息被路由到哪个 partition 上,有 producer 决定.比如可以采用 “random” “key-hash” “轮询”等,如果一个 topic 中有多个partitions,那么在 producer 端实现”消息均衡分发”是必要的. 其中 partition leader 的位置(host:port)注册在 zookeeper 中,producer 作为 zookeeper client,已经注册了 watch 用来监听 partition leader 的变更事件. 异步发送：将多条消息暂且在客户端 buffer 起来，并将他们批量的发送到 broker，小数据 IO 太多，会拖慢整体的网络延迟，批量延迟发送事实上提升了网络效率。不过这也有一定的隐患，比如说当 producer 失效时，那些尚未发送的消息将会丢失。 4、消费者consumer 端向 broker 发送 “fetch” 请求,并告知其获取消息的 offset;此后 consumer 将会获得一定条数的消息;consumer 端也可以重置 offset 来重新消费消息. 在 JMS 实现中,Topic 模型基于 push 方式,即 broker 将消息推送给 consumer 端.不过在 kafka 中,采用了 pull 方式,即 consumer 在和 broker 建立连接之后,主动去pull(或者说fetch) 消息;这中模式有些优点,首先 consumer 端可以根据自己的消费能力适时的去 fetch 消息并处理,且可以控制消息消费的进度(offset);此外,消费者可以良好的控制消息消费的数量,batch fetch. 其他 JMS 实现,消息消费的位置是有 prodiver 保留,以便避免重复发送消息或者将没有消费成功的消息重发等,同时还要控制消息的状态.这就要求 JMS broker 需要太多额外的工作.在kafka 中,partition 中的消息只有一个 consumer 在消费,且不存在消息状态的控制,也没有复杂的消息确认机制,可见 kafka broker 端是相当轻量级的.当消息被 consumer 接收之后,consumer 可以在本地保存最后消息的 offset,并间歇性的向 zookeeper 注册 offset.由此可见,consumer 也很轻量级. 5、消息传送机制对于 JMS 实现,消息传输担保非常直接:有且只有一次(exactly once).在 kafka 中稍有不同: 123456789101) at most once: 最多一次,这个和 JMS 中&quot;非持久化&quot;消息类似.发送一次,无论成败,将不会重发.2) at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.3) exactly once: 消息只会发送一次.at most once: 消费者 fetch 消息,然后保存 offset,然后处理消息;当 client 保存 offset 之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后&quot;未处理&quot;的消息将不能被 fetch 到,这就是&quot;at most once&quot;.at least once: 消费者 fetch 消息,然后处理消息,然后保存 offset.如果消息处理成功之后,但是在保存 offset 阶段 zookeeper 异常导致保存操作未能执行成功,这就导致接下来再次 fetch 时可能获得上次已经处理过的消息,这就是 &quot;at least once&quot;，原因 offset 没有及时的提交给 zookeeper，zookeeper 恢复正常还是之前 offset 状态.exactly once: kafka 中并没有严格的去实现(基于2阶段提交,事务),我们认为这种策略在kafka 中是没有必要的.通常情况下 &quot;at-least-once&quot; 是我们首选.(相比 at most once 而言,重复接收数据总比丢失数据要好). 6、复制备份kafka 将每个 partition 数据复制到多个 server上,任何一个 partition 有一个 leader 和多个 follower(可以没有);备份的个数可以通过 broker 配置文件来设定. leader 处理所有的 read-write 请求, follower 需要和 leader 保持同步. Follower 和 consumer 一样,消费消息并保存在本地日志中; leader 负责跟踪所有的 follower 状态,如果 follower “落后”太多或者失效, leader 将会把它从 replicas 同步列表中删除.当所有的 follower 都将一条消息保存成功,此消息才被认为是 “committed”,那么此时 consumer 才能消费它.即使只有一个 replicas 实例存活,仍然可以保证消息的正常发送和接收,只要 zookeeper 集群存活即可.(不同于其他分布式存储,比如 hbase 需要”多数派”存活才行) 当 leader 失效时,需在 followers 中选取出新的 leader,可能此时 follower 落后于 leader,因此需要选择一个 “up-to-date” 的 follower.选择 follower 时需要兼顾一个问题,就是新 leader 上所已经承载的 partition leader 的个数,如果一个 server 上有过多的 partition leader,意味着此 server 将承受着更多的 IO 压力.在选举新 leader, 需要考虑到”负载均衡”. 7.日志如果一个 topic 的名称为 “my_topic”,它有 2 个 partitions, 那么日志将会保存在 my_topic_0 和 my_topic_1 两个目录中;日志文件中保存了一序列 “log entries” (日志条目), 每个 log entry 格式为 “4个字节的数字N表示消息的长度” + “N个字节的消息内容”; 每个日志都有一个 offset 来唯一的标记一条消息, offset 的值为 8 个字节的数字,表示此消息在此 partition 中所处的起始位置. 每个 partition 在物理存储层面,有多个 log file 组成(称为segment). segmentfile 的命名为 “最小offset”.kafka. 例如 “00000000000.kafka”; 其中 “最小offset” 表示此 segment 中起始消息的 offset. 其中每个 partiton 中所持有的 segments 列表信息会存储在 zookeeper 中. 当 segment 文件尺寸达到一定阀值时(可以通过配置文件设定,默认1G),将会创建一个新的文件; 当 buffer 中消息的条数达到阀值时将会触发日志信息 flush 到日志文件中, 同时如果 “距离最近一次 flush 的时间差” 达到阀值时, 也会触发 flush 到日志文件. 如果 broker 失效, 极有可能会丢失那些尚未 flush 到文件的消息. 因为意外实现, 仍然会导致 log 文件格式的破坏(文件尾部), 那么就要求当 server 启动是需要检测最后一个 segment 的文件结构是否合法并进行必要的修复. 获取消息时,需要指定 offset 和最大 chunk 尺寸, offset 用来表示消息的起始位置, chunk size 用来表示最大获取消息的总长度(间接的表示消息的条数). 根据 offset, 可以找到此消息所在 segment 文件, 然后根据 segment 的最小 offset 取差值, 得到它在 file 中的相对位置, 直接读取输出即可. 日志文件的删除策略非常简单: 启动一个后台线程定期扫描 log file 列表, 把保存时间超过阀值的文件直接删除(根据文件的创建时间). 为了避免删除文件时仍然有 read 操作(consumer消费), 采取 copy-on-write 方式. 8、分配kafka 使用 zookeeper 来存储一些 meta 信息, 并使用了 zookeeper watch 机制来发现 meta 信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等) 1) Broker node registry: 当一个 kafkabroker 启动后, 首先会向 zookeeper 注册自己的节点信息(临时 znode), 同时当 broker 和 zookeeper 断开连接时, 此 znode 也会被删除. 格式: /broker/ids/[0…N] –&gt;host:port; 其中 [0..N] 表示 broker id, 每个 broker 的配置文件中都需要指定一个数字类型的 id(全局不可重复), znode 的值为此 broker 的 host:port 信息. 2) Broker Topic Registry: 当一个 broker 启动时,会向 zookeeper 注册自己持有的 topic 和 partitions 信息, 仍然是一个临时 znode. 格式: /broker/topics/[topic]/[0…N] 其中 [0..N] 表示 partition 索引号. 3) Consumer and Consumer group: 每个 consumer 被创建时, 会向 zookeeper 注册自己的信息; 此作用主要是为了”负载均衡”. 一个 group 中的多个consumer可以交错的消费一个 topic 的所有partitions; 简而言之, 保证此 topic 的所有 partitions 都能被此 group 所消费, 且消费时为了性能考虑, 让 partition 相对均衡的分散到每个 consumer 上. 4) Consumer id Registry: 每个 consumer 都有一个唯一的 ID(host:uuid, 可以通过配置文件指定, 也可以由系统生成), 此 id 用来标记消费者信息. 格式:/consumers/[group_id]/ids/[consumer_id] 仍然是一个临时的 znode, 此节点的值为 {“topic_name”:#streams…}, 即表示此 consumer 目前所消费的 topic + partitions 列表. 5) Consumer offset Tracking: 用来跟踪每个 consumer 目前所消费的 partition 中最大的 offset. 格式:/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]–&gt;offset_value 此 znode 为持久节点, 可以看出 offset 跟 group_id 有关, 以表明当 group 中一个消费者失效, 其他 consumer 可以继续消费. 6) Partition Owner registry: 用来标记 partition 被哪个 consumer 消费.临时 znode 格式:/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]–&gt;consumer_node_id当consumer启动时,所触发的操作: A) 首先进行 &quot;Consumer id Registry&quot;; B) 然后在 &quot;Consumer id Registry&quot; 节点下注册一个 watch 用来监听当前 group 中其他 consumer 的 &quot;leave&quot; 和 &quot;join&quot;; 只要此 znode path 下节点列表变更, 都会触发此 group 下 consumer 的负载均衡. (比如一个 consumer 失效,那么其他 consumer 接管 partitions). C) 在 &quot;Broker id registry&quot; 节点下, 注册一个 watch 用来监听 broker 的存活情况; 如果 broker 列表变更, 将会触发所有的 groups 下的 consumer 重新 balance. 123451) Producer 端使用 zookeeper 用来&quot;发现&quot; broker 列表,以及和 Topic 下每个 partition leader 建立 socket 连接并发送消息.2) Broker 端使用 zookeeper 用来注册 broker 信息, 已经监测 partitionleader 存活性.3) Consumer 端使用 zookeeper 用来注册 consumer 信息,其中包括 consumer 消费的 partition 列表等, 同时也用来发现 broker 列表, 并和 partition leader 建立 socket 连接, 并获取消息. 主要配置1、Broker 配置 2、Consumer 主要配置 3、Producer 主要配置 以上是关于 kafka 一些基础说明，在其中我们知道如果要 kafka 正常运行，必须配置zookeeper，否则无论是 kafka 集群还是的生存者和消费者都无法正常的工作的，以下是对zookeeper 进行一些简单的介绍： zookeeper集群zookeeper 是一个为分布式应用提供一致性服务的软件，它是开源的 Hadoop 项目的一个子项目，并根据 google 发表的一篇论文来实现的。zookeeper 为分布式系统提供了高效且易于使用的协同服务，它可以为分布式应用提供相当多的服务，诸如统一命名服务，配置管理，状态同步和组服务等。zookeeper 接口简单，我们不必过多地纠结在分布式系统难于处理的同步和一致性问题上，你可以使用 zookeeper 提供的现成 (off-the-shelf) 服务来实现来实现分布式系统额配置管理，组管理，Leader 选举等功能。 zookeeper 集群的安装准备三台服务器 1server1:192.168.0.1, server2:192.168.0.2, server3:192.168.0.3. 1)下载zookeeper 到 http://zookeeper.apache.org/releases.html 去下载最新版本Zookeeper-3.4.5 的安装包 zookeeper-3.4.5.tar.gz. 将文件保存 server1 的~目录下 2)安装zookeeper先在服务器分别执行a-c步骤 a)解压 1tar -zxvf zookeeper-3.4.5.tar.gz 解压完成后在目录~下会发现多出一个目录 zookeeper-3.4.5, 重新命令为 zookeeper b）配置 将 conf/zoo_sample.cfg 拷贝一份命名为 zoo.cfg，也放在 conf 目录下。然后按照如下值修改其中的配置： 12345678910111213141516171819202122232425262728# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/home/wwb/zookeeper /datadataLogDir=/home/wwb/zookeeper/logs# the port at which the clients will connectclientPort=2181## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.#http://zookeeper.apache.org/doc/ ... html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.1=192.168.0.1:3888:4888server.2=192.168.0.2:3888:4888server.3=192.168.0.3:3888:4888 tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。 dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。 clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 initLimit：这个配置项是用来配置 Zookeeper 接受（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5 个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒 syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 2*2000=4 秒 server.A = B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号 注意:dataDir, dataLogDir 中的 wwb 是当前登录用户名，data，logs 目录开始是不存在，需要使用 mkdir 命令创建相应的目录。并且在该目录下创建文件 myid, serve1, server2, server3 该文件内容分别为 1, 2, 3。针对服务器 server2### 针对服务器 server2, server3 可以将 server1 复制到相应的目录，不过需要注意dataDir, dataLogDir 目录, 并且文件 myid 内容分别为 2, 3。 3)依次启动server1，server2, server3 的 zookeeper.1234/home/wwb/zookeeper/bin/zkServer.sh start,出现类似以下内容JMX enabled by defaultUsing config: /home/wwb/zookeeper/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 4)测试 zookeeper 是否正常工作在 server1 上执行以下命令 1234567891011121314151617181920212223242526272829301、/home/wwb/zookeeper/bin/zkCli.sh -server192.168.0.2:2181 //出现类似以下内容JLine support is enabled2013-11-27 19:59:40,560 - INFO [main-SendThread(localhost.localdomain:2181):ClientCnxn$SendThread@736]- Session establishmentcomplete on localhost.localdomain/127.0.0.1:2181, sessionid = 0x1429cdb49220000, negotiatedtimeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: 127.0.0.1:2181(CONNECTED) 0] [root@localhostzookeeper2]// 即代表集群构建成功了,如果出现错误那应该是第三部时没有启动好集群//先利用2、ps aux | grep zookeeper// 查看是否有相应的进程的，没有话，说明集群启动出现问题，可以在每个服务器上使用3、./home/wwb/zookeeper/bin/zkServer.sh stop//再依次使用4、./home/wwb/zookeeper/binzkServer.sh start//这时在执行 4 一般是没有问题，如果还是有问题，那么先 stop 再到 bin 的上级目录执行5、./bin/zkServer.shstart试试。 注意：zookeeper 集群时，zookeeper 要求半数以上的机器可用，zookeeper 才能提供服务。 kafka集群(利用上面server1, server2, server3, 下面以 server1 为实例) 1)下载 kafka0.8(http://kafka.apache.org/downloads.html), 保存到服务器 /home/wwb 目录下 kafka-0.8.0-beta1-src.tgz (kafka_2.8.0-0.8.0-beta1.tgz) 2)解压 1tar -zxvf kafka-0.8.0-beta1-src.tgz 产生文件夹 kafka-0.8.0-beta1-src 更改为 kafka01 3)配置 修改 kafka01/config/.properties, 其中 broker.id, log.dirs, zookeeper.connect 必须根据实际情况进行修改，其他项根据需要自行斟酌。大致如下： 12345678910111213141516171819202122broker.id=1 port=9091 num.network.threads=2 num.io.threads=2 socket.send.buffer.bytes=1048576 socket.receive.buffer.bytes=1048576 socket.request.max.bytes=104857600 log.dir=./logs num.partitions=2 log.flush.interval.messages=10000 log.flush.interval.ms=1000 log.retention.hours=168 #log.retention.bytes=1073741824 log.segment.bytes=536870912 num.replica.fetchers=2 log.cleanup.interval.mins=10 zookeeper.connect=192.168.0.1:2181,192.168.0.2:2182,192.168.0.3:2183 zookeeper.connection.timeout.ms=1000000 kafka.metrics.polling.interval.secs=5 kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter kafka.csv.metrics.dir=/tmp/kafka_metrics kafka.csv.metrics.reporter.enabled=false 4）初始化因为 kafka 用 scala 语言编写，因此运行 kafka 需要首先准备 scala 相关环境。 1234&gt; cd kafka01 &gt; ./sbt update &gt; ./sbt package &gt; ./sbt assembly-package-dependency 在第二个命令时可能需要一定时间，由于要下载更新一些依赖包。所以请大家 耐心点。 5) 启动 123456789101112131415161718kafka01&gt;JMX_PORT=9997 bin/kafka--start.sh config/server.properties &amp; //a) kafka02 操作步骤与 kafka01 雷同，不同的地方如下 修改 kafka02/config/server.propertiesbroker.id=2port=9092##其他配置和kafka-0保持一致##启动kafka02 JMX_PORT=9998 bin/kafka-server-start.shconfig/server.properties &amp; // kafka03 操作步骤与 kafka01 雷同，不同的地方如下 修改 kafka03/config/server.properties broker.id=3port=9093##其他配置和kafka-0保持一致##启动 kafka03JMX_PORT=9999 bin/kafka--start.shconfig/serverconfig/server.properties &amp; 6)创建 topic(包含一个分区，三个副本) 1&gt;bin/kafka-create-topic.sh--zookeeper 192.168.0.1:2181 --replica 3 --partition 1 --topicmy-replicated-topic 7)查看 topic 情况 12&gt;bin/kafka-list-top.sh --zookeeper 192.168.0.1:2181topic: my-replicated-topic partition: 0 leader: 1 replicas: 1,2,0 isr: 1,2,0 8)创建发送者 1234&gt;bin/kafka-console-producer.sh--broker-list 192.168.0.1:9091 --topic my-replicated-topicmy test message1my test message2ctrl c 9)创建消费者 12345&gt;bin/kafka-console-consumer.sh --zookeeper127.0.0.1:2181 --from-beginning --topic my-replicated-topic...my test message1my test message2ctrl c 10) 杀掉 server1 上的 broker 1234 &gt;pkill -9 -f config/.properties``` 11)查看 topic bin/kafka-list-top.sh –zookeeper192.168.0.1:2181 topic: my-replicated-topic partition: 0 leader: 1 replicas: 1,2,0 ##发现 topic 还正常的存在1212）创建消费者，看是否能查询到消息 bin/kafka-console-consumer.sh –zookeeper192.168.0.1:2181 –from-beginning –topic my-replicated-topic…my test message 1my test message 2ctrl c ##说明一切都是正常的。` 补充说明： 1、public Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; createMessageStreams(Map&lt;String, Integer&gt; topicCountMap)，其中该方法的参数Map 的 key 为 topic 名称，value 为 topic 对应的分区数， 譬如说如果在 kafka 中不存在相应的 topic 时，则会创建一个 topic，分区数为 value，如果存在的话，该处的 value 则不起什么作用 2、关于生产者向指定的分区发送数据，通过设置 partitioner.class 的属性来指定向那个分区发送数据， 如果自己指定必须编写相应的程序，默认是 kafka.producer.DefaultPartitioner,分区程序是基于散列的键。 3、在多个消费者读取同一个 topic 的数据，为了保证每个消费者读取数据的唯一性， 必须将这些消费者 group_id 定义为同一个值，这样就构建了一个类似队列的数据结构，如果定义不同，则类似一种广播结构的。 4、在 consumerapi 中，参数到数字部分，类似Map&lt;String,Integer&gt;, numStream, 指的都是在 topic 不存在的时，会创建一个topic，并且分区个数为Integer, numStream, 注意如果数字大于 broker 的配置中 num.partitions 属性，会以 num.partitions 为依据创建分区个数的。 5、producerapi，调用 send 时，如果不存在 topic，也会创建 topic，在该方法中没有提供分区个数的参数，在这里分区个数是由服务端 broker 的配置中 num.partitions 属性决定的。 参考http://kafka.apache.org/https://www.jianshu.com/p/4bf007885116https://www.cnblogs.com/likehua/p/3999538.html","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"}]},{"title":"Redis","slug":"Redis","date":"2019-04-26T06:40:13.000Z","updated":"2019-07-28T08:35:24.290Z","comments":true,"path":"Redis/","link":"","permalink":"http://yoursite.com/Redis/","excerpt":"","text":"Redis (Remote Dictionary Server) 是一个由 SalvatoreSanfilippo 写的 key-value 存储系统。 Redis 是一个开源的使用 ANSI C语言编写、遵守 BSD 协议、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的API。 它通常被称为数据结构服务器，因为值（value）可以是字符串(String), 哈希(Map), 列表(list), 集合(sets) 和有序集合(sorted sets)等类型。 redis 特点Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存。因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的Key-Value DB。 Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单个value 的最大限制是 1GB，不像 memcached 只能保存 1MB 的数据，因此 Redis 可以用来实现很多有用的功能，比方说用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性 能消息队列服务，用他的 Set 可以做高性能的tag系统等等。另外 Redis 也可以对存入的 Key-Value 设置 expire 时间，因此也可以被当作一 个功能加强版的 memcached 来用。 Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。 Redis 支持数据的备份，即 master-slave 模式的数据备份。 redis 的 5 种存储类型string类型 能表达3中类型：字符串、整数和浮点数。根据场景相互间自动转型，并且根据需要选取底层的承载方式 value内部以 int、sds 作为结构存储。int 存放整型数据，sds 存放字节/字符串和浮点型数据 sds内部结构： 用 buf 数组存储字符串的内容，但数组的长度会大于所存储内容的长度。会有一格专门存放”\\0”（C标准库）作为结尾，还有预留多几个空的（即free区域），当 append 字符串的长度小于 free 区域，则 sds 不会重新申请内存，直接使用 free 区域 扩容：当对字符串的操作完成后预期的串长度小于 1M 时，扩容后的 buf 数组大小 = 预期长度*2 + 1；若大于 1M，则 buf 总是会预留出1M的 free 空间 value 对象通常具有两个内存部分：redisObject 部分和 redisObject 的 ptr 指向的 sds 部分。创建 value 对象时，通常需要为 redisObject 和 sds 申请两次内存。单对于短小的字符串，可以把两者连续存放，所以可以一次性把两者的内存一起申请了 list类型 list 类型的 value 对象内部以 linkedList 或 zipList 承载。当 list 的元素个数和单个元素的长度较小时，redis 会采用 zipList 实现以减少内存占用，否则采用linkedList 结构 linkedList 内部实现是双向链表。在 list 中定义了头尾元素指针和列表的长度，是的pop/push 操作、llen 操作的复杂度为O(1)。由于是链表，lindex 类的操作复杂度仍然是O(N) zipList 的内部结构 所有内容被放置在连续的内存中。其中 zlbytes 表示 zipList 的总长度，zltail 指向最末元素，zllen 表示元素个数，entry 表示元素自身内容，zlend 作为zipList 定界符 rpush、rpop、llen，复杂度为O(1);lpush/pop 操作由于涉及全列表元素的移动，复杂度为O(N) map类型 map 又叫 hash。map 内部的 key 和 value 不能再嵌套 map 了，只能是 string 类型：整形、浮点型和字符串 map 主要由 hashTable 和 zipList 两种承载方式实现，对于数据量较小的 map，采用zipList 实现 hashTable 内部结构 主要分为三层，自底向上分别是 dictEntry、dictht、dict dictEntry：管理一个 key-value 对，同时保留同一个桶中相邻元素的指针，一次维护哈希桶的内部连 dictht：维护哈希表的所有桶链 dict：当 dictht 需要扩容/缩容时，用于管理 dictht 的迁移 哈希表的核心结构是dictht，它的table字段维护着hash桶，它是一个数组，每个元素指向桶的第一个元素（dictEntry） set 值的流程：先通过 MurmurHash 算法求出 key 的 hash 值，再对桶的个数取模，得到 key 对应的桶，再进入桶中，遍历全部 entry，判定是否已有相同的 key，如果没有，则将新 key 对应的键值对插入到桶头，并且更新 dictht 的 used 数量，used 表示 hash 表中已经存了多少元素。由于每次插入都要遍历 hash 桶中的全部entry，所以当桶中 entry 很多时，性能会线性下降 扩容：通过负载因子判定是否需要增加桶数。负载因子=哈希表中已有元素/哈希桶数的比值。有两个阈值，小于1一定不扩容；大于5一定扩容。扩容时新的桶数目是现有桶的2n倍 缩容：负载因子的阈值是0.1 扩/缩容通过新建哈希表的方式实现。即扩容时，会并存两个哈希表，一个是源表，一个是目标表。通过将源表的桶逐步迁移到目标表，以数据迁移的方式实现扩容，迁移完成后目标表覆盖源表。迁移过程中，首先访问源表，如果发现 key 对应的源表桶已完成迁移，则重新访问目标表，否则在源表中操作 redis 是单线程处理请求，迁移和访问的请求在相同线程内进行，所以不会存在并发性问题 zipList 内部结构 和 list 的 zipList 实现类似。不同的是，map 对应的 zipList 的 entry 个数总是2的整数倍，奇数存放 key，偶数存放 value zipList 实现下，由哈希遍历变成了链表的顺序遍历，复杂度变成O(N) set类型 set 以 intset 或 hashtable 来存储。hashtable 中的 value 永远为 null，当 set 中只包含整数型的元素时，则采用 intset intset 的内部结构 核心元素是一个字节数组，从小到大有序存放着set的元素 由于元素有序排列，所以 set 的获取操作采用二分查找方式实现，复杂度O(log(N))。进行插入时，首先通过二分查找得到本次插入的位置，再对元素进行扩容，再将预计插入位置之后的所有元素向右移动一个位置，最后插入元素，插入复杂度为O(N)。删除类似 sorted-set类型 类似 map 是一个 key-value 对，但是有序的。value 是一个浮点数，称为 score，内部是按照 score 从小到大排序 内部结构以 zipList 或 skipList+hashTable 来实现 redis 客户端与服务器的交互模式串行的请求/响应模式 每一次请求的发送都依赖于上一次请求的相应结果完全接收，同一个连接的每秒吞吐量低 redis 对单个请求的处理时间通常比局域网的延迟小一个数量级，所以串行模式下，单链接的大部分时间都处于网络等待 双工的请求/响应模式(pipeline) 适用于批量的独立写入操作。即可将请求数据批量发送到服务器，再批量地从服务器连接的字节流中一次读取每个响应数据，减少了网络延迟，所以单连接吞吐量较串行会提高一个数量级 原子化的批量请求/响应模式（事务） 客户端通过和 redis 服务器两阶段的交互做到批量命令原子执行的事务效果：入队操作（即服务器端先将客户端发送过来的连接对象暂存在请求队列中）和执行阶段（依次执行请求队列中的所有请求） 一个连接的请求在执行批量请求的过程中，不会执行其他客户端的请求 redis 的事务不是一致的，没有回滚机制。如果中途失败，则返回错误信息，但已经成功执行的命令不会回滚 事务里面有可能会带有读操作作为条件，由于批量请求只会先入队列，再批量一起执行，所以一般读操作不会跟批量写请求一起执行，这时候就有可能会导致批量写之前和之后读到的数据不一致，这种可以通过乐观锁的可串行化来解决，redis 通过 watch 机制实现乐观锁。具体实现过程看下一题 发布/订阅模式 发布端和订阅者通过 channel 关联 channel 的订阅关系，维护在 reids 实例级别，独立于 redisDB 的 key-value 体系。所有的 channel 都由一个 map 维护，键是 channel 的名字，value 是它所有订阅者 client 的指针链表 脚本化的批量执行（脚本模式）乐观锁流程redis通过watch机制实现乐观锁流程 将本次事务涉及的所有 key 注册为观察模式 执行只读操作 根据只读操作的结果组装写操作命令并发送到服务器端入队 发送原子化的批量执行命令 EXEC 试图执行连接的请求队列中的命令 如果前面注册为观察模式的 key 中有一个货多个，在 EXEC 之前被修改过，则 EXEC 将直接失败，拒绝执行；否则顺序执行请求队列中的所有请求 redis 没有原生的悲观锁或者快照实现，但可通过乐观锁绕过。一旦两次读到的操作不一样，watch 机制触发，拒绝了后续的 EXEC 执行 redis 的网络协议redis 协议位于 TCP 层之上，即客户端和 redis 实例保持双工的连接，交互的都是序列化后的协议数据. redis 处理命令的主要逻辑 redis 服务器对命令的处理都是单线程的，但是 I/O 层面却面向多个客户端并发地提供服务，并发到内部单线程的转化通过多路复用框架来实现 首先从多路服用框架（epoll、evport、kqueue）中 select 出已经 ready 的文件描述符（fileDescriptor） ready 的标准是已有数据到达内核（kernel）、已准备好写入数据 对于上一步已经 ready 的 fd，redis 会分别对每个 fd 上已 ready 的事件进行处理，处理完相同 fd 上的所有事件后，再处理下一个 ready 的 fd。有 3 种事件类型 acceptTcpHandler：连接请求事件 readQueryFromClient：客户端的请求命令事件 sendReplyToClient：将暂存的执行结果写回客户端 对来自客户端的命令执行结束后，接下来处理定时任务（TimeEvent） aeApiPoll 的等待时间取决于定时任务处理（TimeEvent）逻辑 本次主循环完毕，进入下一次主循环的 beforeSleep 逻辑，后者负责处理数据过期、增量持久化的文件写入等任务 redis 的持久化机制redis 主要提供了两种持久化机制：RDB 和 AOF； RDB默认开启，会按照配置的指定时间将内存中的数据快照到磁盘中， 创建一个dump.rdb文件，redis启动时再恢复到内存中。 redis会单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中， 然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件， 然后子进程退出，内存释放。 需要注意的是，每次快照持久化都会将主进程的数据库数据复制一遍，导致内存开销加倍， 若此时内存不足，则会阻塞服务器运行，直到复制结束释放内存； 都会将内存数据完整写入磁盘一次，所以如果数据量大的话，而且写操作频繁，必然会引起大量的磁盘I/O操作， 严重影响性能，并且最后一次持久化后的数据可能会丢失； AOF以日志的形式记录每个写操作（读操作不记录），只需追加文件但不可以改写文件， redis启动时会根据日志从头到尾全部执行一遍以完成数据的恢复工作。包括flushDB也会执行。 主要有两种方式触发：有写操作就写、每秒定时写（也会丢数据）。 因为 AOF 采用追加的方式，所以文件会越来越大，针对这个问题，新增了重写机制，就是当日志文件大到一定程度的时候， 会 fork 出一条新进程来遍历进程内存中的数据，每条记录对应一条 set 语句，写到临时文件中， 然后再替换到旧的日志文件（类似 rdb 的操作方式）。 默认触发是当 aof 文件大小是上次重写后大小的一倍且文件大于 64M 时触发； 当两种方式同时开启时，数据恢复 redis 会优先选择 AOF 恢复。一般情况下，只要使用默认开启的 RDB 即可，因为相对于 AOF，RDB 便于进行数据库备份，并且恢复数据集的速度也要快很多。 开启持久化缓存机制，对性能会有一定的影响，特别是当设置的内存满了的时候，更是下降到几百reqs/s。所以如果只是用来做缓存的话，可以关掉持久化。 redis 内存分析的设计思路主要有3种方式可以实现 keys 命令：获取到所有的 key，再根据 key 获取所有的内容。缺点是如果 key 数量特别多，则会导致 redis 卡住影响业务 aof：通过 aof 文件获取到所有数据。缺点是有一些 redis 实例写入频繁，不适合开启 aof，并且文件可能特别大，传输、解析效率差 rdb：使用 bgsave 获取 rdb 文件，然后解析。缺点是 bgsave 在 fork 子进程时有可能会卡住主进程。当对于其他两种，在低峰期在从节点做 bgsave 获取 rdb 文件，相对安全可靠。 设计思路： 在访问低峰期时根据 redis 获取 rdb 文件 解析 rdb 文件 根据相对应的数据结构及内容，估算内容消耗等 统计并生成报表 开源框架：https://github.com/xueqiu/rdr redis 集群（redis cluster）redis3 以后，节点之间提供了完整的 sharding（分片）、replication（主备感知能力）、failover（故障转移）的特性 配置一致性：每个节点（Node）内部都保存了集群的配置信息，存储在 clusterState 中，通过引入自增的 epoch 变量来使得集群配置在各个节点间保持一致 sharding 数据分片 将所有数据划分为 16384 个分片（slot），每个节点会对应一部分 slot，每个 key 都会根据分布算法映射到 16384 个 slot 中的一个，分布算法为 slotId=crc16(key)%16384 当一个 client 访问的 key 不在对应节点的 slots 中，redis 会返回给 client 一个 moved 命令，告知其正确的路由信息从而重新发起请求。client 会根据每次请求来缓存本地的路由缓存信息，以便下次请求直接能够路由到正确的节点 分片迁移：分片迁移的触发和过程控制由外部系统完成，redis 只提供迁移过程中需要的原语支持。主要包含两种：一种是节点迁移状态设置，即迁移钱标记源、目标节点；另一种是key 迁移的原子化命令 failover 故障转移 故障发现：节点间两两通过 TCP 保持连接，周期性进行 PING、PONG 交互，若对方的 PONG 相应超时未收到，则将其置为 PFAIL 状态，并传播给其他节点 故障确认：当集群中有一半以上的节点对某一个 PFAIL 状态进行了确认，则将起改为 FAIL 状态，确认其故障 slave 选举：当有一个 master 挂掉了，则其 slave 重新竞选出一个新的 master。主要根据各个 slave 最后一次同步 master 信息的时间，越新表示 slave 的数据越新，竞选的优先级越高，就更有可能选中。竞选成功之后将消息传播给其他节点。 集群不可用的情况： 集群中任意 master 挂掉，且当前 master 没有 slave。 集群中超过半数以上 master 挂掉。 其他普通哈希算法和一致性哈希算法对比普通哈希：也称硬哈希，采用简单取模的方式，将机器进行散列，这在 cache 环境不变的情况下能取得让人满意的结果，但是当cache环境动态变化时，这种静态取模的方式显然就不满足单调性的要求（当增加或减少一台机子时，几乎所有的存储内容都要被重新散列到别的缓冲区中）。 一致性哈希：将机器节点和 key 值都按照一样的 hash 算法映射到一个 0~2^32 的圆环上。当有一个写入缓存的请求到来时，计算 Key 值 k 对应的哈希值 Hash(k)，如果该值正好对应之前某个机器节点的 Hash 值，则直接写入该机器节点，如果没有对应的机器节点，则顺时针查找下一个节点，进行写入，如果超过 2^32 还没找到对应节点，则从 0 开始查找（因为是环状结构）。为了更可能的满足平衡性，可以引入虚拟节点，即一个实体节点映射到多个虚拟节点。 参考：http://blog.huanghao.me/?p=14 缓存雪崩，缓存穿透，缓存并发，缓存预热，缓存算法 缓存雪崩：可能是因为数据未加载到缓存中，或者缓存同一时间大面积的失效，从而导致所有请求都去查数据库，导致数据库 CPU 和内存负载过高，甚至宕机。解决思路： 加锁计数（即限制并发的数量，可以用 semphore）或者起一定数量的队列来避免缓存失效时大量请求并发到数据库。但这种方式会降低吞吐量。 分析用户行为，然后失效时间均匀分布。或者在失效时间的基础上再加 1~5 分钟的随机数。 如果是某台缓存服务器宕机，则考虑做主备。 缓存穿透：指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库中查询。解决思路： 如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。 可以给 key 设置一些格式规则，然后查询之前先过滤掉不符合规则的 Key。 缓存并发：如果网站并发访问高，一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况，如果并发确实很大，这也可能造成DB压力过大，还有缓存频繁更新的问题。解决思路： 对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询。 缓存预热：目的就是在系统上线前，将数据加载到缓存中。解决思路： 数据量不大的话，在系统启动的时候直接加载。 自己写个简单的缓存预热程序。 缓存算法： FIFO 算法：First in First out，先进先出。原则：一个数据最先进入缓存中，则应该最早淘汰掉。也就是说，当缓存满的时候，应当把最先进入缓存的数据给淘汰掉。 LFU 算法：Least Frequently Used，最不经常使用算法。 LRU 算法：Least Recently Used，近期最少使用算法。 LRU 和 LFU 的区别。LFU算法是根据在一段时间里数据项被使用的次数选择出最少使用的数据项，即根据使用次数的差异来决定。而LRU是根据使用时间的差异来决定的。 用redis实现分布式锁主要使用的命令： 12345setnx key val。当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。expire key timeout。为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。delete key。删除锁 实现思想： 使用 setnx 加锁，如果返回1，则说明加锁成功，并设置超时时间，避免系统挂了，锁没法释放。在 finally 中 delete 删除锁释放。 如果需要设置超时等待时间，则可以加个 while 循环，在获取不到锁的情况下，进行循环获取锁，超时了则退出。 参考https://segmentfault.com/a/1190000012919740https://www.jianshu.com/p/6023c8fa5937https://blog.csdn.net/wuyangyang555/article/details/82152005https://blog.csdn.net/fly43108622/article/details/52964491https://blog.csdn.net/waeceo/article/details/78701397Redis 相关的问题","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"Zookeeper","slug":"Zookeeper","date":"2019-04-11T02:36:02.000Z","updated":"2019-07-28T08:50:44.630Z","comments":true,"path":"Zookeeper/","link":"","permalink":"http://yoursite.com/Zookeeper/","excerpt":"","text":"Zookeeper 分布式服务框架是 Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 ZooKeeper的由来随着大数据时代的到来，人们张口闭口都是 Hadoop、Hbase 与 Spark 等名词，似乎不懂这些都不好意思打招呼。但实际上，Hadoop 技术栈中略显低调的 ZooKeeper，对于开发人员来说是更加有用的项目。那么 ZooKeeper 是用干什么的呢？ ZooKeeper 是 Apache Hadoop 项目的组成部分，现在已发展成为 Apache 基金会的顶级项目。早期雅虎有许多分布式系统的项目都存在数据不一致的问题，于是雅虎的工程师开发了一套用来解决分布式环境下协调项目，使得开发人员能够专注于业务逻辑上，而不用去解决复杂的分布式问题。 由于雅虎内部有很多用动物命名的项目，例如 Pig、Hive 等，就像一个动物园一样。在ZooKeeper 发布之后，人们吐槽说动物名称的项目太多了，正好 ZooKeeper 是被开发来协调各个不同分布式服务，所以人们就用“动物园管理员”的名称来命名它。 Zookeeper提供了什么简单的说，zookeeper = 文件系统 + 通知机制。 1、 文件系统Zookeeper 维护一个类似文件系统的数据结构： 每个子目录项如 NameService 都被称作为 znode，和文件系统一样，我们能够自由的增加、删除 znode，在一个 znode 下增加、删除子 znode，唯一的不同在于znode是可以存储数据的。 有四种类型的 znode： PERSISTENT-持久化目录节点客户端与 Zookeeper 断开连接后，该节点依旧存在 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点客户端与 Zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号 EPHEMERAL-临时目录节点客户端与 Zookeeper 断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点客户端与 Zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号 2、 通知机制客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，Zookeeper 会通知客户端。 就这么简单，下面我们看看能做点什么呢？ Zookeeper 能解决哪些问题？分布式环境下，开发人员面临着以下的困难和挑战： 节点故障。分布式环境中的每个节点都面临着崩溃的风险。根据分布式理论，随着运行时间和节点数量的增加，节点故障几乎是不可避免的。 通信异常。单机环境下调用另外一个程序，结果只有成功或者失败两种情况。但在分布式环境下调用别的程序，可能由于消息在网络中丢失，也有可能被调用方在执行中崩溃。总之，调用方无法等到结果的返回，调用发生超时。在这种情况下，被调用方的执行结果可能成功，也可能失败，调用方无法感知。 网络分区。由于采用网络传输信息，通信的延迟远大于单机环境。当通信延时不断增大，会出现部分节点之间可以通信，部分节点之间无法通信的情况，导致网络分区（脑裂）的出现。网络分区对分布式环境下的数据一致性有很大的影响。 由于诸多问题，分布式环境下的服务的开发比单机环境下会更加困难。为了保证服务的可用性，开发人员不可避免的要解决以上问题。如果每一个项目都要去解决这些底层问题，必须去单独开发一套分布式协调的程序。不但造轮子的过程会十分低效而繁琐，往往会有很多 BUG 隐藏其中。ZooKeeper 就是为了解决上述问题而被开发，使得开发人员可以聚焦于业务逻辑。 ZooKeeper 是一个开源的分布式协调框架，是 Google 的 Chubby 项目的开源实现。ZooKeeper 提供了一套用来构建分布式系统的原语集合，解决了各种本需开发人员解决的分布式难题，包装成简单易用的接口，极大的简化了分布式环境下的开发工作。 Zookeeper 主要作用1、 命名服务这个似乎最简单，在 zookeeper 的文件系统里创建一个目录，即有唯一的 path。在我们使用 tborg 无法确定上游程序的部署机器时即可与下游程序约定好 path，通过 path 即能互相探索发现，不见不散了。 2、 配置管理程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到 zookeeper 上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。 3、 集群管理所谓集群管理无在乎两点：是否有机器退出和加入、选举 master。 对于第一点，所有机器约定在父目录 GroupMembers 下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper 的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。新机器加入 也是类似，所有机器收到通知：新兄弟目录加入，highcount 又有了。 对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为 master 就好。 4、 分布式锁有了 zookeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 对于第一类，我们将 zookeeper 上的一个 znode 看作是一把锁，通过 createznode 的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。厕所有言：来也冲冲，去也冲冲，用完删除掉自己创建的 distribute_lock 节点就释放出锁。 对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选 master 一样，编号最小的获得锁，用完删除，依次方便。 5、队列管理两种类型的队列： 1、 同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 2、队列按照 FIFO 方式进行入队和出队操作。 第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。 终于了解完我们能用 zookeeper 做什么了，可是作为一个程序员，我们总是想狂热了解 zookeeper 是如何做到这一点的，单点维护一个文件系统没有什么难度，可是如果是一个集群维护一个文件系统保持数据的一致性就非常困难了。 分布式与数据复制Zookeeper 作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处： 1、 容错 一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 2、提高系统的扩展能力 把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 3、提高性能 让客户端本地访问就近的节点，提高用户访问速度。 从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 1、写主(WriteMaster) 对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； 2、写任意(Write Any) 对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。 对 zookeeper 来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这 也是它建立 observer 的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。 我们关注的重点还是在如何保证数据在集群所有机器的一致性，这就涉及到 paxos 算法。 数据一致性与paxos算法据说 Paxos 算法的难理解与算法的知名度一样令人敬仰，所以我们先看如何保持数据的一致性，这里有个原则就是： 在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。 Paxos 算法解决的什么问题呢，解决的就是保证每个节点执行相同的操作序列。好吧，这还不简单，master 维护一个全局写队列，所有写操作都必须 放入这个队列编号，那么无论我们写多少个节点，只要写操作是按编号来的，就能保证一致性。没错，就是这样，可是如果 master 挂了呢。 Paxos 算法通过投票来对写操作进行全局编号，同一时刻，只有一个写操作被批准，同时并发的写操作要去争取选票，只有获得过半数选票的写操作才会被 批准（所以永远只会有一个写操作得到批准），其他的写操作竞争失败只好再发起一轮投票，就这样，在日复一日年复一年的投票中，所有写操作都被严格编号排 序。编号严格递增，当一个节点接受了一个编号为 100 的写操作，之后又接受到编号为 99 的写操作（因为网络延迟等很多不可预见原因），它马上能意识到自己 数据不一致了，自动停止对外服务并重启同步过程。任何一个节点挂掉都不会影响整个集群的数据一致性（总2n+1台，除非挂掉大于n台）。 总结Zookeeper 作为 Hadoop 项目中的一个子项目，是 Hadoop 集群管理的一个必不可少的模块，它主要用来控制集群中的数据，如它管理 Hadoop 集群中的 NameNode，还有 Hbase 中 Master Election、Server 之间状态同步等。 Zookeeper的基本概念角色Zookeeper 中的角色主要有以下三类，如下表所示：系统模型如图所示： 设计目的 最终一致性：client 不论连接到哪个 Server，展示给它都是同一个视图，这是zookeeper 最重要的性能。 可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。 实时性：Zookeeper 保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper 不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用 sync()接口。 等待无关（wait-free）：慢的或者失效的 client 不得干预快速的 client 的请求，使得每个 client 都能有效的等待。 原子性：更新只能成功或者失败，没有中间状态。 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有 Server 上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。 Zookeeper 工作原理ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和 命名服务等。Zookeeper 是 hadoop 的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调 机制不适合在某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。Zookeeper 的目的就在于此。 Zookeeper 的核心是原子广播，这个机制保证了各个 Server 之间的同步。实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式，它们分 别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。 为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了 zxid。实现中 zxid 是一个64位的数字，它高32位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个 新的 epoch，标识当前属于那个 leader 的统治时期。低32位用于递增计数。 每个 Server 在工作过程中有三种状态： LOOKING：当前 Server 不知道 leader 是谁，正在搜寻 LEADING：当前 Server 即为选举出来的 leader FOLLOWING：leader 已经选举出来，当前 Server 与之同步 选主流程 当 leader 崩溃或者 leader 失去大多数的 follower，这时候 zk 进入恢复模式，恢复模式需要重新选举出一个新的 leader，让所有的 Server 都恢复到一个正确的状态。Zk 的选举算法有两种：一种是基于 basic paxos 实现的，另外一种是基于 fast paxos 算法实现的。系统默认的选举算法为 fast paxos。先介绍 basic paxos 流程： 选举线程由当前 Server 发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的 Server； 选举线程首先向所有 Server 发起一次询问(包括自己)； 选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中； 收到所有 Server 回复以后，就计算出 zxid 最大的那个 Server，并将这个 Server 相关信息设置成下一次要投票的 Server； 线程将当前 zxid 最大的 Server 设置为当前 Server 要推荐的 Leader，如果此时获胜的 Server获得 n/2 + 1 的 Server 票数， 设置当前推荐的 leader 为获胜的Server，将根据获胜的 Server 相关信息设置自己的状态，否则，继续这个过程，直到leader 被选举出来。 通过流程分析我们可以得出：要使 Leader 获得多数 Server 的支持，则 Server 总数必须是奇数 2n+1，且存活的 Server 的数目不得少于 n+1. 每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 Server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示： fast paxos 流程是在选举过程中，某 Server 首先向所有 Server 提议自己要成为leader，当其它 Server 收到提议以后，解决 epoch 和 zxid 的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出 Leader。其流程图如下所示： 同步流程选完 leader 以后，zk 就进入状态同步过程。 1. leader 等待 server 连接； 2. Follower 连接 leader，将最大的 zxid 发送给 leader； 3. Leader 根据 follower 的 zxid 确定同步点； 4. 完成同步后通知 follower 已经成为 uptodate 状态； 5. Follower收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了。 工作流程Leader 工作流程Leader主要有三个功能： 1. 恢复数据； 2. 维持与 Learner 的心跳，接收 Learner 请求并判断 Learner 的请求消息类型； 3. Learner 的消息类型主要有 PING 消息、REQUEST 消息、ACK 消息、REVALIDATE 消息，根据不同的消息类型，进行不同的处理。 PING 消息是指 Learner 的心跳信息；REQUEST 消息是 Follower 发送的提议信息，包括写请求及同步请求；ACK 消息是 Follower 的对提议的回复，超过半数的 Follower 通过，则 commit 该提议；REVALIDATE 消息是用来延长 SESSION 有效时间。Leader 的工作流程简图如下所示，在实际实现中，流程要比下图复杂得多，启动了三个线程来实现功能。 Follower 工作流程Follower 主要有四个功能： 1. 向 Leader 发送请求（PING 消息、REQUEST 消息、ACK 消息、REVALIDATE 消息）； 2. 接收 Leader 消息并进行处理； 3. 接收 Client 的请求，如果为写请求，发送给 Leader 进行投票； 4. 返回 Client 结果。 Follower 的消息循环处理如下几种来自 Leader 的消息： 1. PING消息： 心跳消息； 2. PROPOSAL消息：Leader 发起的提案，要求 Follower 投票； 3. COMMIT消息：服务器端最新一次提案的信息； 4. UPTODATE消息：表明同步完成； 5. REVALIDATE消息：根据 Leader 的 REVALIDATE 结果，关闭待 revalidate 的 session 还是允许其接受消息； 6. SYNC消息：返回 SYNC 结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。 Follower 的工作流程简图如下所示，在实际实现中，Follower 是通过5个线程来实现功能的。 对于 observer 的流程不再叙述，observer 流程和 Follower 的唯一不同的地方就是observer 不会参加 leader 发起的投票。 ZooKeeper 典型使用场景一览ZooKeeper 是一个高可用的分布式数据管理与系统协调框架。基于对 Paxos 算法的实现，使该框架保证了分布式环境中数据的强一致性，也正是基 于这样的特性，使得 zookeeper 能够应用于很多场景。网上对 zk 的使用场景也有不少介绍，本文将结合作者身边的项目例子，系统的对 zk 的使用场景进 行归类介绍。 值得注意的是，zk 并不是生来就为这些场景设计，都是后来众多开发者根据框架的特性，摸索出来的典型使用方法。因此，也非常欢迎你分享你在 ZK 使用上的奇技淫巧。 场景类别 典型场景描述（ZK特性，使用方法） 应用中的具体使用 数据发布与订阅 发布与订阅即所谓的配置管理，顾名思义就是将数据发布到 zk 节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，地址列表等就非常适合使用。 1. 索引信息和集群中机器节点状态存放在 zk 的一些指定节点，供各个客户端订阅使用。2. 系统日志（经过处理后的）存储，这些日志通常2-3天后被清除。3. 应用中用到的一些配置信息集中管理，在应用启动的时候主动来获取一次，并且在节点上注册一个 Watcher，以后每次配置有更新，实时通知到应用，获取最新配置信息。4. 业务逻辑中需要用到的一些全局变量，比如一些消息中间件的消息队列通常有个 offset，这个 offset 存放在 zk 上，这样集群中每个发送者都能知道当前的发送进度。5. 系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息。以前通常是暴露出接口，例如 JMX 接口，有了 zk 后，只要将这些信息存放到 zk 节点上即可。 Name Service 这个主要是作为分布式命名服务，通过调用 zk 的 create node api，能够很容易创建一个全局唯一的 path，这个 path 就可以作为一个名称。 分布通知/协调 ZooKeeper 中特有 watcher 注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对 ZK 上同一个 znode 进行注册，监听 znode 的变化（包括znode本身内容及子节点的），其中一个系统 update 了 znode ，那么另一个系统能 够收到通知，并作出相应处理。 1. 另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过 zk 上某个节点关联，大大减少系统耦合。2. 另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改 了 ZK 上某些节点的状态，而zk就把这些变化通知给他们注册 Watcher 的客户端，即推送系统，于是，作出相应的推送任务。3. 另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到 zk 来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。总之，使用 zookeeper 来进行分布式通知和协调能够大大降低系统之间的耦合。 分布式锁 分布式锁，这个主要得益于 ZooKeeper 为我们保证了数据的强一致性，即用户只要完全相信每时每刻，zk 集群中任意节点（一个 zk server）上的相同 znode 的数据是一定是相同的。锁服务可以分为两类，一个是保持独占，另一个是控制时序。所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把 zk 上的一个 znode 看作是一把锁，通过 create znode 的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指 定）。Zk 的父节点（/distribute_lock）维持一份 sequence ,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。 集群管理 1. 集群机器监控：这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群 机器是否存活。过去的做法通常是：监控系统通过某种手段（比如 ping ）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：1. 集群中机器有变动的时候，牵连修改的东西比较多。2. 有一定的延时。利用 ZooKeeper 有两个特性，就可以实时另一种集群机器存活性监控系统：a. 客户端在节点 x 上注册一个 Watcher，那么如果 x 的子节点变化了，会通知该客户端。b. 创建 EPHEMERAL 类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。例如，监控系统在 /clusterServers 节点上注册一个 Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。2. Master 选举则是 zookeeper 中最为经典的使用场景了。在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行， 其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个 master 选举便是这种场景下的碰到的主要问题。利用 ZooKeeper 的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。另外，这种场景演化一下，就是动态 Master 选举。这就要用到 EPHEMERAL_SEQUENTIAL 类型节点的特性了。上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终 在 ZK 上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 , /currentMaster/{sessionId}-2 , /currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为 Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是 Master 了。 1. 在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的 Master 来进行全量索引的生成， 然后同步到集群中其它机器。2. 另外，Master 选举的容灾措施是，可以随时进行手动指定 master，就是说应用在zk在无法获取 master 信息时，可以通过比如 http 方式，向 一个地方获取 master。 分布式队列 队列方面，我目前感觉有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第二种先进先出队列，和分布式锁服务中的控制时序场景基本原理一致，这里不再赘述。第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行 了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。 参考https://blog.csdn.net/qq_25424545/article/details/81437080https://blog.csdn.net/lingbo229/article/details/81052078","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://yoursite.com/tags/zookeeper/"}]},{"title":"dubbo","slug":"dubbo","date":"2019-03-28T04:05:46.000Z","updated":"2019-07-28T08:50:09.371Z","comments":true,"path":"dubbo/","link":"","permalink":"http://yoursite.com/dubbo/","excerpt":"","text":"官网 Dubbo 是 Alibaba 开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo 采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。关于注册中心、协议支持、服务监控等内容，详见后面描述。 总体架构Dubbo 框架设计一共划分了 10 个层，而最上面的 Service 层是留给实际想要使用 Dubbo 开发分布式服务的开发者实现业务逻辑的接口层。图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口， 位于中轴线上的为双方都用到的接口。下面，结合 Dubbo 官方文档，我们分别理解一下框架分层架构中，各个层次的设计要点： 服务接口层（Service）：该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。 配置层（Config）：对外配置接口，以 ServiceConfig 和 ReferenceConfig 为中心，可以直接 new 配置类，也可以通过spring解析配置生成配置类。 服务代理层（Proxy）：服务接口透明代理，生成服务的客户端 Stub 和服务器端Skeleton，以 ServiceProxy 为中心，扩展接口为 ProxyFactory。 服务注册层（Registry）：封装服务地址的注册与发现，以服务URL为中心，扩展接口为 RegistryFactory、Registry 和 RegistryService。可能没有服务注册中心，此时服务提供方直接暴露服务。 集群层（Cluster）：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster、Directory、Router 和 LoadBalance。将多个服务提供方组合为一个服务提供方，实现对服务消费方来透明，只需要与一个服务提供方进行交互。 监控层（Monitor）：RPC调用次数和调用时间监控，以 Statistics 为中心，扩展接口为MonitorFactory、Monitor 和 MonitorService。 远程调用层（Protocol）：封将RPC调用，以 Invocation 和 Result 为中心，扩展接口为 Protocol、Invoker 和 Exporter。Protocol 是服务域，它是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。Invoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 信息交换层（Exchange）：封装请求响应模式，同步转异步，以 Request 和 Response 为中心，扩展接口为 Exchanger、ExchangeChannel、ExchangeClient 和 ExchangeServer。 网络传输层（Transport）：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel、Transporter、Client、Server和Codec。 数据序列化层（Serialize）：可复用的一些工具，扩展接口为 Serialization、 ObjectInput、ObjectOutput 和 ThreadPool。 从上图可以看出，Dubbo 对于服务提供方和服务消费方，从框架的 10 层中分别提供了各自需要关心和扩展的接口，构建整个服务生态系统（服务提供方和服务消费方本身就是一个以服务为中心的）。根据官方提供的，对于上述各层之间关系的描述，如下所示： 在 RPC 中，Protocol 是核心层，也就是只要有 Protocol + Invoker + Exporter 就可以完成非透明的 RPC 调用，然后在 Invoker 的主过程上 Filter 拦截点。 图中的 Consumer 和 Provider 是抽象概念，只是想让看图者更直观的了解哪些类分属于客户端与服务器端，不用 Client 和 Server 的原因是 Dubbo 在很多场景下都使用Provider、Consumer、Registry、Monitor 划分逻辑拓普节点，保持统一概念。 而 Cluster 是外围概念，所以 Cluster 的目的是将多个 Invoker 伪装成一个 Invoker，这样其它人只要关注 Protocol 层 Invoker 即可，加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，因为只有一个提供者时，是不需要 Cluster 的。 Proxy 层封装了所有接口的透明化代理，而在其它层都以 Invoker 为中心，只有到了暴露给用户使用时，才用 Proxy 将 Invoker 转成接口，或将接口实现转成 Invoker，也就是去掉 Proxy 层 RPC 是可以 Run 的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。 而 Remoting 实现是 Dubbo 协议的实现，如果你选择 RMI 协议，整个 Remoting 都不会用上，Remoting 内部再划为 Transport 传输层和 Exchange 信息交换层，Transport 层只负责单向消息传输，是对 Mina、Netty、Grizzly 的抽象，它也可以扩展 UDP 传输，而 Exchange 层是在传输层之上封装了 Request-Response 语义。 Registry 和 Monitor 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在一起。 从上面的架构图中，我们可以了解到，Dubbo 作为一个分布式服务框架，主要具有如下几个核心的要点： 服务定义 服务是围绕服务提供方和服务消费方的，服务提供方实现服务，而服务消费方调用服务。 服务注册 对于服务提供方，它需要发布服务，而且由于应用系统的复杂性，服务的数量、类型也不断膨胀； 对于服务消费方，它最关心如何获取到它所需要的服务，而面对复杂的应用系统，需要管理大量的服务调用。 而且，对于服务提供方和服务消费方来说，他们还有可能兼具这两种角色，即既需要提供服务，有需要消费服务。 通过将服务统一管理起来，可以有效地优化内部应用对服务发布/使用的流程和管理。服务注册中心可以通过特定协议来完成服务对外的统一。Dubbo 提供的注册中心有如下几种类型可供选择： 1234Multicast 注册中心Zookeeper 注册中心Redis 注册中心Simple 注册中心 服务监控 无论是服务提供方，还是服务消费方，他们都需要对服务调用的实际状态进行有效的监控，从而改进服务质量。 远程通信与信息交换 远程通信需要指定通信双方所约定的协议，在保证通信双方理解协议语义的基础上，还要保证高效、稳定的消息传输。 Dubbo继承了当前主流的网络通信框架，主要包括如下几个： 123MinaNettyGrizzly 服务调用下面从Dubbo官网直接拿来，看一下基于RPC层，服务提供方和服务消费方之间的调用关系，如图所示： 上图中，紫色的表示与业务有交互，淡蓝色的表示只对 Dubbo 内部交互。上述图所描述的调用流程如下： 123服务提供方发布服务到服务注册中心；服务消费方从服务注册中心订阅服务；服务消费方调用已经注册的可用服务 注册/注销服务 服务的注册与注销，是对服务提供方角色而言，那么注册服务与注销服务的时序图 如图所示： 服务订阅/取消 为了满足应用系统的需求，服务消费方的可能需要从服务注册中心订阅指定的有服务提供方发布的服务，在得到通知可以使用服务时，就可以直接调用服务。反过来，如果不需要某一个服务了，可以取消该服务。 下面看一下对应的时序图,如图所示： 协议支持Dubbo 支持多种协议，如下所示： 12345678Dubbo 协议Hessian 协议HTTP 协议RMI 协议WebService 协议Thrift 协议Memcached 协议Redis 协议 在通信过程中，不同的服务等级一般对应着不同的服务质量，那么选择合适的协议便是一件非常重要的事情。你可以根据你应用的创建来选择。例如，使用 RMI 协议，一般会受到防火墙的限制，所以对于外部与内部进行通信的场景，就不要使用RMI协议，而是基于 HTTP 协议或者 Hessian 协议。 参考补充Dubbo 以包结构来组织各个模块，各个模块及其关系，如图所示：可以通过 Dubbo 的代码（使用 Maven 管理）组织，与上面的模块进行比较。简单说明各个包的情况： dubbo-common 公共逻辑模块，包括 Util 类和通用模型。 dubbo-remoting 远程通讯模块，相当于 Dubbo 协议的实现，如果 RPC 用 RMI 协议则不需要使用此包。 dubbo-rpc 远程调用模块，抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。 dubbo-cluster 集群模块，将多个服务提供方伪装为一个提供方，包括：负载均衡、容错、路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发。 dubbo-registry 注册中心模块，基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。 dubbo-monitor 监控模块，统计服务调用次数，调用时间的，调用链跟踪的服务。 dubbo-config 配置模块，是 Dubbo 对外的 API，用户通过 Config 使用 Dubbo，隐藏Dubbo 所有细节。 dubbo-container 容器模块，是一个 Standalone 的容器，以简单的 Main 加载 Spring 启动，因为服务通常不需要 Tomcat/JBoss 等 Web 容器的特性，没必要用 Web 容器去加载服务。 服务发布过程中做了哪些事 一共有6种颜色,我一次从上到下说一下这发布过程的一些动作 123456暴露本地服务暴露远程服务启动 netty连接 zookeeper到 zookeeper 注册监听 zookeeper 参考https://www.jianshu.com/p/60a9263f2ee2 https://www.cnblogs.com/barrywxx/p/8528849.html Dubbo 面试题 Dubbo+zookeeper面试题补充 必看","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"http://yoursite.com/tags/dubbo/"}]},{"title":"源码分析","slug":"源码分析","date":"2018-12-02T03:59:14.000Z","updated":"2019-07-24T07:59:15.673Z","comments":true,"path":"源码分析/","link":"","permalink":"http://yoursite.com/源码分析/","excerpt":"","text":"AFNetWorking AFNetworking 官网AFNetworking 1AFNetworking 2AFNetworking 3 AlamofireAlamofire 官网Alamofire 1 SDWebImage SDWebImage 官网SDWebImage4.0SDWebImage 4.x版本源码分析 KingfisherKingfisher 官网Kingfisher源码阅读 SnapKitSnapKit 官网SnapKit 源码解读","categories":[{"name":"iOS 源码分析","slug":"iOS-源码分析","permalink":"http://yoursite.com/categories/iOS-源码分析/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"http://yoursite.com/tags/源码分析/"},{"name":"iOS 深入学习","slug":"iOS-深入学习","permalink":"http://yoursite.com/tags/iOS-深入学习/"}]},{"title":"Shiro","slug":"Shiro","date":"2018-10-27T06:51:52.000Z","updated":"2019-07-28T08:47:17.401Z","comments":true,"path":"Shiro/","link":"","permalink":"http://yoursite.com/Shiro/","excerpt":"","text":"Apache Shiro 是一个强大且易用的 Java 安全框架,执行身份验证、授权、密码和会话管理。使用 Shiro 的易于理解的 API,您可以快速、轻松地获得任何应用程序,从最小的移动应用程序到最大的网络和企业应用程序。 主要功能三个核心组件：Subject, SecurityManager 和 Realms。 Subject：即“当前操作用户”。但是，在 Shiro 中，Subject 这一概念并不仅仅指人，也可以是第三方进程、后台帐户（Daemon Account）或其他类似事物。它仅仅意味着“当前跟软件交互的东西”。Subject 代表了当前用户的安全操作，SecurityManager 则管理所有用户的安全操作。 SecurityManager：它是 Shiro 框架的核心，典型的 Facade 模式，Shiro 通过SecurityManager 来管理内部组件实例，并通过它来提供安全管理的各种服务。 Realm： Realm 充当了 Shiro 与应用安全数据间的“桥梁”或者“连接器”。也就是说，当对用户执行认证（登录）和授权（访问控制）验证时，Shiro 会从应用配置的 Realm 中查找用户及其权限信息。 从这个意义上讲，Realm 实质上是一个安全相关的 DAO：它封装了数据源的连接细节，并在需要时将相关数据提供给 Shiro。当配置 Shiro 时，你必须至少指定一个 Realm，用于认证和（或）授权。配置多个 Realm 是可以的，但是至少需要一个。 Shiro 内置了可以连接大量安全数据源（又名目录）的 Realm，如 LDAP、关系数据库（JDBC）、类似 INI 的文本配置资源以及属性文件等。如果缺省的 Realm 不能满足需求，你还可以插入代表自定义数据源的自己的 Realm 实现。(以上内容来自百度百科) Spring Boot 整合 Shiroshiro 依赖 123456789101112131415161718&lt;!--shiro--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-cas&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; 配置 shiro1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Configurationpublic class ShiroConfig &#123; @Bean public ShiroFilterFactoryBean shirFilter(SecurityManager securityManager) &#123; ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); // 必须设置 SecurityManager shiroFilterFactoryBean.setSecurityManager(securityManager); // setLoginUrl 如果不设置值，默认会自动寻找Web工程根目录下的&quot;/login.jsp&quot;页面 或 &quot;/login&quot; 映射 shiroFilterFactoryBean.setLoginUrl(&quot;/notLogin&quot;); // 设置无权限时跳转的 url; shiroFilterFactoryBean.setUnauthorizedUrl(&quot;/notRole&quot;); // 设置拦截器 Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); //游客，开发权限 filterChainDefinitionMap.put(&quot;/guest/**&quot;, &quot;anon&quot;); //用户，需要角色权限 “user” filterChainDefinitionMap.put(&quot;/user/**&quot;, &quot;roles[user]&quot;); //管理员，需要角色权限 “admin” filterChainDefinitionMap.put(&quot;/admin/**&quot;, &quot;roles[admin]&quot;); //开放登陆接口 filterChainDefinitionMap.put(&quot;/login&quot;, &quot;anon&quot;); //其余接口一律拦截 //主要这行代码必须放在所有权限设置的最后，不然会导致所有 url 都被拦截 filterChainDefinitionMap.put(&quot;/**&quot;, &quot;authc&quot;); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); System.out.println(&quot;Shiro拦截器工厂类注入成功&quot;); return shiroFilterFactoryBean; &#125; /** * 注入 securityManager */ @Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); // 设置realm. securityManager.setRealm(customRealm()); return securityManager; &#125; /** * 自定义身份认证 realm; * &lt;p&gt; * 必须写这个类，并加上 @Bean 注解，目的是注入 CustomRealm， * 否则会影响 CustomRealm类 中其他类的依赖注入 */ @Bean public CustomRealm customRealm() &#123; return new CustomRealm(); &#125;&#125; 注意：里面的 SecurityManager 类导入的应该是 import org.apache.shiro.mgt.SecurityManager; 但是，如果你是复制代码过来的话，会默认导入 java.lang.SecurityManager 这里也稍稍有点坑，其他的类的话，也是都属于 shiro 包里面的类 shirFilter 方法中主要是设置了一些重要的跳转 url，比如未登陆时，无权限时的跳转；以及设置了各类 url 的权限拦截，比如 /user 开始的 url 需要 user 权限，/admin 开始的 url 需要 admin 权限等。 Filter 解释 anon 无参，开放权限，可以理解为匿名用户或游客 authc 无参，需要认证 logout 无参，注销，执行后会直接跳转到shiroFilterFactoryBean.setLoginUrl(); 设置的 url authcBasic 无参，表示 httpBasic 认证 user 无参，表示必须存在用户，当登入操作时不做检查 ssl 无参，表示安全的URL请求，协议为 https perms[user] 参数可写多个，表示需要某个或某些权限才能通过，多个参数时写 perms[“user, admin”]，当有多个参数时必须每个参数都通过才算通过 roles[admin] 参数可写多个，表示是某个或某些角色才能通过，多个参数时写 roles[“admin，user”]，当有多个参数时必须每个参数都通过才算通过 rest[user] 根据请求的方法，相当于 perms[user:method]，其中 method 为 post，get，delete 等 port[8081] 当请求的URL端口不是8081时，跳转到schemal://serverName:8081?queryString 其中 schmal 是协议 http 或 https 等等，serverName 是你访问的 Host，8081 是 Port 端口，queryString 是你访问的 URL 里的 ? 后面的参数 常用的主要就是 anon，authc，user，roles，perms 等 注意：anon, authc, authcBasic, user 是第一组认证过滤器 perms, port, rest, roles, ssl 是第二组授权过滤器 要通过授权过滤器，就先要完成登陆认证操作（即先要完成认证才能前去寻找授权) 才能走第二组授权器（例如访问需要 roles 权限的 url 如果还没有登陆的话，会直接跳转到 shiroFilterFactoryBean.setLoginUrl(); 设置的 url ） shiro filter 修改创建一个 filter 类继承自1FormAuthenticationFilter 重写如下内容12345678910111213141516171819202122232425262728@Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) &#123; JSONObject jsonObject = new JSONObject(); jsonObject.put(&quot;code&quot;, &quot;804&quot;); jsonObject.put(&quot;msg&quot;, &quot;无访问权限!&quot;); PrintWriter out = null; HttpServletResponse res = (HttpServletResponse) response; try &#123; res.setCharacterEncoding(&quot;UTF-8&quot;); res.setContentType(&quot;application/json&quot;); out = response.getWriter(); out.println(jsonObject); &#125; catch (Exception e) &#123; &#125; finally &#123; if (null != out) &#123; out.flush(); out.close(); &#125; &#125; return false; &#125; @Bean public FilterRegistrationBean registration(AjaxPermissionsAuthorizationFilter filter) &#123; FilterRegistrationBean registration = new FilterRegistrationBean(filter); registration.setEnabled(false); return registration; &#125; 将指定的信息返回给客户端。 自定义 realm 类我们首先要继承 AuthorizingRealm 类来自定义我们自己的 realm 以进行我们自定义的身份，权限认证操作。记得要 Override 重写 doGetAuthenticationInfo 和 doGetAuthorizationInfo 两个方法（两个方法名很相似，不要搞错） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class CustomRealm extends AuthorizingRealm &#123; private UserMapper userMapper; @Autowired private void setUserMapper(UserMapper userMapper) &#123; this.userMapper = userMapper; &#125; /** * 获取身份验证信息 * Shiro中，最终是通过 Realm 来获取应用程序中的用户、角色及权限信息的。 * * @param authenticationToken 用户身份信息 token * @return 返回封装了用户信息的 AuthenticationInfo 实例 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; System.out.println(&quot;————身份认证方法————&quot;); UsernamePasswordToken token = (UsernamePasswordToken) authenticationToken; // 从数据库获取对应用户名密码的用户 String password = userMapper.getPassword(token.getUsername()); if (null == password) &#123; throw new AccountException(&quot;用户名不正确&quot;); &#125; else if (!password.equals(new String((char[]) token.getCredentials()))) &#123; throw new AccountException(&quot;密码不正确&quot;); &#125; return new SimpleAuthenticationInfo(token.getPrincipal(), password, getName()); &#125; /** * 获取授权信息 * * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; System.out.println(&quot;————权限认证————&quot;); String username = (String) SecurityUtils.getSubject().getPrincipal(); SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); //获得该用户角色 String role = userMapper.getRole(username); Set&lt;String&gt; set = new HashSet&lt;&gt;(); //需要将 role 封装到 Set 作为 info.setRoles() 的参数 set.add(role); //设置该用户拥有的角色 info.setRoles(set); return info; &#125;&#125; 重写的两个方法分别是实现身份认证以及权限认证，shiro 中有个作登陆操作的 Subject.login() 方法，当我们把封装了用户名，密码的 token 作为参数传入，便会跑进这两个方法里面（不一定两个方法都会进入） 其中 doGetAuthorizationInfo 方法只有在需要权限认证时才会进去，比如前面配置类中配置了 filterChainDefinitionMap.put(“/admin/**”, “roles[admin]”); 的管理员角色，这时进入 /admin 时就会进入 doGetAuthorizationInfo 方法来检查权限；而 doGetAuthenticationInfo 方法则是需要身份认证时（比如前面的 Subject.login() 方法）才会进入 再说下 UsernamePasswordToken 类，我们可以从该对象拿到登陆时的用户名和密码（登陆时会使用 new UsernamePasswordToken(username, password);），而 get 用户名或密码有以下几个方法 1234token.getUsername() //获得用户名 Stringtoken.getPrincipal() //获得用户名 Object token.getPassword() //获得密码 char[]token.getCredentials() //获得密码 Object 注意：有很多人会发现，UserMapper 等类，接口无法通过 @Autowired 注入进来，跑程序的时候会报 NullPointerException， 网上说了很多诸如是 Spring 加载顺序等原因，但其实有一个很重要的地方要大家注意， CustomRealm 这个类是在 shiro 配置类的 securityManager.setRealm() 方法中设置进去的， 而很多人直接写securityManager.setRealm(new CustomRealm()); ,这样是不行的，必须要使用 @Bean 注入 MyRealm，不能直接 new 对象 123456789101112@Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); // 设置realm. securityManager.setRealm(customRealm()); return securityManager; &#125; @Bean public CustomRealm customRealm() &#123; return new CustomRealm(); &#125; 道理也很简单，和 Controller 中调用 Service 一样，都是 SpringBean，不能自己 new当然，同样的道理也可以这样写： 1234567@Bean public SecurityManager securityManager(CustomRealm customRealm) &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); // 设置realm. securityManager.setRealm(customRealm); return securityManager; &#125; 然后只要在 CustomRealm 类加上个类似 @Component 的注解即可。 使用时在 Controller 的接口上加上 @RequiresPermissions 注解即可。当然你还得设计对应的权限表。 参考官网 https://www.jianshu.com/p/3c51832f1051","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"shiro","slug":"shiro","permalink":"http://yoursite.com/tags/shiro/"}]},{"title":"JWT","slug":"JWT","date":"2018-10-15T06:07:03.000Z","updated":"2019-07-28T08:48:37.985Z","comments":true,"path":"JWT/","link":"","permalink":"http://yoursite.com/JWT/","excerpt":"","text":"JWT(JSON WEB TOKEN) 是一套开源的身份验证协议/解决方案。 在实际的开发中，我们经常需要认证用户的信息，并且需要保存相关的数据。常用的方式： 用户向服务器发送用户名和密码 服务器验证通过后，在 session 里保存相关的数据 服务器向客户端返回一个 session_id ，写入客户端 cookie 客户端在随后的每一次请求里，都会通过 cookie ，将 session_id 传回给服务器 服务器通过 session_id 判断用户身份。 这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。 举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？ 一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。 另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。 jwt 原理JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。 12345&#123; &quot;姓名&quot;: &quot;张三&quot;, &quot;角色&quot;: &quot;管理员&quot;, &quot;到期时间&quot;: &quot;2018年7月1日0点0分&quot;&#125; 以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名。 服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。 jwt 的数据结构实际的 jwt 像下面这样它是一个很长的字符串，中间用点（.）分隔成三个部分。注意，JWT 内部是没有换行的，这里只是为了便于展示，将它写成了几行。 JWT 的三个部分依次如下。 Header（头部） Payload（负载） Signature（签名） 写成一行，就是下面的样子。 1Header.Payload.Signature HeaderHeader 部分是一个 JSON 对象，描述 JWT 的元数据，通常是下面的样子。 1234&#123; &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot;&#125; 上面代码中，alg 属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ 属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT。 最后，将上面的 JSON 对象使用 Base64URL 算法转成字符串。 PayloadPayload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用。 1234567iss (issuer)：签发人exp (expiration time)：过期时间sub (subject)：主题aud (audience)：受众nbf (Not Before)：生效时间iat (Issued At)：签发时间jti (JWT ID)：编号 除了官方字段，你还可以在这个部分定义私有字段，下面就是一个例子。 12345&#123; &quot;sub&quot;: &quot;1234567890&quot;, &quot;name&quot;: &quot;John Doe&quot;, &quot;admin&quot;: true&#125; 注意，JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。 这个 JSON 对象也要使用 Base64URL 算法转成字符串。 SignatureSignature 部分是对前两部分的签名，防止数据篡改。 首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。 1234HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret) 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，就可以返回给用户。 Base64URL前面提到，Header 和 Payload 串型化的算法是 Base64URL。这个算法跟 Base64 算法基本类似，但有一些小的不同。 JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法。 jwt 的使用方式客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。 此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息 Authorization 字段里面。 1Authorization: Bearer &lt;token&gt; 另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。 jwt 的特点 JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。 JWT 不加密的情况下，不能将秘密数据写入 JWT。 JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。 JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。 JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。 原文看这里官网介绍看这里 jwt 用法maven 依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.auth0/java-jwt --&gt; &lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;/dependency&gt; demo： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package jwt.jwt;import java.util.Base64;import java.util.Date;import java.util.HashMap;import java.util.Map;import com.auth0.jwt.JWT;import com.auth0.jwt.JWTCreator.Builder;import com.auth0.jwt.algorithms.Algorithm;import com.auth0.jwt.interfaces.DecodedJWT;import com.auth0.jwt.interfaces.JWTVerifier;public class JwtDemo &#123; //JWT验证token的密钥 private static final String JWT_SECRET = &quot;your secret can&apos;t be exposed&quot;; public static void main(String[] args) &#123; //签名算法，根据密钥，生成Algorithm实例，通常应用生命周期内都可以使用这个对象 Algorithm algorithm = Algorithm.HMAC256(JWT_SECRET); //根据Algorithm生成token Builder tokenBuilder = JWT.create(); //配置token的Header自定义部分 Map&lt;String, Object&gt; headers = new HashMap&lt;&gt;(); headers.put(&quot;myheader&quot;, &quot;myheader&quot;); tokenBuilder.withHeader(headers); //配置token的PayLoad部分预定义字段 tokenBuilder.withIssuer(&quot;iss&quot;) .withSubject(&quot;sub&quot;) .withAudience(&quot;viewer1&quot;, &quot;viewer2&quot;) .withExpiresAt(new Date(System.currentTimeMillis() + 5000)); //配置PayLoad部分自定义字段 tokenBuilder.withClaim(&quot;name&quot;, &quot;jack&quot;) .withArrayClaim(&quot;pets&quot;, new String[] &#123;&quot;cat&quot;, &quot;dog&quot;, &quot;bird&quot;&#125;); //根据Alogrithm，签名后生成token String token = tokenBuilder.sign(algorithm); System.out.println(&quot;token : &quot; + token); //解密token看下内容 DecodedJWT decodedJWT = JWT.decode(token); System.out.println(&quot;header : &quot; + decodeBase64Url(decodedJWT.getHeader())); System.out.println(&quot;payload : &quot; + decodeBase64Url(decodedJWT.getPayload())); //构造JWTVerifier，用于验证token，这里说明， //签名及payload用来验证token，header的自定义字段则不用于验证 JWTVerifier jwtVerifier = JWT.require(algorithm) .withIssuer(&quot;iss&quot;) .withAudience(&quot;viewer1&quot;, &quot;viewer2&quot;) .acceptExpiresAt(System.currentTimeMillis() + 5000) .withSubject(&quot;sub&quot;) .withClaim(&quot;name&quot;, &quot;jack&quot;) //可以尝试修改verifier，则下面的验证会抛异常 .withArrayClaim(&quot;pets&quot;, new String[] &#123;&quot;cat&quot;, &quot;dog&quot;, &quot;bird&quot;&#125;) .build(); //使用Verifier执行验证 DecodedJWT decodedJWT2 = jwtVerifier.verify(token); System.out.println(&quot;payload again: &quot; + decodeBase64Url(decodedJWT2.getPayload())); &#125; private static String decodeBase64Url(String base64Url) &#123; return new String(Base64.getUrlDecoder().decode(base64Url)); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"jwt","slug":"jwt","permalink":"http://yoursite.com/tags/jwt/"}]},{"title":"Nginx安装配置","slug":"Nginx安装配置","date":"2018-09-25T09:17:03.000Z","updated":"2019-07-23T06:11:55.466Z","comments":true,"path":"Nginx安装配置/","link":"","permalink":"http://yoursite.com/Nginx安装配置/","excerpt":"","text":"NginxNginx（发音同engine x）是异步框架的网页服务器，也可以用作反向代理、负载平衡器和 HTTP 缓存。该软件由伊戈尔·赛索耶夫创建并于2004年首次公开发布。2011年成立同名公司以提供支持。2019年3月11日，Nginx 公司被 F5 Networks 以6.7亿美元收购。 Nginx 是免费的开源软件，根据类 BSD 许可证的条款发布。一大部分 Web 服务器使用 Nginx，通常作为负载均衡器。Nginx 可以部署在网络上使用 FastCGI 脚本、SCGI 处理程序、WSGI 应用服务器或 Phusion Passenger 模块的动态 HTTP 内容，并可作为软件负载均衡器。 Nginx 使用异步事件驱动的方法来处理请求。Nginx 的模块化事件驱动架构可以在高负载下提供更可预测的性能。 Nginx 是一款面向性能设计的HTTP服务器，相较于 Apache、lighttpd 具有占有内存少，稳定性高等优势。与旧版本（&lt;=2.2）的 Apache 不同，Nginx 不采用每客户机一线程的设计模型，而是充分使用异步逻辑从而削减了上下文调度开销，所以并发服务能力更强。整体采用模块化设计，有丰富的模块库和第三方模块库，配置灵活。 在 Linux 操作系统下，Nginx 使用 epoll 事件模型，得益于此，Nginx 在 Linux 操作系统下效率相当高。同时 Nginx 在 OpenBSD 或 FreeBSD 操作系统上采用类似于 epoll 的高效事件模型 kqueue。 根据 Netcraft 在2016年11月网络服务器调查，Nginx 被发现是所有“活跃”站点（被调查站点的18.22%）和百万最繁忙站点（被调查站点的27.83%）中使用次数最多的Web服务器。根据 W3Techs 的数据，前100万个网站中的37.7%，前10万个网站中的49.7%，以及前10000个网站中的57.0%被使用。 据 BuiltWith 统计，在全球前10000个网站中，有38.2%的网站使用 Nginx。 维基百科使用 Nginx 作为其 SSL 终端代理。 从 OpenBSD 5.2版本（2012年11月1日）开始，Nginx 成为了 OpenBSD 基础系统的一部分，提供了替代 Apache 1.3 系统的替代方案， 但是后来被替换为 OpenBSD 自己的 httpd(8)。（来自维基百科） 安装第一步：安装 Homebrew打开终端输入一下命令 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 关于 homebrew 的介绍看这里 第二步安装 Nginx使用 homebrew 安装 1sudo brew install nginx 查看版本号1nginx -v 注意： brew安装的文件路径一般默认在 /usr/local/Cellar/nginx/ nginx的真正路径在: /usr/local/etc/nginx 启动1启动 sudo nginx 打开浏览器输入http://localhost:8080 其他常用指令12停止 sudo nginx -s stop重启 sudo nginx -s reload ##常用配置 核心配置文件 nginx.conf1位置 /usr/local/etc/nginx/nginx.conf nginx 配置文件主要分为六个区域： main(全局设置) events(nginx工作模式) http(http设置) sever(主机设置) location(URL匹配) upstream(负载均衡服务器设置)。 nginx.conf 常用配置 server模块 12345678910server &#123; listen 8080; #端口配置 server_name localhost; #域名配置 #charset koi8-r; #access_log logs/host.access.log main; ······&#125; location模块 1234location / &#123; root html; index index.html index.htm; &#125; location /表示匹配访问根目录。root指令用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。默认的html读取路径是 1路径 /usr/local/Cellar/nginx/[version]/html 这里的html文件夹实际上是一个替身（快捷方式），实际的默认文件位置是在 1默认文件路径 /usr/local/var/www 其他参数 1234567listen：表示当前的代理服务器监听的端口，默认的是监听80端口。注意，如果我们配置了多个server，这个listen要配置不一样，不然就不能确定转到哪里去了。server_name：表示监听到之后需要转到哪里去，这时我们直接转到本地，这时是直接到nginx文件夹内。location：表示匹配的路径，这时配置了/表示所有请求都被匹配到这里root：里面配置了root这时表示当匹配这个请求的路径时，将会在这个文件夹内寻找相应的文件，这里对我们之后的静态文件伺服很有用。 #配置 Tomcat 通过 proxy_pass 配置请求转发地址。即当访问 localhost 的 8080 端口时，请求会跳转至 localhost 的 8180 端口处。修改完 Nginx 的配置后不需要重启 Nginx，输入上面的重启命令即可。 负载均衡配置当一台服务器出现故障后，我们需要将请求自动转向另一台服务器，此种需求该如何配置呢？利用Nginx 也是比较方便能够实现，具体配置如下： 注意，上面还加上了一个weight属性，此属性表示各服务器被访问到的权重，weight越高访问到的几率越高。 配置后访问 localhost:8080,跳转到 tomcat 的启动页： 其他配置 配置示例1、配置 HTTP 服务（80端口） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# Virtual Host configuration for arlingbc.com## You can move that to a different file under sites-available/ and symlink that# to sites-enabled/ to enable it.## 丢弃缺乏 Host 头的请求server &#123; listen 80; return 444;&#125;server &#123; listen 80; listen [::]:80; server_name example.com www.example.com; # 定义服务器的默认网站根目录位置 root /var/www/example/; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; # access log file 访问日志 access_log logs/nginx.access.log main; # 禁止访问隐藏文件 # Deny all attempts to access hidden files such as .htaccess, .htpasswd, .DS_Store (Mac). location ~ /\\. &#123; deny all; access_log off; log_not_found off; &#125; # 默认请求 location / &#123; # 首先尝试将请求作为文件提供，然后作为目录，然后回退到显示 404。 # try_files 指令将会按照给定它的参数列出顺序进行尝试，第一个被匹配的将会被使用。 # try_files $uri $uri/ =404; try_files $uri $uri/ /index.php?path_info=$uri&amp;$args =404; access_log off; expires max; &#125; # 静态文件，nginx 自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期 30 天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125; # .php 请求 location ~ \\.php$ &#123; try_files $uri =404; include /etc/nginx/fastcgi_params; fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_intercept_errors on; &#125; # PHP 脚本请求全部转发到 FastCGI 处理. 使用 FastCGI 默认配置. # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # include snippets/fastcgi-php.conf; # # # With php7.0-cgi alone: # fastcgi_pass 127.0.0.1:9000; # # With php7.0-fpm: # fastcgi_pass unix:/run/php/php7.0-fpm.sock; #&#125; # 拒绝访问. htaccess 文件，如果 Apache 的文档根与 nginx 的一致 # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125;&#125; 2、配置 HTTPS 服务（443端口） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748### 443 port##server &#123; ## # 阿里云参考配置 ## listen 443; listen [::]:443; server_name example.com www.example.com; root /var/www/example/; # 为虚拟服务器指明文档的根目录 index index.html index.htm; # 给定URL文件 ## # 部署 HTTP 严格传输安全（HSTS） ## add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains; preload;&quot; # Note: You should disable gzip for SSL traffic. # See: https://bugs.debian.org/773332 gzip off; ## # SSL configuration ## ssl on; ssl_certificate cert/certfile.pem; # 证书 ssl_certificate_key cert/certfile.key; # 私钥 ssl_session_timeout 5m; # 设置超时时间 # 密码套件配置 # 密码套件名称构成：密钥交换-身份验证-加密算法（算法-强度-模式）-MAC或PRF ssl_ciphers ECDHE-RSA-AES128-GCM- SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1.2; # 设置 SSL/TSL 协议版本号 ssl_prefer_server_ciphers on; # 控制密码套件优先级，让服务器选择要使用的算法套件 ssl_buffer_size 1400; # 减少TLS缓冲区大小，可以显著减少首字节时间（《HTTPS权威指南》P416） ## # location configuration ## # ...&#125; 参考https://blog.csdn.net/zzk220106/article/details/72466765https://www.cnblogs.com/naaoveGIS/p/5478208.htmlhttps://www.jianshu.com/p/849343f679aa配置详解","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"用 Hexo + Github 搭建个人的 Blog","slug":"hexo","date":"2018-09-12T16:00:00.000Z","updated":"2019-07-22T08:47:51.679Z","comments":true,"path":"hexo/","link":"","permalink":"http://yoursite.com/hexo/","excerpt":"","text":"Hexo + Github 搭建个人blog最近花时间研究了一下 hexo + github 搭建个人 blog，觉得还不错。就把个人的 blog 的搭建换成了 hexo。而我之前用的是 jekyll + github 搭建的，二者各有千秋，看个人喜好。想要学习如何使用 jekyll 搭建自己的 blog，可以看一下我的这篇文章。 对比了一下两种搭建的方式，我们来看看二者的不同： 首先是 jekyll jekyll 安装起来相对来说，繁琐一些 jekyll 的配置主题修改起来相对简单一些，如果你有简单的 HTML 操作，在修改jekyll 样式的时候很方便 jekyll 写完新的文章部署到 git 上，步骤相对多一些。多的操作也就是 git 的 add，push 等操作 接着来看看 hexo hexo 安装方便 hexo 主题样式的修改相对来说繁琐一些，文件太多 hexo 部署简单，操作更少。两个指令就可解决 hexo 更依赖于插件，来完善自己的功能 同样，二者的主题都很多，你可以直接按照别人的文档修改就可。jekyll 主题、hexo 主题 个人觉得，在更换不同的电脑，配置完环境，进行编写的时候， jekyll 更方便一些，直接把 git 仓库里的代码 clone 到本地就可以进行操作了。而 hexo 部署到 git 上的目录结构已经变了，所以 clone 以后并不能编辑，部署。需要生成指定的目录，把 git 仓库里的内容 clone 到指定的目录。 安装 Hexo说了那么多，咱们开始步入正轨。由于 hexo 是依赖于 nodejs 的，安装 nodejs 我们可以使用 homebrew（Homebrew是以最简单，最灵活的方式来安装苹果公司在MacOS中不包含的UNIX工具）。 打开终端： 1、安装 homebrew 12ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;//如果你不知道什么是 ruby，请自行搜索，以及如何更换 ruby 源 2、安装 nodejs 12brew install node//如有提示，按照提示安装相关依赖 3、安装 hexo 1sudo npm install -g hexo 4、创建文件夹 12345//你可以选择任意位置创建一个你个人 blog 的存放目录//在终端进入到创建好的文件夹cd /Users/XXX/Desktop/myBlog#初始化 hexohexo init 5、生成静态网页 1234//编译hexo generate//启动本地服务器 hexo server 在浏览器上运行 http://localhost:4000 就能看到类似于如下的网站首页： 生成新的文章，修改配置如何生成新的文章呢？ 生成新的文章12345678//前提是你已经在终端进入到了上一步创建的文件夹hexo new post &quot;我的第一篇博客&quot;//然后你可以看到终端显示如下信息：//INFO Created: ~/blog/source/_posts/我的第一篇博客.md//表名创建成功。然后直接使用 markdown 编辑器，编辑即可。//如果你不知道什么是 markdown 请自行搜索。 如何修改 hexo 的配置呢？你可以在根目录下看到 _config.yml 文件，打开之后如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/ # Site ##修改以适应搜索引擎的收录title: Hexo ##定义网站的标题subtitle: ##定义网站的副标题description: ##定义网站的描述author: jason jwl ##定义网站的负责人language: ##定义网站的语言,默认zh-Hans，跟换主题后，根据主题提供的语言进行修改timezone: ##定义网站的时区 # URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://yoursite.com ##定义网站访问的域名root: / ##定义所在Web文件夹在哪个目录permalink: :year/:month/:day/:title/ ##定义时间格式permalink_defaults: # Directorysource_dir: source ##定义从哪个文件夹获取博客资料public_dir: public ##定义生成静态网站到哪个文件夹 archive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render: # Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map: # Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss # Pagination## Set per_page to 0 to disable paginationper_page: 10 ##定义每一页多少条博客pagination_dir: page # Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: landscape ##定义使用的主题 # Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: 1、我们可以参照上面的注释修改网站的主题，描述子标题等。 2、需要注意的是 在跟换网站语言的时候，不同的主题，对应的中文的名称不一样，需要根据自己主题里的语言进行修改。 3、permalink 选项决定你在浏览器地址栏所看见的文章地址，我是选择去掉了年月日。 4、theme 第一次初始化之后，使用的是默认的主题 landscape，在此处配置不同主题。根目录 theme 文件夹下。 5、deploy 用配置关联 github。 如果关联 github首先在 github 上创建一个 xxxxx.github.io 仓库(xxxxx是你github 的账号名)，然后把本地项目提交到 github 的远程项目。具体的操作，你可以参考我的 这篇文章。 然后在 _config.yml 文件，修改配置： 12345deploy: type: git repo: https://github.com/xxx/xxx.github.io.git branch: master // xxx为个人github的name 最后运行下面的命令即可 123456789//清除缓存hexo clean//编译简写hexo g// 部署到githexo d//如果报错如下：ERROR Deployer not found: git//安装下列插件，然后重复上面的操作就行了npm install hexo-deployer-git --save 如果发布新的文章，同样执行上面的三个指令就行了。 如何绑定自己的域名先去自己购买一个域名，设置一下。按照我上面文章的链接操作。唯一要注意的是在终端，进入到自己上面创建的存放 blog 的根目录下的 source 文件夹，执行vi CNAME，然后用文本编辑打开该文件（如果，你会使用vi操作，就直接输入即可），直接把个人域名地址放进去即可 高级一点的更换主题前面，我已经把 hexo 的主题网址贴出来了，想换哪一个直接点进去，按照里面的描述，操作即可。 但是，这里有一个坑，先看一下下面的图： 这里一般新的主题只有前两个可以使用，后面的点击都会出现下面的情况：所以我们需要如下操作 1234//比如要创建标签文件夹，终端中输入（前提在Hexo文件路径下）：hexo new page &quot;tags&quot;输出：INFO Created: ~/Desktop/MyBlog/Blog/source/tags/index.md 然后，坑就出现了，按照网上查的，有人说编辑上面路径的 index.md 如下： 123title: tagsdate: 2018-01-20 18:57:48type: &quot;tags&quot; 实际上应该是这样的： 123title: tagsdate: 2018-01-20 18:57:48layout: tags 这样当你在创建新的文章的时候，tags 才起作用。类推一下，分类、关于，你都可以按照上面的操作，来做。 搜索对于搜索，在你 clone 下来的主题文件夹里，也有一个 _config.yml 文件，你可以按照配置文件后面的注释来操作，以及阅读该主题的 README 文档进行配置。基本上都是依赖插件来做的。 配置404我的 blog 利用的是腾讯的404公益界面 。 首先 12#进入 Hexo 所在文件夹（前面安装的时候，自己创建的），输入 hexo new page 404 接着 12345678910111213141516#在根目录下 /source/404/index.md 添加以下代码：---title: 404 Not Found: 该页无法显示comments: falsepermalink: /404---&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;404&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 切记 permalink: /404 必须添加，否则不生效 最后部署 123hexo clean hexo g hexo d 添加评论功能由于网易的跟帖服务停止维护了，所以我们可以选择来必力。首先我们先到 https://livere.com 网站注册账号，选择免费的然后点击客户中心，填写一些信息，就会得到下面的内容：拿到 data-uid 在你的主题配置文件里进行填写。部署一下就可以了。firefox 浏览器加载不了，其他的浏览器可以。估计是我的 firefox 浏览器的 jQuery 没打开。搜索功能也是的，firefox 不支持。 如何存放图片首先把 hexo 的配置文件打开，（不是主题的配置文件） 12//找到下面的，设置为 truepost_asset_folder: true 然后安装插件 1npm install hexo-asset-image --save 接着 1234//等一小会儿，执行下面的命令hexo n &quot;xxxx&quot;//会生成一篇新的 xxxx.md 文件，以及一个同名的 xxxx 文件夹，把图片放入该文件夹中。//然后利用 ![你想输入的替代文字](xxxx/图片名.jpg) 语法，在你的 md 文件里使用图片 最后部署一下就可以了。 结语总体来说，怎个流程都比较简单，你要相信，你遇到的问题，网上都有人遇到，所以，不知道如何操作，果断打开你的Google浏览器，百度一下，啥都有了。皮一下，很开心哦。 另外，想添加一些骚操作的东西，可以看看这些文章： https://blog.csdn.net/sugar_rainbow/article/details/57415705 https://blog.csdn.net/qianqianstd/article/details/55823691 https://www.jianshu.com/p/9f0e90cc32c2","categories":[{"name":"搭建 blog","slug":"搭建-blog","permalink":"http://yoursite.com/categories/搭建-blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"NSHashTable 和 NSMapTable","slug":"2018-04-27-hashTable","date":"2018-04-26T16:00:00.000Z","updated":"2019-07-22T08:47:51.835Z","comments":true,"path":"2018-04-27-hashTable/","link":"","permalink":"http://yoursite.com/2018-04-27-hashTable/","excerpt":"","text":"NSHashTable 和 NSMapTable前言在我们的开发之中不知道你是否留意过这两个类？在你的代码中，有没有使用过这两个类？（ ps：在我开发的过程中，居然没有用过。）下面我们就来看看这两个类是用来干什么的。 NSHashTable可能在今天的 ARC 的内存管理下，我们不太注重对于一个对象的内存管理，不太注重是不是会产生强引用，所以对于 NSHashTable 这个类不太关注，至少在我的开发过程中，没有去使用这个类。 NSHashTable 效仿了 NSSet(NSMutableSet) ，但是提供了比 NSSet 更多的操作选择。特别是在弱引用的支持上，NSHashTable 在对象以及内存处理上更加灵活。 特性1. NSHashTable 是可变的，它没有不可变版本。 2. 它可以持有元素的弱引用，而且对象被销毁之后能正确的将其移除。而这一点在 NSSet 是做不到的。 3. 它的成员可以在添加时被拷贝。 4. 它的成员可以使用指针来标识是否相等及做 hash 检测 5. 它可以包含任意指针，其成员没有限制为对象。我们可以配置一个 NSHashTable 实例来操作任意的指针，而不仅仅是对象。 初始化 NSHashTable 时，我们可以设置一个初始选项，这个选项确定了 NSHashTable 对象后面所有的行为。这个选项是有 NSHashTableOptions 枚举来定义的，枚举类型如下： 123456789101112// 默认行为，强引用集合中的对象，等同于 NSSet NSHashTableStrongMemory = 0, // 在将对象添加到集合之前，会拷贝对象 NSHashTableCopyIn = NSPointerFunctionsCopyIn, // 使用移位指针 (shifted pointer) 来做 hash 检测及确定两个对象是否相等； // 同时使用 description 方法来做描述字符串 NSHashTableObjectPointerPersonality = NSPointerFunctionsObjectPointerPersonality, // 弱引用集合中的对象，且在对象被释放后，会被正确的移除。 NSHashTableWeakMemory = NSPointerFunctionsWeakMemory 示例我们来看一下，关于弱引用的使用： 123456789101112131415161718192021222324252627282930313233#import &quot;ViewController.h&quot;@interface ViewController () &#123; NSHashTable *_hashTable;&#125;@end@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad]; [self test]; NSLog(@&quot;调用之后的 hashTable：%@&quot;, _hashTable);&#125;- (void)test &#123; if (!_hashTable) &#123; _hashTable = [NSHashTable weakObjectsHashTable]; &#125; NSObject *objc = [[NSObject alloc] init]; [_hashTable addObject:objc]; NSLog(@&quot;添加之后的 hashTable ：%@&quot;, _hashTable);&#125;- (void)didReceiveMemoryWarning &#123; [super didReceiveMemoryWarning];&#125;@end 打印结果： 1234562018-07-12 21:32:42.401083+0800 HashTableAndMapDemo[73674:2559037] 添加之后的 hashTable ：NSHashTable &#123;[4] &lt;NSObject: 0x60000001f9f0&gt;&#125;2018-07-12 21:32:42.401264+0800 HashTableAndMapDemo[73674:2559037] 调用之后的 hashTable：NSHashTable &#123;&#125; 我们可以看到，在出了作用域之后，obj 立刻被释放了。集合里的引用也被安全的删除了。 NSMapTableNSMapTable 对象类似与 NSDictionary 的数据结构，但是 NSMapTable 功能比 NSDictionary 对象要多的功能就是可以设置 key 和 value 的 NSPointerFunctionsOptions 特性,其他的用法与 NSDictionary 相同。 特性1. NSDictionary/NSMutableDictionary 会复制 keys 并且通过强引用 values 来实现存储。 2. NSMapTable 是可变的。 3. NSMapTable 可以通过弱引用来持有 keys 和 values，所以当 key 或者 value 被deallocated 的时候，所存储的实体也会被移除。 4. NSMapTable 可以在添加 value 的时候对 value 进行复制。 和 NSHashTable 类似，NSMapTable 可以随意的存储指针，并且利用指针的唯一性来进行对比和重复检查。 简单示例来看看简单的示例： 123456789101112- (void)testMap &#123; if (!_mapTable) &#123; _mapTable = [NSMapTable mapTableWithKeyOptions:NSMapTableStrongMemory valueOptions:NSMapTableStrongMemory]; NSObject *objc = [[NSObject alloc] init]; [_mapTable setObject:objc forKey:@&quot;123&quot;]; NSLog(@&quot;keys: %@&quot;, [[_mapTable keyEnumerator] allObjects]); NSLog(@&quot;_map: %@&quot;, _mapTable); &#125; &#125; 打断点调试，断点1 放在 set 位置，断点2 放在 NSLog 位置： 1234567(lldb) po CFGetRetainCount((__bridge CFTypeRef)(objc));1(lldb) po CFGetRetainCount((__bridge CFTypeRef)(objc));2(lldb) 可以看到当 value 使用 NSMapTableStrongMemory 修饰时，objc 的引用计数为2. 1234567(lldb) po CFGetRetainCount((__bridge CFTypeRef)(objc));1(lldb) po CFGetRetainCount((__bridge CFTypeRef)(objc));1(lldb) 当 value 使用 NSMapTableWeakMemory 修饰时， objc 的引用计数为1. 可以看得出来，类似于 NSHashTable 选择，不同的模式，对于对象的引用持有是不同的。 结语以上就是关于 NSHashTable 和 NSMapTable 相关的一些记载，其实，在开中 NSSet 和 NSDictionary 能解决大多数的问题，当然了解更多的知识点，对于自己的思路也是扩展的。所以，想了解更多的内容可以参考 这篇文章 以及 这篇文章，或者去问度娘。","categories":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/categories/iOS/"}],"tags":[{"name":"NSHashTable","slug":"NSHashTable","permalink":"http://yoursite.com/tags/NSHashTable/"},{"name":"NSMapTable","slug":"NSMapTable","permalink":"http://yoursite.com/tags/NSMapTable/"}]},{"title":"NSProxy","slug":"2018-04-25-NSProxy","date":"2018-04-24T16:00:00.000Z","updated":"2019-07-22T08:47:51.591Z","comments":true,"path":"2018-04-25-NSProxy/","link":"","permalink":"http://yoursite.com/2018-04-25-NSProxy/","excerpt":"","text":"NSProxy前两天被问到有没有接触过NSHashTable and NSMapTable，由于项目中没用到过，所以之前也没有去了解过。然后，就在网上查了一下，结果在一篇文章中看到了一段话如下： 如果一个开发者想要存储一个weak类型的值或者使用一个没有实现NSCopying协议的object作为NSDictionary的key，他可能会很聪明的想到NSValue +valueWithNonretainedObject。 于是乎又去看看了valueWithNonretainedObject相关的内容，然后在这一篇文章中看到了本文的主角NSProxy。 偷窥NSProxyNSProxy是和NSObject同级的一个类，可以说他是一个虚拟类，它只是实现了NSObject的协议。它的作用有点类似于一个复制的类。我们可以看一下NSProxy里包含哪些内容：可以看得出来，它确实遵守了NSObject协议，而且第一个Ivr是一个isa指针，所以我们可以把它当作一个NSObject或者派生类来使用。 通过代码加深偷窥我们可以通过代码来看看，我么可以做哪些操作，可以用来做些什么。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// XZFProxy.h#import &lt;Foundation/Foundation.h&gt;@interface XZFProxy : NSProxy@property (nonatomic, copy) NSString *className; //类名，用来过滤类- (void)initWithFromObjc:(NSObject *)objc; //初始化方法@end// XZFProxy.m#import &quot;XZFProxy.h&quot;@interface XZFProxy()@property (nonatomic, strong) NSObject *objc;@end@implementation XZFProxy+ (id)proxyWithObjc:(NSObject *)objc &#123; XZFProxy *xzfProxy = [XZFProxy alloc]; xzfProxy.objc = objc; return xzfProxy;&#125;/** 初始化 @param objc 传入一个objc */- (void)changeObjc:(NSObject *)objc &#123; self.objc = objc;&#125;#pragma mark - 需要实现的方法///1.查询该方法的方法签名,用来生成 NSInvocation- (NSMethodSignature *)methodSignatureForSelector:(SEL)sel &#123; NSMethodSignature * mSignature = nil; if ([self.objc methodSignatureForSelector:sel]) &#123; mSignature = [self.objc methodSignatureForSelector:sel]; &#125; else &#123; mSignature = [super methodSignatureForSelector:sel]; &#125; return mSignature;&#125;///2.有了方法签名，调用方法实现-(void)forwardInvocation:(NSInvocation *)invocation &#123; //在这里我们可以实现对任意对象的行为进行拦截 if (self.objc) &#123; //拦截方法的执行者为复制的对象 [invocation setTarget:self.objc]; if ([self.objc isKindOfClass:[NSClassFromString(self.className) class]]) &#123; //拦截参数 argument：表示的是方法的参数 index：表示的是方法参数的下标 NSString *str = @&quot;不爱学习，只想玩。。。&quot;; [invocation setArgument:&amp;str atIndex:3]; &#125; //开始调用方法 [invocation invoke]; &#125;&#125;@end 代码的调用： 123456789101112- (void)viewDidLoad &#123; [super viewDidLoad]; XZFTeacher *teacher = [[XZFTeacher alloc] init]; XZFProxy *xzfProxy = [XZFProxy proxyWithObjc:teacher]; xzfProxy.className = @&quot;XZFTeacher&quot;; [xzfProxy performSelector:@selector(callStudentWithName:toLearnProject:) withObject:@&quot;张三&quot; withObject:@&quot;英语&quot;]; XZFStudent *student = [[XZFStudent alloc] initWithName:@&quot;李四&quot;]; [xzfProxy changeObjc:student]; [xzfProxy performSelector:@selector(startLearnProject:) withObject:@&quot;数学&quot;];&#125; 我们可以在控制台查看打印的结果：我们很轻松的改变了Teacher的执行内容。当然我们还可以通过下面两个方法，处理一个方法的返回值： 12- (void)getReturnValue:(void *)retLoc;- (void)setReturnValue:(void *)retLoc; 我们可以用下面的代码来获取被代理对象的方法返回值： 12NSString *str;[invocation setReturnValue:&amp;str]; 通过下面的代码来修改被代理对象的方法的返回值： 12NSString *str = @&quot;迎娶白富美，出任CEO&quot;;[invocation setReturnValue:&amp;str]; 值得注意的是：上述方法是拷贝指针所指向的数据，所以要传递str指针的指针，这样才能把str设置为返回值的地址，切记不要弄混淆了。 总结通过NSProxy，不仅可以修改方法的执行结果，还可以实现埋点计数等功能。你可以开动你的大脑去想想怎么利用NSProxy实现更多你想实现的效果。本文代码地址请戳这里。想了解更多的内容你可以参考下面的几篇文章： https://www.jianshu.com/p/a7187e014c03 https://www.jianshu.com/p/923f119333d8 https://blog.csdn.net/ssirreplaceable/article/details/53375972","categories":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/categories/iOS/"}],"tags":[{"name":"weak类型","slug":"weak类型","permalink":"http://yoursite.com/tags/weak类型/"},{"name":"NSProxy","slug":"NSProxy","permalink":"http://yoursite.com/tags/NSProxy/"}]},{"title":"数据结构算法之 二叉树","slug":"2018-04-05-binary-tree","date":"2018-04-04T16:00:00.000Z","updated":"2019-07-22T08:47:51.684Z","comments":true,"path":"2018-04-05-binary-tree/","link":"","permalink":"http://yoursite.com/2018-04-05-binary-tree/","excerpt":"","text":"二叉树树的概念树（tree）是一种抽象数据类型（ADT）或是实作这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由n(n &gt; 1)个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为看起来像一颗倒挂的树，也就是说他是根朝上，而叶朝下的。它具有以下特点： 每个节点有零个或多个子节点； 没有父节点的节点称为根节点； 每一个非根节点有且只有一个父节点； 除了根节点外，每个子节点可以分为多个不相交的子树； 树的术语 节点的度：一个节点含有的子树的个数称为该节点的度； 树的度：一棵树中，最大的节点称为树的度； 叶节点或终端节点：度为0的节点； 父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点； 子节点：一个节点含有的子树的根节点称为该节点的子节点； 兄弟节点：具有相同父节点的节点互称为兄弟节点； 节点的层次：从根开始定义起，根为第一层，根的子节点为第二层，以此类推； 树的高度或深度：树中节点的最大层次； 堂兄弟节点：父节点在同一层的节点互为堂兄弟； 节点的祖先：从跟到该节点所经分支上的所有节点； 子孙：以某节点为根的子树中任一节点都称为该节点的子孙； 森林：由m(m &gt;= 0)颗互不相交的树的集合称为森林； 树的种类 无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树； 有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树； 1、二叉树：每个节点最多含有两个子树的树称为二叉树； **a、完全二叉树：**对于一棵二叉树，假设其深度为d（d &gt; 1）。除了第d层外，其他各层的节点数目均已达到最大值，且第d层所有节点从左向右连续的紧密的排列，这样的二叉树被称为完全二叉树，其中**满二叉树**的定义是所有叶节点都在最底层的完全二叉树； **b、平衡二叉树：**当且仅当任何节点的两颗子树的高度差不大于1的二叉树； **c、排序二叉树：**也称二叉搜索树，有序二叉树； 2、霍夫曼树（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树； 3、B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树。 树的存储与表示顺序存储：将数据结构存储在固定的数组中，然在遍历速度上有一定的优势，但因所占空间比较大，是非主流二叉树。二叉树通常以链式存储。链式存储：由于对节点的个数无法掌握，常见树的存储表示都转换成二叉树进行处理，子节点个数最多为2。 常见的一些树的应用场景 xml，html等，那么编写这些东西的解析器的时候，不可避免用到树 路由协议就是使用了树的算法 mysql数据库索引 文件系统的目录结构 所以很多经典的AI算法其实都是树搜索，此外机器学习中的decision tree也是树结构 二叉树二叉树的基本概念二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”和“右子树”。 二叉树的性质（特性）性质1:在二叉树的第i层上至多有2^(i-1)个节点（i &gt; 0）；性质2:深度为k的二叉树至多2^k -1个节点；性质3:对于任意一棵二叉树，如果其叶节点数为N0，而度数为2的节点总数为N1，则N0 = N1 + 1；性质4:具有n个节点的完全二叉树的深度必为log2(n + 1)；性质5:对完全二叉树，若从上至下、从左至右编号，则编号为i 的结点，其左孩子编号必为2i，其右孩子编号必为2i＋1；其双亲的编号必为i/2（i＝1 时为根,除外） (1)完全二叉树——若设二叉树的高度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树。 (2)满二叉树——除了叶结点外每一个结点都有左右子叶且叶子结点都处在最底层的二叉树。 二叉树的创建创建节点：通过使用Node类中定义三个属性，分别为elem本身的值，还有lchild左孩子和rchild右孩子 12345678910111213141516171819202122232425#pragma mark - 二叉树节点@interface Binary_Tree_Node()@property(nonatomic, assign) int elem;@property(nonatomic, strong) Binary_Tree_Node *lChild;@property(nonatomic, strong) Binary_Tree_Node *rChild;- (instancetype)initWithItem:(int)item;@end@implementation Binary_Tree_Node/** 初始化节点 @param item 节点的值 @return 返回节点 */- (instancetype)initWithItem:(int)item &#123; if (self = [super init]) &#123; self.elem = item; self.lChild = nil; self.rChild = nil; &#125; return self;&#125;@end 创建树：树的创建,创建一个树的类，并给一个root根节点，一开始为空，随后添加节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#pragma mark - 二叉树@interface Binary_Tree()@end@implementation Binary_Tree- (instancetype)init &#123; if (self = [super init]) &#123; self.root_Node = nil; &#125; return self;&#125;#pragma mark - 添加节点/** 添加节点 @param item 节点的值 */- (void)add:(int)item &#123; Binary_Tree_Node *node = [[Binary_Tree_Node alloc] initWithItem:item]; if (self.root_Node == nil) &#123; self.root_Node = node; return; &#125; NSMutableArray &lt;Binary_Tree_Node *&gt;*nodeArray = [NSMutableArray array]; [nodeArray addObject:self.root_Node]; while (nodeArray.count) &#123; Binary_Tree_Node *cur_node = nodeArray[0]; if (cur_node.lChild == nil) &#123; cur_node.lChild = node; return; &#125; else &#123; [nodeArray addObject:cur_node.lChild]; &#125; if (cur_node.rChild == nil) &#123; cur_node.rChild = node; return; &#125; else &#123; [nodeArray addObject:cur_node.rChild]; &#125; [nodeArray removeObjectAtIndex:0]; &#125;&#125; 二叉树的遍历树的遍历是一种重要的运算。所谓遍历是指对树中所有结点的信息的访问，即依次对树中每个结点访问一次且仅访问一次，我们把这种对所有节点的访问称为遍历（traversal）。那么树的两种重要的遍历模式是深度优先遍历和广度优先遍历,深度优先一般用递归，广度优先一般用队列。一般情况下能用递归实现的算法大部分也能用堆栈来实现。 广度优先遍历：（层次遍历）从树的root开始，从上到下从左到右遍历整个树的节点 123456789101112131415161718192021222324252627#pragma mark - 广度遍历/** 遍历二叉树的每一个节点 */- (void)breadth_travel &#123; if (self.root_Node == nil) &#123; return; &#125; NSMutableArray &lt;Binary_Tree_Node *&gt;*nodeArray = [NSMutableArray array]; [nodeArray addObject:self.root_Node]; while (nodeArray.count) &#123; Binary_Tree_Node *cur_node = nodeArray[0]; NSLog(@&quot;%d&quot;, cur_node.elem); if (cur_node.lChild != nil) &#123; [nodeArray addObject:cur_node.lChild]; &#125; if (cur_node.rChild != nil) &#123; [nodeArray addObject:cur_node.rChild]; &#125; [nodeArray removeObjectAtIndex:0]; &#125;&#125; 深度优先遍历：对于一棵二叉树，深度优先搜索是沿着树的深度遍历树的节点，尽可能深的搜索树的分支。那么深度遍历有三种方法，这三种方式常被用于访问树的节点，他们之间的不同在于访问每个节点的次序不同。这三种遍历分别叫做先序遍历(preorder)，中序遍历(inorder)和后序遍历(postorder)。 先序遍历，我们先访问根节点，然后递归使用先序遍历访左问子树，再递归使用先序遍历访问右子树 根节点-&gt;左节点-&gt;右节点 123456789101112131415#pragma mark - 1.前序遍历 根节点-&gt;左子树-&gt;右子树/** 前序遍历 根节点-&gt;左子树-&gt;右子树 @param node 传进来的节点 */- (void)preOrder:(Binary_Tree_Node *)node &#123; if (node == nil) &#123; return; &#125; NSLog(@&quot;%d&quot;, node.elem); [self preOrder:node.lChild]; [self preOrder:node.rChild];&#125; 中序遍历，我们递归使用中序遍历访问左子树，然后访问根节点，最后再递归使用中序遍历访问右子树 左子树-&gt;根节点-&gt;右子树 123456789101112131415#pragma mark - 2.中序遍历 左子树-&gt;根节点-&gt;右子树/** 中序遍历 左子树-&gt;根节点-&gt;右子树 @param node 传进来的节点 */- (void)inOrder:(Binary_Tree_Node *)node &#123; if (node == nil) &#123; return; &#125; [self inOrder:node.lChild]; NSLog(@&quot;%d&quot;, node.elem); [self inOrder:node.rChild];&#125; 后序遍历，我们先递归使用后序遍历访问左子树和右子树，最后访问根节点 左子树-&gt;右子树-&gt;根节点 123456789101112131415#pragma mark - 3.前序遍历 左子树-&gt;右子树-&gt;根节点/** 左子树-&gt;右子树-&gt;根节点 @param node 传进来的节点 */- (void)postOrder:(Binary_Tree_Node *)node &#123; if (node == nil) &#123; return; &#125; [self postOrder:node.lChild]; [self postOrder:node.rChild]; NSLog(@&quot;%d&quot;, node.elem);&#125; 本文代码地址请点我","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/数据结构/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://yoursite.com/tags/二叉树/"}]},{"title":"数据结构算法之 常见算法","slug":"2018-03-31-arithmetic","date":"2018-03-30T16:00:00.000Z","updated":"2019-07-22T08:47:51.743Z","comments":true,"path":"2018-03-31-arithmetic/","link":"","permalink":"http://yoursite.com/2018-03-31-arithmetic/","excerpt":"","text":"算法常见概念算法的概念算法是计算机处理信息的本质，因为计算机程序本质上是一个算法来告诉计算机确切的步骤来执行一个指定的任务。一般的，当算法在处理信息时，会从输入设备或者数据的存储地址读取数据，把结果写入输出设备或者某个存储地址供以后调用。算法是独立存在的一种解决问题的方法和思想。对于算法而言，实现的语言并不重要，重要的是思想。算法可以有不同的语言描述实现版本（Objective-C，Swift，Python，Java描述等），而本文主要用OC，Swift，Python语言进行描述。 算法的5大特性 输入：算法具有0个或多个输入 输出：算法至少有1个或多个输出 有穷性：算法在有限的步骤之后会自动结束而不会无限循环，并且每一个步骤可以在接受的时间内完成 确定性：算法中的每一步都有确切的含义，不会出现二义性 可行性：算法的每一步都是可行的，也就是说每一步都能够执行有限的次数完成 数据结构的概念数据是一个抽象的概念，将其进行分类后得到程序设计语言中的基本类型。如：int，float，char等。数据元素之间不是独立的，存在特定的关系，这些关系便是结构。数据结构指数据对象中数据元素之间的关系。 算法与数据结构的区别数据结构只是静态的描述了数据元素之间的关系。高效的程序需要在数据结构的基础上设计和选择算法。程序 = 数据结构 + 算法总结：算法是为了解决实际问题而设计的，数据结构是算法需要处理的问题的载体。 常见算法冒泡排序冒泡排序（bubble sort）是一种简单的排序算法。它重复的遍历要排序的数组，一次比较两个元素，如果他们的顺序错误就把他们交换过来。遍历数组的工作是重复的进行直到没有再需要交换的元素，也就是说该数组已经排序完成。这个算法名字的由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 图解如下： 原理如下： 比较相邻的元素。如果第一个比第二个大（升序），就交换它们两个。 对每一对相邻的元素做同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 针对所有的元素重复以上的步骤，最后一个除外。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// OC实现- (NSArray *)bubble_sort:(NSMutableArray &lt;NSNumber *&gt;*)array &#123; if (array.count == 0) &#123; return @[]; &#125; for (int i = 0; i &lt; array.count - 1; i ++) &#123; int count = 0; for (int j = 0; j &lt; array.count - 1 - i; j ++) &#123; if (array[j].intValue &gt; array[j + 1].intValue) &#123; NSNumber *temp = array[j]; [array replaceObjectAtIndex:j withObject:array[j + 1]]; [array replaceObjectAtIndex:(j + 1) withObject:temp]; count ++; &#125; &#125; if (count == 0) &#123; return array; &#125; &#125; return array;&#125;// swift实现//MARK: - 冒泡排序func bubble_sort(array: [Int]) -&gt; [Int] &#123; if array.count == 0 &#123; return [] &#125; var newArray = array for i in 0..&lt;(newArray.count - 1) &#123; var count = 0 for j in 0..&lt;(newArray.count - 1 - i) &#123; if newArray[j] &gt; newArray[j + 1] &#123; let temp = newArray[j] newArray[j] = newArray[j + 1] newArray[j + 1] = temp count += 1 &#125; &#125; if count == 0 &#123; return newArray &#125; &#125; return newArray&#125; 选择排序选择排序（selection-sort）是一种简单直观的排序算法。 原理如下： 首先在未排序的数组中找到最小（大）的元素，存放到排序序列的起始位置。 然后在从剩余未排序的元素中继续寻找最小（大）元素，放到已排序序列的末尾。 以此类推，直到所有元素排序完毕。 图解如下： 动画示例：红色的表示当前最小值，黄色表示已排序元素，蓝色表示当前位置。 选择排序的主要优点与数据移动有关。如果某个元素位于正确的最终位置上，则它不会被移动。选择排序每次交换一对元素，他们当中至少有一个将被移到其最终位置上，因此对n个元素的数组进行排序总共进行至多n-1次交换。在所有的完全依靠交换去移动元素的排序方法中，选择排序是非常好的一种。 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//OC实现- (NSArray *)select_sort:(NSMutableArray &lt;NSNumber *&gt;*)array &#123; if (array.count == 0) &#123; return array; &#125; for (int i = 0; i &lt; array.count; i ++) &#123; int mix_index = i; for (int j = i + 1; j &lt; array.count; j ++) &#123; if (array[j].intValue &lt; array[mix_index].intValue) &#123; mix_index = j; &#125; &#125; NSNumber *temp = array[i]; [array replaceObjectAtIndex:i withObject:array[mix_index]]; [array replaceObjectAtIndex:mix_index withObject:temp]; &#125; return array;&#125;//swift实现//MARK: - 选择排序func select_sort(array: [Int]) -&gt; [Int] &#123; if array.count == 0 &#123; return [] &#125; var newArray = array for i in (0..&lt;newArray.count) &#123; var min_index = i for j in (i + 1)..&lt;newArray.count &#123; if newArray[j] &lt; newArray[min_index] &#123; min_index = j &#125; &#125; let temp = newArray[i] newArray[i] = newArray[min_index] newArray[min_index] = temp &#125; return newArray&#125; 插入排序插入排序：（insertion-sort）是一种简单直观的排序算法。它的工作原理是通过构建有序的序列。对于未排序的元素，在已排序的元素中从后向前扫描，找到相应的位置并插入。插入排序在实现上，在从后向前的扫描过程中，需要反复把已排序元素逐步向后挪位，为新元素提供插入空间。 图解如下： 示例动画如下： 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738// OC实现- (NSArray *)insert_sort:(NSMutableArray &lt;NSNumber *&gt;*)array &#123; if (array.count == 0) &#123; return @[]; &#125; for (int i = 1; i &lt; array.count; i ++) &#123; for (int j = i; j &gt; 0; j --) &#123; if (array[j - 1].intValue &gt; array [j].intValue) &#123; NSNumber *temp = array[j - 1]; [array replaceObjectAtIndex:j - 1 withObject:array[j]]; [array replaceObjectAtIndex:j withObject:temp]; &#125; &#125; &#125; return array;&#125;// swift实现//MARK: - 插入排序func insert_sort(array: [Int]) -&gt; [Int] &#123; if array.count == 0 &#123; return [] &#125; var newArray = array for i in (1..&lt;newArray.count) &#123; for j in (1...i).reversed() &#123; if newArray[j - 1] &gt; newArray[j] &#123; let temp = newArray[j - 1] newArray[j - 1] = newArray[j] newArray[j] = temp &#125; &#125; &#125; return newArray&#125; 快速排序快速排序：（quickSort）又称划分交换排序（partition-exchange sort），通过一趟排序将要排序的数据分割为独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达成整个数据变成有序数组。 步骤如下： 从数列中挑出一个元素，称为“基准”(pivot)。 重新排列数列，所有元素比基准值小的摆放在基准前面，所有的元素比基准值大的摆在基准的后面（相同的数可以到任意一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 递归的把小于基准元素的子数组和大于基准元素的子数组排序。 递归的最底部情形是，数列的大小是0或者1，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会结束，因为在每次的迭代（iteration）中，他至少会把一个元素摆到他最后的位置上。 图解如下： 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//OC代码/** 快速选择 @param array 快排之前的数组 @param start 开始的下标 @param end 结束的下标 @return 排序后的数组 */- (NSArray *)quick_sort:(NSMutableArray &lt;NSNumber *&gt;*)array startIndex:(int)start endIndex:(int)end &#123; if (start &gt;= end) &#123; return array; &#125; int left = start; int right = end; NSNumber *temp = array[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; array[right].intValue &gt;= temp.intValue) &#123; right --; &#125; array[left] = array[right]; while (left &lt; right &amp;&amp; array[left].intValue &lt; temp.intValue) &#123; left ++; &#125; array[right] = array[left]; &#125; array[left] = temp; [self quick_sort:array startIndex:0 endIndex:left - 1]; [self quick_sort:array startIndex:left + 1 endIndex:end]; return array;&#125;//Swift代码//MARK: - 快速排序func quick_sort(array: inout [Int], start: Int, end: Int) -&gt; [Int] &#123; if array.count == 0 &#123; return [] &#125; if start &gt;= end &#123; return [] &#125; var left = start var right = end let mid_value = array[left] while left &lt; right &#123; while (left &lt; right &amp;&amp; array[right] &gt;= mid_value) &#123; right -= 1 &#125; array[left] = array[right] while (left &lt; right &amp;&amp; array[left] &lt; mid_value) &#123; left += 1 &#125; array[right] = array[left] &#125; array[left] = mid_value quick_sort(array: &amp;array, start: start, end: left - 1) quick_sort(array: &amp;array, start: left + 1, end: end) return array&#125; 希尔排序希尔排序（shell sort）是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非常稳定的排序算法。该方法因DL. Shell于1959年提出而得名。希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 排序过程：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。 图解如下： 例如，假设有这样一组数[ 13 14 94 33 82 25 59 94 65 23 45 27 73 25 39 10 ]，如果我们以步长为5开始进行排序，我们可以通过将这列表放在有5列的表中来更好地描述算法，这样他们就应该看起来是这样(竖着的元素是步长组成)： 123413 14 94 33 8225 59 94 65 2345 27 73 25 3910 然后我们对每列进行排序： 123410 14 73 25 2313 27 94 33 3925 59 94 65 8245 将上述四行数字，依序接在一起时我们得到：[ 10 14 73 25 23 13 27 94 33 39 25 59 94 65 82 45 ]。这时10已经移至正确位置了，然后再以3为步长进行排序： 12345610 14 7325 23 1327 94 3339 25 5994 65 8245 排序之后变为： 12345610 14 1325 23 3327 25 5939 65 7345 94 8294 最后以1步长进行排序（此时就是简单的插入排序了） 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//OC代码- (NSArray *)shell_sort:(NSMutableArray &lt;NSNumber *&gt;*)array &#123; if (array.count == 0) &#123; return array; &#125; int T = @(array.count / 2).intValue; while (T) &#123; for (int i = T; i &lt; array.count; i ++) &#123; int j = i; while (j &gt;= T &amp;&amp; array[j - T].intValue &gt; array[j].intValue) &#123; NSNumber *temp = array[j - T]; [array replaceObjectAtIndex:j - T withObject:array[j]]; [array replaceObjectAtIndex:j withObject:temp]; j -= T; &#125; &#125; T /= 2; &#125; return array;&#125;//Swift代码func shell_sort(array: inout [Int]) -&gt; [Int] &#123; if array.count == 0 &#123; return [] &#125; var T: Int = array.count / 2 while T &gt; 0 &#123; for i in (T..&lt;array.count) &#123; var j = i while j &gt;= T &amp;&amp; (array[j - T] &gt; array[j]) &#123; let temp = array[j - T] array[j - T] = array[j] array[j] = temp j -= T &#125; &#125; T /= 2 &#125; return array&#125; 归并排序归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。将数组分解最小之后，然后合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了之后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另外一个数组的剩余部分复制过来即可。 归并排序分析图解： 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091//OC代码- (NSMutableArray &lt;NSNumber *&gt;*)merge_sort:(NSMutableArray &lt;NSNumber *&gt;*)array &#123; if (array.count &lt;= 1) &#123; return array; &#125; int mid_index = @(array.count / 2).intValue; NSMutableArray &lt;NSNumber *&gt;*left_array = [NSMutableArray array]; NSMutableArray &lt;NSNumber *&gt;*right_array = [NSMutableArray array]; for (int i = 0; i &lt; mid_index; i ++) &#123; [left_array addObject:array[i]]; &#125; for (int i = mid_index; i &lt; array.count; i ++) &#123; [right_array addObject:array[i]]; &#125; left_array = [self merge_sort:left_array]; right_array = [self merge_sort:right_array]; NSMutableArray &lt;NSNumber *&gt;*result = [NSMutableArray array]; int left_index = 0; int right_index = 0; while (left_index &lt; left_array.count &amp;&amp; right_index &lt; right_array.count) &#123; if (left_array[left_index].intValue &gt; right_array[right_index].intValue) &#123; [result addObject:right_array[right_index]]; right_index ++; &#125; else &#123; [result addObject:left_array[left_index]]; left_index ++; &#125; &#125; for (int i = left_index; i &lt; left_array.count; i ++) &#123; [result addObject:left_array[i]]; &#125; for (int i = right_index; i &lt; right_array.count; i ++) &#123; [result addObject:right_array[i]]; &#125; return result;&#125;//swift代码//MARK: - 归并排序func merge_sort(array: inout [Int]) -&gt; [Int] &#123; if array.count &lt;= 1 &#123; return array &#125; let mid = array.count / 2 var left_array: [Int] = [] for i in (0..&lt;mid) &#123; left_array.append(array[i]) &#125; var right_array: [Int] = [] for i in (mid..&lt;array.count) &#123; right_array.append(array[i]) &#125; left_array = merge_sort(array: &amp;left_array) right_array = merge_sort(array: &amp;right_array) var result: [Int] = [] var left_p = 0 var right_p = 0 while left_p &lt; left_array.count &amp;&amp; right_p &lt; right_array.count &#123; if left_array[left_p] &lt; right_array[right_p] &#123; result.append(left_array[left_p]) left_p += 1 &#125; else &#123; result.append(right_array[right_p]) right_p += 1 &#125; &#125; for i in (left_p..&lt;left_array.count) &#123; result.append(left_array[i]) &#125; for i in (right_p..&lt;right_array.count) &#123; result.append(right_array[i]) &#125; return result&#125; 常见的算法这么多，想了解更多的算法和数据结构的可以去看看相关的书籍比如《算法导论》、《数据结构与算法python语言描述》等。本文代码地址点这里","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/数据结构/"}],"tags":[{"name":"常见算法","slug":"常见算法","permalink":"http://yoursite.com/tags/常见算法/"}]},{"title":"数据结构算法之 链表","slug":"2018-03-15-linkList","date":"2018-03-14T16:00:00.000Z","updated":"2019-07-22T08:47:51.883Z","comments":true,"path":"2018-03-15-linkList/","link":"","permalink":"http://yoursite.com/2018-03-15-linkList/","excerpt":"","text":"链表链表概念链表是一种数据结构，和数组同级。比如，java中我们使用的ArrayList，其实现原理是数组。而LinkedList的实现原理就是链表了。链表在进行循环遍历的效率不高，但是插入和删除时优势明显。链表就是链式存储的线性表。根据指针域的不同，链表分为单向链表，双向链表，循环链表等等。 单向节点链表中最简单的一种就是单向链表，它包含两个域，一个信息域和一个指针域。这个链表指向链表中的下一个节点，而最后一个节点则指向一个空值。单向链表是一种线性表，实际上是由节点(Node)组成的，一个链表拥有不定数量的节点。其数据在内存中存储是不连续的，它存储的数据分散在内存中，每个节点只能也只有它能知道下一个节点的存储位置。由N个节点(Node)组成单向链表，每一个节点记录本节点的数据和下一个节点。向外暴露的只有一个头节点(Head)，我们对联标的所有操作，都是直接或者间接的通过其头节点来进行的。上图中最左边的节点即为头节点(Head)，但是添加节点的顺序是从右向左的，添加的新节点会被作为新节点。最先添加的节点对下一节点的引用可以为空。引用是引用下一节点而非下一个节点的对象。因为有着不断地引用，所以头节点就可以操作所有的节点了。下图描述了单向链表存储情况。存储是分散的，每一个节点只要记录下一节点，就把所有数据串了起来，形成一个单向链表。节点是由一个需要存储的对象及对下一个节点的引用组成的。也就是说，节点拥有两个成员：存储的对象、对下一个节点的引用。如下图： 双向链表双向链表是一种更复杂的链表。每个节点有两个连接：一个指向前一个节点，(当此”连接”为第一个”连接”时，指向空值或者空列表)；而当另一个指向下一个节点，(当此“连接”为最后一个“连接”时，指向空值或者空列表)一个双向链表有三个整数值：数值，向后的节点链接，向前的节点链接。双向链表也叫双链表。双向链表中不仅有指向后一个节点的指针，还有指向前一个节点的指针。这样就可以从任何一个节点访问前一个节点，当然也可以访问后一个节点么，以至整个链表。一般是在需要大批量的另外储存数据在链表中的位置的时候用。双向链表也可以配合下面的其他链表的扩展使用。由于另外储存了指向链表内容的指针，并且可能会修改相邻的节点，有的时候第一个节点可能会被删除或者在之前添加一个新的节点。这时候就要修改指向首个节点的指针。有一种方便的可以消除这种特殊情况的方法是在最后一个节点之后、第一个节点之前储存一个永远不会被删除或者移动的虚拟节点，形成一个下面说的循环链表。这个虚拟节点之后的节点就是真正的第一个节点。这种情况通常可以用这个虚拟节点直接表示这个链表，对于把链表单独的存在数组里的情况，也可以直接用这个数组表示链表并用第0个或者第-1个(如果编译器支持)节点固定的表示这个虚拟节点。 循环链表在一个循环链表中，首节点和末节点被连接在一起。这种方式在单向和双向链表中皆可实现。要转换一个循环链表，你开始于任意一个节点然后沿着列表的任一方向知道返回开始的节点。再来看另一种方法，循环链表可以被视为“无头无尾”。这种列表很利于节约数据存储缓存，假定你在一个列表中有一个对象并且希望所有其他对象迭代在一个非特殊的排列下。指向整个列表的指针可以被称作存储指针。如上图用单向链表构建的循环链表。循环链表中第一个节点就是最后一个节点，反之亦然。循环链表的无边界使得在这样的链表上设计算法会比普通链表更加容易。对于新加入的节点应该是在第一个节点之前还是最后一个节点之后可以根据实际要求灵活处理，区别不大。当然，如果只会在最后插入数据(或者只会在之前)，处理也很容易。另外一种模拟的循环链表，就是在访问到最后一个节点之后的时候，手动跳转到第一个节点。访问到第一个节点之前的时候，也一样。这样也可以实现循环链表的功能，在直接用循环链表比较麻烦或者可能会出现问题的时候可以用。 存储结构链表中的节点不需要以特定的方式存储，但是集中存储也是可以的，主要分下面几种具体的存储方法： 共用存储空间：链表的节点和其他的数据共用存储空间，优点是可以存储无限多的内容(不过要处理器支持这个大小，并且存储空间足够的情况下)，不需要提前分配内存；缺点是由于内容分散，有时候可能不方便调试。 独立存储空间：一个链表或者多个链表使用独立的存储空间，一般用数组或者类似结构实现，优点是可以自动获得一个附加数据：唯一的编号，并且方便调试；缺点是不能动态的分配内存。当然，另外的在上面加一层块状链表用来分配内存也是可以的，这样就解决了这个问题。这种方法有时候被叫做数组模拟链表，但是事实上只是用表示在数组中的位置的下标索引代替了指向内存地址的指针，这种下标索引其实也是逻辑上的指针，整个结构还是链表，并不算是被模拟的(但是可以说成是用数组实现的链表)。 链表的几大特性链表主要有以下几个特性： 解决数组无法存储多种数据类型的问题 解决数组中，元素个数无法改变的限制 数组移动元素的过程中，要对元素进行大范围的移动，很耗时间，效率也不高。 链表的应用连表用来构建许多其他的数据结构，如堆栈，行列和他们的衍生。节点的数据域，也可以成为另一个链表。通过这种手段，我们可以用列表来构建许多链性数据结构；这个实例产生于Lisp编程语言，在Lisp中链表是初级数据结构，并且成为了常见的基础编程模式。有时候，链表用来生成联合数组，在这种情况下我们称之为联合数列。这种情况下用链表会优于其他数据结构，如自平衡二叉查找树(self-balancing binary search trees)甚至是一些小的数据集合。不管怎样，一些时候一个链表在这样一个树中建立一个节点子集，并且以此来更有效率的转换这个集合。 C代码实例链表的数据结构 1234struct list_node &#123; int data; //数据域，用于存储数据 struct list_node *next; //指针，可以用来访问节点数据，也可以遍历，指向下一个节点&#125;; 创建一个链表的一个节点 12345678910111213141516171819202122232425#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;struct list_node &#123; int data; struct list_node *next;&#125;;typedef struct list_node list_single;int main(void) &#123; list_single *node = NULL; //1、首先定义一个头指针 node = (list_single *)malloc(sizeof(list_single)); //2、然后分配内存空间 if (node == NULL) &#123; printf(&quot;malloc fair!\\n&quot;); &#125; memset(node, 0, sizeof(list_single)); //3、清一下 node-&gt;data = 100; //4、给链表节点的数据赋值 node-&gt;next = NULL; //5、将链表的指针域指向空 printf(&quot;%d\\n&quot;, node-&gt;data); free(node); return 0;&#125; 把创建节点封装成一个函数 123456789101112131415list_single *create_list_node(int data) &#123; list_single *node = NULL; //1、首先定义一个头指针 node = (list_single *)malloc(sizeof(list_single)); //2、然后分配内存空间 if (node == NULL) &#123; printf(&quot;malloc fair!\\n&quot;); &#125; memset(node, 0, sizeof(list_single)); //3、清一下 node-&gt;data = data; //4、给链表节点的数据赋值 node-&gt;next = NULL; //5、将链表的指针域指向空 printf(&quot;%d\\n&quot;, node-&gt;data); free(node); return 0;&#125; 接着完成上面的程序 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;struct list_node &#123; int data; struct list_node *next;&#125;;typedef struct list_node list_single;list_single *create_list_node(int data) &#123; list_single *node = NULL; //1、首先定义一个头指针 node = (list_single *)malloc(sizeof(list_single)); //2、然后分配内存空间 if (node == NULL) &#123; printf(&quot;malloc fair!\\n&quot;); &#125; memset(node, 0, sizeof(list_single)); //3、清一下 node-&gt;data = data; //4、给链表节点的数据赋值 node-&gt;next = NULL; //5、将链表的指针域指向空 printf(&quot;%d\\n&quot;, node-&gt;data); free(node); return 0;&#125;int main(void) &#123; int data = 100; list_single *node = create_list_node(data); printf(&quot;node-&gt;data = %d\\n&quot;, node-&gt;data); printf(&quot;node-&gt;next = %d\\n&quot;, node-&gt;next); free(node); return 0;&#125; 执行结果 范例代码是一个ADT（抽象数据类型）双向环形链表的基本操作部分的实例（未包含线程安全机制），全部遵从ANSI C标准，由User:JohnBull贡献，代码遵从GPL版权许可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111//声明接口#ifndef LLIST_H#define LLIST_Htypedef void node_proc_fun_t(void *);typedef int node_comp_fun_t(const void*, const void*);typedef void LLIST_T;LLIST_T *llist_new(int elmsize);int llist_delete(LLIST_T *);int llist_node_append(LLIST_T *, const void *);int llist_node_prepend(LLIST_T *, const void *);int llist_travel(LLIST_T *, node_proc_fun_t*);int llist_sort(LLIST_T *, node_comp_fun_t*);void *llist_node_delete(LLIST_T *, node_comp_fun_t *, const void *key);void *llist_node_find(LLIST_T *, node_comp_fun_t *, const void *key);//类型确定struct node_st&#123; void *datap; struct node_st *next, *prev;&#125;;struct llist_st&#123; struct node_st head; int elmsize; int elmnr;&#125;;//初始化和销毁LLIST_T *llist_new(int elmsize)&#123; struct llist_st *newlist; newlist = malloc(sizeof(struct llist_st)); if (newlist == NULL) &#123; return NULL; &#125; newlist -&gt; head.datap = NULL; newlist -&gt; head.next = &amp;newlist -&gt; head; newlist -&gt; head.prev = &amp;newlist -&gt; head; newlist -&gt; elmsize = elmsize; return (void *)newlist;&#125;int llist_delete(LLIST_T *ptr) &#123; struct llist_st *me = ptr; struct node_st *curr, *save; for (curr = me -&gt; head.next; curr != &amp;me -&gt; head; curr = save) &#123; save = curr -&gt; next; free(curr -&gt; datap); free(curr); &#125; free(me); return 0;&#125;//节点插入int llist_node_append(LLIST_T *ptr, const void *datap) &#123; struct llist_st *me = ptr; struct node_st *newnodep; newnodep = malloc(sizeof(struct node_st)); if (newnodep == NULL) &#123; return -1; &#125; newnodep -&gt; datap = malloc(me -&gt; elmsize); if (newnodep -&gt; datap == NULL) &#123; free(newnodep); return -1; &#125; memcpy(newnodep -&gt; datap, datap, me -&gt; elmsize); me -&gt; head.prev -&gt; next = newnodep; newnodep -&gt; prev = me -&gt; head.prev; me -&gt; head.prev = newnodep; newnodep -&gt; next = &amp;me -&gt; head; return 0;&#125;//遍历template&lt;class T&gt;class ChainIterator &#123; public: T* Initialize(const Chain&lt;T&gt; &amp;c) &#123; location = c.first; if (!location) return &amp;location -&gt; data; return 0; &#125; T *Next() &#123; if (!location) return 0; location = location -&gt; link; if (location) return &amp;location -&gt; data; return 0; &#125; private: ChainNode&lt;T&gt; *location;&#125; 以下代码摘自Linux内核2.6.21.5源码(部分)，展示了链表的另一种实现思路，未采用ANSI C标准，采用GNU C标准，遵从GPL版权许可： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647struct list_head &#123; struct list_head *next, *prev;&#125;; #define LIST_HEAD_INIT(name) &#123; &amp;(name), &amp;(name) &#125; #define LIST_HEAD(name) / struct list_head name = LIST_HEAD_INIT(name) static inline void INIT_LIST_HEAD(struct list_head *list) &#123; list-&gt;next = list; list-&gt;prev = list;&#125; static inline void __list_add(struct list_head *new, struct list_head *prev, struct list_head *next)&#123; next-&gt;prev = new; new-&gt;next = next; new-&gt;prev = prev; prev-&gt;next = new;&#125; static inline void list_add(struct list_head *new, struct list_head *head) &#123; __list_add(new, head, head-&gt;next);&#125; static inline void __list_del(struct list_head * prev, struct list_head * next) &#123; next-&gt;prev = prev; prev-&gt;next = next;&#125; static inline void list_del(struct list_head *entry) &#123; __list_del(entry-&gt;prev, entry-&gt;next); entry-&gt;next = NULL; entry-&gt;prev = NULL;&#125; #define __list_for_each(pos, head) / for (pos = (head)-&gt;next; pos != (head); pos = pos-&gt;next) #define list_for_each_entry(pos, head, member) / for (pos = list_entry((head)-&gt;next, typeof(*pos), member); / prefetch(pos-&gt;member.next), &amp;pos-&gt;member != (head); / pos = list_entry(pos-&gt;member.next, typeof(*pos), member)) python代码的实现单向链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101class SingleNode(object): &quot;&quot;&quot;单链表的节点&quot;&quot;&quot; def __init__(self, element): self.elem = element self.next = Noneclass SingleLinkedList(object): &quot;&quot;&quot;单链表&quot;&quot;&quot; def __init__(self, node = None): self._head = node def is_empty(self): &quot;&quot;&quot;判断是否为空&quot;&quot;&quot; return self._head == None def length(self): &quot;&quot;&quot;返回链表的长度&quot;&quot;&quot; # cur游标 用来遍历节点 cur = self._head # count 记录数量 count = 0 while cur != None: count += 1 cur = cur.next return count def travel(self): &quot;&quot;&quot;遍历整个链表&quot;&quot;&quot; # cur游标 用来遍历节点 cur = self._head while cur != None: print (cur.elem) cur = cur.next def add(self, item): &quot;&quot;&quot;链表头部添加元素&quot;&quot;&quot; node = SingleNode(item) node.next = self._head self._head = node def append(self, item): &quot;&quot;&quot;链表尾部添加元素&quot;&quot;&quot; node = SingleNode(item) if self.is_empty(): self._head = node else: cur = self._head while cur.next != None: cur = cur.next cur.next = node def insert(self, pos, item): &quot;&quot;&quot;指定位置添加元素&quot;&quot;&quot; if pos &lt;= 0: self.add(item) elif pos &gt; (self.length() - 1): self.append(item) else: pre = self._head count = 0 while count &lt;= (pos - 1): count += 1 pre = pre.next # 当循环结束后，pre指向pos-1的位置 node = SingleNode(item) node.next = pre.next pre.next = node def remove(self, item): &quot;&quot;&quot;删除节点&quot;&quot;&quot; cur = self._head pre = None while cur != None: if cur.elem == item: if cur == self._head: self._head = cur.next else: pre.next = cur.next break else: pre = cur cur = cur.next def search(self, item): &quot;&quot;&quot;查找节点是否存在&quot;&quot;&quot; cur = self._head while cur != None: if cur.elem == item: return True else: cur = cur.next return False 双向链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107class Node(object): &quot;&quot;&quot;结点&quot;&quot;&quot; def __init__(self, item): self.elem = item self.next = None self.prev = Noneclass DoubleLinkedList(object): &quot;&quot;&quot;双链表&quot;&quot;&quot; def __init__(self, node=None): self._head = node def is_empty(self): &quot;&quot;&quot;判断是否为空&quot;&quot;&quot; return self._head == None def length(self): &quot;&quot;&quot;返回链表的长度&quot;&quot;&quot; # cur游标 用来遍历节点 cur = self._head # count 记录数量 count = 0 while cur != None: count += 1 cur = cur.next return count def travel(self): &quot;&quot;&quot;遍历整个链表&quot;&quot;&quot; # cur游标 用来遍历节点 cur = self._head while cur != None: print (cur.elem) cur = cur.next def add(self, item): &quot;&quot;&quot;链表头部添加元素&quot;&quot;&quot; node = Node(item) node.next = self._head self._head = node node.next.prev = node def append(self, item): &quot;&quot;&quot;链表尾部添加元素&quot;&quot;&quot; node = Node(item) if self.is_empty(): self._head = node else: cur = self._head while cur.next != None: cur = cur.next cur.next = node node.prev = cur def insert(self, pos, item): &quot;&quot;&quot;指定位置添加元素&quot;&quot;&quot; if pos &lt;= 0: self.add(item) elif pos &gt; (self.length() - 1): self.append(item) else: cur = self._head count = 0 while count &lt;= pos: count += 1 cur = cur.next # 当循环结束后，pre指向pos-1的位置 node = Node (item) node.next = cur node.prev = cur.prev cur.prev.next = node cur.prev = node def remove(self, item): &quot;&quot;&quot;删除节点&quot;&quot;&quot; cur = self._head while cur != None: if cur.elem == item: if cur == self._head: self._head = cur.next if cur.next: #判断链表是否只有一个节点 cur.next.prev = None else: cur.prev.next = cur.next if cur.prev.next: cur.next.prev = cur.prev break else: cur = cur.next def search(self, item): &quot;&quot;&quot;查找节点是否存在&quot;&quot;&quot; cur = self._head while cur != None: if cur.elem == item: return True else: cur = cur.next return False 单向链表实现的循环链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149class SingleNode(object): &quot;&quot;&quot;单链表的节点&quot;&quot;&quot; def __init__(self, element): self.elem = element self.next = Noneclass SingleCycleLinkedList(object): &quot;&quot;&quot;单向循环链表&quot;&quot;&quot; def __init__(self, node = None): self._head = node if node: node.next = node def is_empty(self): &quot;&quot;&quot;判断是否为空&quot;&quot;&quot; return self._head == None def length(self): &quot;&quot;&quot;返回链表的长度&quot;&quot;&quot; if self.is_empty(): return 0 # cur游标 用来遍历节点 cur = self._head # count 记录数量 count = 1 while cur.next != self._head: count += 1 cur = cur.next return count def travel(self): &quot;&quot;&quot;遍历整个链表&quot;&quot;&quot; # cur游标 用来遍历节点 cur = self._head while cur.next != self._head: print (cur.elem) cur = cur.next # 退出循环，打印尾节点 print (cur.elem) def add(self, item): &quot;&quot;&quot;链表头部添加元素&quot;&quot;&quot; node = SingleNode(item) if self.is_empty(): self._head = node node.next = node return cur = self._head while cur.next != self._head: cur = cur.next node.next = self._head self._head = node cur.next = node def append(self, item): &quot;&quot;&quot;链表尾部添加元素&quot;&quot;&quot; node = SingleNode(item) if self.is_empty(): self._head = node node.next = node else: cur = self._head while cur.next != self._head: cur = cur.next cur.next = node node.next = self._head def insert(self, pos, item): &quot;&quot;&quot;指定位置添加元素&quot;&quot;&quot; if pos &lt;= 0: self.add(item) elif pos &gt; (self.length() - 1): self.append(item) else: pre = self._head count = 0 while count &lt;= (pos - 1): count += 1 pre = pre.next # 当循环结束后，pre指向pos-1的位置 node = SingleNode(item) node.next = pre.next pre.next = node def remove(self, item): &quot;&quot;&quot;删除节点&quot;&quot;&quot; if self.is_empty(): return cur = self._head pre = None while cur.next != self._head: if cur.elem == item: if cur == self._head: # 头节点情况 # 找尾节点 rear = self._head while rear.next != self._head: rear = rear.next self._head = cur.next rear.next = self._head else: pre.next = cur.next return else: pre = cur cur = cur.next # 退出循环，cur指向尾节点 if cur.elem == item: if cur == self._head: # 链表只有一个节点 self._head = None else: pre.next = cur.next def search(self, item): &quot;&quot;&quot;查找节点是否存在&quot;&quot;&quot; if self.is_empty(): return False cur = self._head while cur.next != self._head: if cur.elem == item: return True else: cur = cur.next if cur.elem == item: return True return False 只要弄懂了链表的原理，其实不管用什么语言实现，只不过是一种描述方式而已。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/数据结构/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://yoursite.com/tags/链表/"}]},{"title":"记录Photos框架的使用","slug":"2018-01-30-new","date":"2018-01-29T16:00:00.000Z","updated":"2019-07-22T08:47:51.842Z","comments":true,"path":"2018-01-30-new/","link":"","permalink":"http://yoursite.com/2018-01-30-new/","excerpt":"","text":"记录Photos框架的使用前言这几天项目里用到了图片选择器，就想把之前项目里用ALAssetsLibrary框架封装的图片选择器拿过来用，但是ALAssetsLibrary框架在9.0之后就被弃用了。所以，就要试试Photos框架了。在网上找了几篇blog研究了一下，就搞了起来。期间也踩了几个坑，所以开篇记录一下。 第一波 获取用户相册先介绍一些概念，大家可以参考一下这篇blog PHAsset：代表照片库中的一个资源，跟 ALAsset 类似，通过 PHAsset 可以获取和保存资源 PHFetchOptions：获取资源时的参数，可以传 nil，即使用系统默认值 PHFetchResult：表示一系列的资源集合，也可以是相册的集合 PHAssetCollection：表示一个相册或者一个时刻，或者是一个「智能相册（系统提供的特定的一系列相册，例如：最近删除，视频列表，收藏等等，如下图所示） PHImageManager：用于处理资源的加载，加载图片的过程带有缓存处理，可以通过传入一个 PHImageRequestOptions 控制资源的输出尺寸等规格 PHImageRequestOptions：如上面所说，控制加载图片时的一系列参数 先上一段获取相册的代码： 123456789101112131415161718//所有智能相册 let smartAlbums = PHAssetCollection.fetchAssetCollections(with: .smartAlbum, subtype: .albumRegular, options: nil) weak var weakSelf = self DispatchQueue.global().async &#123; smartAlbums.enumerateObjects(&#123; (collection, index, stop) in if (collection.isKind(of: PHAssetCollection.self)) &#123; if (collection.localizedTitle == &quot;Recently Added&quot; || collection.localizedTitle == &quot;All Photos&quot;) &#123; weakSelf?.allAlbums.append(collection) &#125; &#125; &#125;) DispatchQueue.main.async &#123; weakSelf?.tableView?.reloadData() &#125; &#125; 上述方法中的第一第二个参数的类型介绍： PHAssetCollectionType有三个值： album：自定义相册，例如：QQ smartAlbum：相机胶卷、我的照片流、屏幕截图、全景照片等 moment：时刻 PHAssetCollectionSubtype一些值： albumRegular：用户在Photos中创建的相册，也就是我所谓的逻辑相册 albumSyncedEvent：使用iTunes从Photos照片库或者iPhoto照片库同步过来的事件。然而，在iTunes 12以及iOS 9.0 beta4上，选用该类型没法获取同步的事件相册，而必须使用AlbumSyncedAlbum。 albumSyncedFaces：使用iTunes从Photos照片库或者iPhoto照片库同步的人物相册。 albumSyncedAlbum：做了AlbumSyncedEvent应该做的事 albumImported：从相机或是外部存储导入的相册，完全没有这方面的使用经验，没法验证。 从上面的方法中我们可以获取到用户相关的相册，collection.localizedTitle获取相册名字，对应的中英文对照如下： 1234567891011121314[&quot;Slo-mo&quot; : &quot;慢动作&quot;, &quot;Recently Added&quot; : &quot;最近添加&quot;, &quot;Favorites&quot; : &quot;个人收藏&quot;, &quot;Recently Deleted&quot; : &quot;最近删除&quot;,&quot;Videos&quot; : &quot;视频&quot;,&quot;All Photos&quot; : &quot;所有照片&quot;,&quot;Selfies&quot; : &quot;自拍&quot;,&quot;Screenshots&quot; : &quot;屏幕快照&quot;,&quot;Camera Roll&quot; : &quot;相机胶卷&quot;,&quot;Panoramas&quot; : &quot;全景照片&quot;,&quot;Hidden&quot; : &quot;已隐藏&quot;,&quot;Time-lapse&quot; : &quot;延时拍摄&quot;,&quot;Bursts&quot; : &quot;连拍快照&quot;.&quot;Depth Effect&quot; : &quot;景深效果&quot;] 第二波 获取相册中的资源先来一波代码： 123456789101112131415let options = PHFetchOptions()options.sortDescriptors = [NSSortDescriptor.init(key: &quot;creationDate&quot;, ascending: true)]options.predicate = NSPredicate.init(format: &quot;mediaType == %ld&quot;, PHAssetMediaType.image.rawValue)let fetchResult = PHAsset.fetchAssets(in: phCollection!, options: options) weak var weakSelf = selfDispatchQueue.global().async &#123; fetchResult.enumerateObjects &#123; (asset, index, stop) in weakSelf?.dataSource.append(asset) &#125; DispatchQueue.main.async &#123; ... &#125;&#125; 代码中，通过谓词NSPredicate筛选出所有的照片资源。PHAssetMediaType有四个值： unknown：未知 image：图片 video：视频 audio：音频 PHAsset代表照片库中的一个资源，跟ALAsset类似，通过PHAsset我们可以获取和保存资源。打印asset显示包含如下信息： 第三波 获取相册里的图片废话不多说，直接上代码 123456789101112131415DispatchQueue.global().async &#123; let requestOptions = PHImageRequestOptions() requestOptions.resizeMode = .fast weak var weakSelf = self let manager = PHImageManager.default() manager.requestImage(for: asset, targetSize: self.getTargetSize(), contentMode: .aspectFit, options: requestOptions, resultHandler: &#123; (image, dic) in DispatchQueue.main.async &#123; if image != nil &#123; weakSelf?.imgView.image = image ... &#125; &#125; &#125;) &#125; 图片的获取是通过PHImageManager来获得，在这里遇到了一个坑，在网上普遍看到的写法如下： 12345678910111213141516DispatchQueue.global().async &#123; let requestOptions = PHImageRequestOptions() requestOptions.deliveryMode = .highQualityFormat requestOptions.isSynchronous = true //requestOptions.isNetworkAccessAllowed = true weak var weakSelf = self let manager = PHImageManager.default() manager.requestImage(for: asset, targetSize: PHImageManagerMaximumSize, contentMode: .aspectFit, options: requestOptions, resultHandler: &#123; (image, dic) in DispatchQueue.main.async &#123; if image != nil &#123; weakSelf?.imgView.image = image weakSelf?.kXZFImage = image &#125; &#125; &#125;)&#125; 代码中不包含requestOptions.isNetworkAccessAllowed = true此句代码，在模拟器上获取到了图片，但是在真机上调试的时候，打印出来的image = nil，很是纳闷，然后各种搜索查代码，然后把targetSize，给替换成了一个固定的值，结果打印出来的图片尺寸全部都是一样，并不是原图。最后又是各种尝试，查找资料，发现一篇文章里的代码包含这一句requestOptions.isNetworkAccessAllowed = true代码，然后再去尝试，发现获取原图成功了。应该是PHImageManager需要从Apple方获取原图。如果想获取自定义的图片尺寸，就按照第一种写法，可以快速的获取到图片。如果想获取原图，就需要按照第二种写法，获取，把注释掉的代码释放出来，这样有一个问题就是，相册图片比较多，图片比较大的时候，加载会比较慢。 第一种写法的requestOptions.resizeMode有三个可选项 none // no resize 不重设size fast // use targetSize as a hint for optimal decoding when the source image is a compressed format (i.e. subsampling), the delivered image may be larger than targetSize （当源图像是压缩格式(即次采样)时，使用Target Size作为最佳解码提示时，交付的图像可能大于Target Size） exact // same as above but also guarantees the delivered image is exactly targetSize (must be set when a normalizedCropRect is specified) （与上面相同，但也保证交付的图像是准确的目标大小(必须在指定了规范化的CropRect时设置)） 第二种写法的requestOptions.deliveryMode opportunistic // client may get several image results when the call is asynchronous or will get one result when the call is synchronous （当调用是异步的时，客户端可能会得到多个映像结果，或者在调用是同步的时候会得到一个结果。） highQualityFormat // client will get one result only and it will be as asked or better than asked (sync requests are automatically processed this way regardless of the specified mode)（客户端将只获得一个结果，并且它将被问到或者比被请求的结果更好(同步请求将以这种方式自动处理，而不管指定的模式如何)。） fastFormat // client will get one result only and it may be degraded （客户端只会得到一个结果，并且可能会降级。） 具体的详解，可以看开篇提到的这篇blog，有系列的介绍。本次遇到的坑就是这些，记录一下，以防下次再踩。结尾，谢谢网上各位的分享，让知识传播起来。本文源码请戳这里","categories":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/categories/iOS/"}],"tags":[{"name":"Photos","slug":"Photos","permalink":"http://yoursite.com/tags/Photos/"}]},{"title":"iOS深入学习 - Socket","slug":"2017-11-14-socket","date":"2017-11-13T16:00:00.000Z","updated":"2019-07-24T04:02:58.401Z","comments":true,"path":"2017-11-14-socket/","link":"","permalink":"http://yoursite.com/2017-11-14-socket/","excerpt":"","text":"网络各个协议：TCP/IP、socket、Http等网络七层由上而下分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。其中物理层、数据链路层和网络层通常被称作媒体层，是网络工程师所研究的对象；传输层、会话层、表示层和应用层被称为主机层，是用户所面向和关心的内容。 http协议对应于应用层 TCP协议对应于传输层 ip协议对应于网络层 三者本质上没有可比性，何况Http协议是基于TCP连接的。 TCP/IP是传输层协议，主要解决数据如何在网络中传输的；而Http是应用层协议，主要解决如何包装数据。 我们在传输数据时，可以使用传输层(TCP/IP)，但是那样的话，由于没有应用层，便无法识别数据内容，如果想要使传输数据有意义，则必须使用应用层协议。应用层协议很多，有HTTP，FTP，TELNET等等，也可以自己定义应用层协议。WEB使用HTTP作应用层协议，以封装HTTP文本信息。然后使用TCP/IP做传输层协议将它发送到网络上。Socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口(API)，通过Socket，我们才能使用TCP/IP协议。 Http和Socket连接区别TCP连接要想明白Socket连接，先要明白TCP连接。手机能够使用互联网功能是因为手机底层实现了TCP/IP协议，可以使手机终端通过无线网络建立TCP连接。TCP协议可以对上层网络提供接口，使上层网络数据的传输建立在“无差别”的网络之上。建立一个TCP连接需要经过“三次握手”： 第一次握手：客户端发送syn包(syn = j)到服务器，并进入SYN_SEND状态，等待服务器确认； 第二次握手：服务器接收syn包，必须确认客户的SYN(ack = j + 1)，同时自己也发送一个SYN包(syn = k)，即SYN + ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN + ACK包，向服务器发送确认包ACK(ack = k + 1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。 握手过程中传送的包里不包含数据，三次握手结束后，客户端与服务器才正式开始传输数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP连接都将被一直保持下去。断开连接时服务器和客户端均可以主动发起断开TCP连接的请求，断开过程需要经过“四次握手”。 TCP连接的拆除需要发送四个包，因此称为四次握手(four-way handshake)。在socket编程中，任何一方执行close()操作即可产生握手（有地方称为“挥手”）操作。 之所以有“三次握手”和“四次握手”的区别，是因为连接时当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 HTTP协议http协议即超文本传输协议(Hypertext Transfer Protocol)，是web联网的基础，也是手机联网常用的协议之一，http协议是建立在TCP协议之上的一种应用。http连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为“一次连接”。 在http 1.0中，客户端每次请求都要求建立一次单独的连接，在处理完本次请求后，就自动释放连接。 在http 1.1中，则可以在一次连接中处理多个请求，并且多个请求可以重叠进行，不需要等待一个请求结束后再发送下一个请求。 由于http在每次请求结束后都会主动释放连接，因此http连接是一种“短连接”，要保持客户端程序的在线状态，需要不断的向服务器发起连接请求。通常的做法是即使不需要获得任何数据，客户端也保持每隔一段固定的时间向服务器发送一次“保持连接”的请求，服务器在收到该请求后对客户端进行回复，表明知道客户端在线。若服务器长时间无法收到客户端的请求，则认为客户端“下线”，若客户端长时间无法收到服务器的回复，则认为网络已经断开。 Socket原理套接字(socket)概念套接字(socket)是通信的基石，是支持TCP/IP协议的网络通信的基本单元。通讯示意图： 通讯原理图： 它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议、本地主机的IP地址、本地进程的协议端口、远地主机的IP地址、远地进程的协议端口。 应用层通过传输层进行数据通信时，TCP会遇到同时为多个应用程序进程提供并发服务的问题。多个TCP连接或多个应用程序进程可能需要通过同一个TCP协议端口传输数据。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP/IP协议交互提供了套接字(socket)接口。应用层和传输层通过socket接口，区分来自不同应用程序进程或者网络连接的通信，实现数据传输的并发服务。 建立socket连接建立socket连接至少需要一对套接字，其中一个运行于客户端，称为ClientSocket，另一个运行于服务器端，称为ServerSocket。套接字之间的连接分为三个步骤： 服务器监听 客户端请求 连接确认 服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述他要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后向服务器端套接字提出连接请求。连接确认：当服务器端套接字监听或者说接受到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，双方就正式建立连接。而服务器端套接字继续处于监听状态，继续接受其他客户端套接的连接请求。 socket连接与TCP连接创建socket连接时，可以指定使用的传输层协议，socket可以支持不同的传输层协议(TCP或UDP),当使用TCP协议进行连接时，该socket连接就是一个TCP连接。 socket连接与http连接由于通常情况下socket连接就是TCP连接，因此socket连接一旦建立，通信双方即可开始相互发送数据内容，知道双方连接断开。但在实际网络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致socket连接断开，因此需要通过轮询告诉网络，该连接处于活跃状态。 而http连接使用的是“请求-响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务端才能回复数据。 很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是socket连接，服务器就可以直接将数据传送给客户端；若双方建立的是http连接，则服务器需要等到客户端发送一次请求后才能将数据传回客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。 注意： 1、服务器返回数据不一定是一次性就返回完的，可能是一点一点的返回的，所以我们接收数据时需要创建一个循环，循环的去接收服务器每次返回到客户端的数据。 2、当最后一次返回数据为0时，说明数据已经返回完成了。 3、使用socket就不需要设置ATS。因为socket是底层实现的。 socket使用步骤 创建客户端socket 连接到服务器socket 客户端socket发送数据到服务器socket 客户端socket接收服务器返回的数据 关闭客户端socket 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#import &quot;ViewController.h&quot;#import &lt;sys/socket.h&gt;#import &lt;netinet/in.h&gt;#import &lt;arpa/inet.h&gt;@interface ViewController ()@end@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad]; //1、创建客户端socket /** 参数 参数1:domain，协议域/协议簇，AF_INET(IPV4的网络开发) 参数2:type，socket类型，SOCK_STREAM(TCP)/SOCK_DGRAM(UDP，报文) 参数3:protocol，IPPROTO_TCP,协议，如果输入0，可以根据第二个参数，自动选择协议 返回值 int类型，如果&gt;0,就表示创建客户端socket成功，返回socket */ int clientSocket = socket(AF_INET, SOCKET_STREAM, 0); if (clientSocket &gt; 0) &#123; NSLog(@&quot;创建客户端socket成功&quot;); &#125; //2、客户端socket连接到服务器的socket /** 参数： 参数1:客户端socket 参数2:指向数据结构sockaddr的指针，其中包括目的端口和IP地址，服务器的“结构体”地址。提示：C语言中没有对象。 参数3:结构体数据长度 返回值 0 成功/其他 错误代码，(不是非0即真) */ struct sockaddr_in addr; addr.sin_family = AF_INET; addr.sin_port = htons(80); addr.sin_addr.s_addr = inet_addr(&quot;119.75.217.109&quot;); int isConnected = connect(clientSocket, (const struct sockaddr *)&amp;addr, sizeof(addr)); if (isConnected == 0) &#123; NSLog(@&quot;连接到服务器成功&quot;); &#125; //3、客户端socket向服务器socket发送请求 /** 参数： 参数1:客户端socket 参数2:发送内容地址 void * == id 参数3:发送内容长度 参数4:发送方式标志，一般为0 返回值 如果成功，则返回发送的字节数，失败则返回SOCKET_ERROR */ NSString *sendMsg = @&quot;GET / HTTP/1.1\\r\\n&quot; &quot;Host: www.baidu.com\\r\\n&quot; &quot;User-Agent: iphone\\r\\n&quot; &quot;Connection: close\\r\\n\\r\\n&quot; ; ssize_t sendCount = send(clientSocket, sendMsg.UTF8String, strlen(sendMsg.UTF8String), 0); NSLog(@&quot;发送字符数 %ld&quot;,sendCount); //4、客户端socket接收服务器socket发送的数据(响应) /** 参数： 参数1：客户端socket 参数2：接收内容缓存区地址 参数3：接收内容缓存区长度 参数4：接收方式，0表示阻塞，必须等待服务器返回数据 返回值 如果返回成功，则返回读入的字节数，失败则返回SOCKET_ERROR 提示：服务器发送给客户端数据时，是一点一点发送的 提示：当服务器把数据都发送完了以后，再次发送时，只发送0字节 */ //创建接收服务器发送的数据的容器 / 缓冲区，并且指定了容器 uint8_t buffer[1024]; //需要创建一个容器 NSMutableData *dataM = [NSMutableData data]; //循环的接收服务器发送的数据 ssize_t recvCount = -1; while (recvCount != 0) &#123; //只接收了一次 recvCount = recv(clientSocket, buffer, sizeof(buffer), 0); NSLog(@&quot;接收的内容数 %ld&quot;, recvCount); [dataM appendBytes: buffer, length: recvCount]; &#125; NSString *html = [[NSString alloc] initWithData: dataM encoding: NSUTF8StringEncoding]; NSLog(@&quot;%@&quot;, html); //5、关闭socket close(clientSocket[]());&#125;@end","categories":[{"name":"iOS 深入学习","slug":"iOS-深入学习","permalink":"http://yoursite.com/categories/iOS-深入学习/"}],"tags":[{"name":"Socket","slug":"Socket","permalink":"http://yoursite.com/tags/Socket/"}]},{"title":"iOS深入学习 - Runtime","slug":"2017-10-20-runtime","date":"2017-10-19T16:00:00.000Z","updated":"2019-07-24T04:03:12.097Z","comments":true,"path":"2017-10-20-runtime/","link":"","permalink":"http://yoursite.com/2017-10-20-runtime/","excerpt":"","text":"SmallTalk 与 C 的融合–Objective-C三十几年前，Brad Cox 和 Tom Love在主流且高效的C语言基础上，借鉴Smalltalk的面向对象与消息机制，想要搞出一个易用且轻量的C语言扩展，但C和Smalltalk的思想和语法格格不入，比如在Smalltalk中一切皆对象，一切调用都是消息： 1233 log 再比如用一个工厂方法来实例化一个对象： 1p := Person name: &apos;sunnyxx&apos; age: 26 在当时来看，一个具有面向对象功能的C语言真的是非常有吸引力，但必须得解决消息语法的转换，于是乎他们开发了一个Preprocessor(预编译程序)，去解析Smalltalk风格的语法，再转换成C语言的代码，进而和其他C代码一起编译。想法很美好，但Smalltalk语法里又是空格、又是冒号的，万一遇到个什么复杂嵌套调用，语法解析多难写呀，于是乎他们想，把消息两边加个中括号吧，这样Parser写起来简单多了： 1[Person name: &quot;sunnyxx&quot; age: 26]; 这就造就了Objective-C奇怪的中括号、冒号四不像语法，这怎么看都是个临时的方案，但当时可能是唯一的方法，借用已有的C的编译器比重造一个成本低多了，而且完全兼容C语言。随着这几年Apple开发的火热，Objective-C越来越成为Apple不爽的地方，先是恨透了在GCC上给Objective-C加支持，自己重建了个Clang，后是干脆重新发明了Swift来彻底代替，用了30年的时间终于还完了技术债。 虽然有了个Preprocessor，但只能做到把Smalltalk风格的代码分析并转译成C，还需要解决两个问题： C语言上实现一个OOP对象模型 将Smalltalk风格的Message机制转换成C函数调用 对象模型的设计倒很省事，直接搬照Smalltalk的就好了：如Class/Meta Class/Instance Method/Class Method这些概念，还有一些关键字如self/super/nil等全都是Smalltalk的。这步转换在Preprocessing过程中就可以完成，因为重写后的Class就是原原本本的C语言的Struct，只需要按Smalltalk中“类-元类”的模型设置好即可，无需额外的支持。消息机制就不一样了，要实现向一个target(class/instance)发送消息名(selector)动态寻找到函数实现地址(IMP)并调用的过程，还要处理消息向父类传递、消息转发(Smallltalk中叫“Message-Not-Understood”)等，这些行为无法在Preprocessing或Build Time实现，需要提供若干运行时的C函数进行支持，所有这些函数打个包，便形成了最原始的Runtime。 所以最初的Objective-C = C + Preprocessor + Runtime 注：GCC中一开始用预处理器来支持Objective-C，之后作为一个编译器模块，再后来都交给了Clang实现。 作为单纯的C语言扩展，Runtime中只要实现几个最基础的函数(如objc_msgSend)即可，但为了构建整套Objective-C面向对象的基础库(如Foundation)，Runtime还需要提供像NSObject这样的Root Class作为面向对象的起点、提供运行时反射机制以及运行时对Class结构修改的API等。再后来，即便是Objective-C语言本身的不断发展，新语言特性的加入，也不在乎是扩展Clang和扩展Runtime，比如： ARC：编译器分析对象引用关系，在合适的位置插入内存管理的函数，并需要把这些函数打包加到Runtime中，如 ==objc_storeStrong==,==objc_storeWeak==等。同时还要处理dealloc函数，自动加入对super的调用等，具体可以看这篇文章。 Lightweight Generics：叫做“轻量泛型”是因为只增加了编译器检查支持，而泛型信息并未影响到运行时，所以Runtime库无需改动。 Syntax Sugars：比如Boxed Expr(@123)、Array Literal(@[...])、Dictionary Literal(@{...})和轻量泛型一样，只是把如@123在编译rewrite成[NSNumber numberWithInt: 123]而已，无需改动Runtime。 Non Fragile Ivars: 类实例变量的动态调整技术，用于实现Objective-C Binary的兼容性，随着Objective-C 2.0出现，需要编译器和Runtime的共同配合，感兴趣的可以看这篇文章。 因此，Runtime的精髓并非在于平日里很少接触的那些所谓的“黑魔法”Runtime API、也并非各种Swizzle大法，而是Objective-C语言层面如何处理Type、处理Value、如何设计OOP数据结构和消息机制、如何设计ABI等，去了解这么一个小而精美的C语言运行时扩展是怎么设计出来的。 相关的文章：https://zh.wikipedia.org/wiki/Objective-Chttp://web.cecs.pdx.edu/~harry/musings/SmalltalkOverview.html Runtime简介作为一门动态语言，Objective-C会尽可能的将编译和链接时要做的事情推迟到运行时。只要有可能，Objective-C总是使用动态的方式来解决问题。这意味着Objective-C语言不仅需要一个编译环境，同时也需要一个运行时系统来执行编译好的代码。运行时系统(runtime)扮演的角色类似于Objective-C语言的操作系统，Objective-C基于该系统来工作的。因此，runtime好比Objective-C的灵魂，很多东西都是在这个基础上出现的。所以它是值得你花功夫去理解的。 与静态语言编译后的区别1、静态语言一个静态语言程序，如下所示的C程序： 12345#include &lt;stdio.h&gt;int main(int argc, const char **argv[]) &#123; printf(&quot;Hello World&quot;); return 0;&#125; 会经过编译器的语法分析，优化然后将你最佳化的代码编译成汇编语言，然后完全按照你设计的逻辑和你的代码自上而下执行。 2、Objective-C 动态语言很常见的一个消息发送语句： [receiver message] 会被编译器转化成 objc_msgSend(receiver, selector) 如果有参数则为 objc_msgSend(receiver, selector, arg1, arg2, …) 消息只有到运行时才会和函数实现绑定起来，而不是按照编译好的逻辑一成不变的执行。按照作者的理解，编译阶段只是确定了要去向receiver对象发送message消息，但是却没有发送，真正发送是等到运行的时候进行。因此，编译阶段完全不知道message方法的具体实现，甚至，该方法到底有没有被实现也不知道。这就有可能导致运行时奔溃问题。 Objective-C Runtime的几点说明 1、runtime是开源的 目前Apple公司和GNU公司各自维护一个开源的runtime版本，这两个版本之间都在努力的保持一致。其中Apple的版本可以在工程中引用#import &lt;objc/runtime.h&gt; 点击右键jump to definition，进去查看 2、runtime是由C语言实现的 runtime作为Objective-C最核心的部分，几乎全部由C语言实现。这里的“几乎”所指的例外就包含有的方法(比如下面要说到的objc_msgSend方法)甚至是用汇编实现的 3、runtime的两个版本 Objective-C运行时系统有两个已知版本：早期版本(Legacy)和现行版本(Modern)。在现行版本中，最显著的新特性就是实例变量是“健壮”(non-fragile)的： 在早期版本中，如果你改变类中实例变量的布局，你必须重新编译该类的所有子类。在现行版本中，如果你改变类中实例变量的布局，你无需重新编译该类的任何子类。此外，现行版本支持声明property的synthesis属性器。 和Runtime system交互的三种方式1、通过Objective-C源代码 大部分情况下，运行时系统在后台自动运行，我们只需要编写和编译Objective-C源代码。当编译Objective-C类和方法时，编译器为实现语言动态特性将自动创建一些数据结构和函数。这些数据结构包含类定义和协议定义中的信息，如在Objective-C 2.0 程序设计语言中定义类和协议类一节所讨论的类的对象和协议类的对象，方法选标，实例变量模板，以及其他来自于源代码的信息。运行时系统的主要功能就是根据源代码中的表达式发送消息。 2、通过类NSObject的方法 Cocoa程序中绝大部分类都是NSObject类的子类，所以大部分都继承了NSObject类的方法，因而继承了NSObject的行为(NSProxy类是个例外)。然而，某些情况下，NSObject类仅仅定义了完成某件事情的模板，而没有提供所有需要的代码。 例如，NSObject类定义了description方法，返回该类内容的字符串表示。这主要是用来调试程序–GDB中的print-object方法就是直接打印出该方法返回的字符串。NSObject类中该方法的实现并不知道子类中的内容，所以它只是返回类的名字和对象的地址。NSObject的子类可以重新实现该方法以提供更多的信息。 某些NSObject的方法只是简单的从运行时系统中获取信息，从而允许对象进行一定程度的自我检查。 例如，class返回对象的类；isKindOfClass:和isMemberOfClass:则检查对象是否在指定的类继承体系中；respondsToSelector:检查对象能否响应指定的消息；conformsToProtocol:检查对象是否实现了指定协议类的方法；methodForSelector:则返回指定方法实现的地址。 3、通过运行时系统的函数 运行时系统是一个有公开接口的动态库，由一些数据接口和函数的集合组成，这些数据结构和函数的声明头文件在/usr/include/objc中。这些函数支持用纯C的函数来实现和Objective-C同样的功能。还有一些函数构成了NSObject类方法的基础。这些函数使得访问运行时系统接口和提供开发工具成为可能。尽管大部分情况下它们在Objective-C程序不是必须的，但是有时候对于Objective-C程序来说某些函数是非常有用的。这些函数的文档参见Objective-C 2.0运行时系统参考库。 Runtime的几个概念SELSEL又叫方法选择器，这到底是个什么玩意呢？在objc.h中是这样定义的： typedef struct objc_selector *SEL; 这个SEL表示什么？首先，说白了，方法选择器仅仅是一个char*指针，仅仅表示它所代表的方法名字罢了。Objective-C在编译的时候，会根据方法的名字，生成一个用来区分这个方法的唯一的一个ID，这个ID就是SEL类型的。我们需要注意的是，只要方法的名字相同，那么它们的ID都是相同的。就是说，不管是超类还是子类，不管有没有超类和子类的关系，只要名字相同那么ID就是一样的。 而这也就导致了Objective-C在处理有相同函数名和参数个数但参数类型不同的函数的能力非常的弱，比如当你想在程序中实现下面两个方法： 12-(void)setWidth: (int)width;-(void)setWidth: (double)width; 这样的函数则被认为是一种编译错误，而这最终导致了一个非常非常奇怪的Objective-C特色的函数命名： 12-(void)setWidthIntValue: (int)width;-(void)setWidthDoubleValue: (double)width; 可能有人会问，runtime费了老半天劲，究竟想做什么？ 刚才我们说道，编译器会根据每个方法的方法名为那个方法生成唯一的SEL，这些SEL组成一个Set集合，这个Set简单的说就是一个经过了优化过的hash表。而Set的特点就是唯一，也就是SEL是唯一的，因此，如果我们想到这个方法集合中查找某个方法时，只需要去找到这个方法对应的SEL就行了，SEL实际上就是根据方法名hash化了的一个字符串，而对于字符串的比较仅仅需要比较他们的地址就可以了，犀利，速度上无与伦比。但是，有一个问题，就是数量增多会增大hash冲突而导致的性能下降(或是没有冲突，因为也可能用的是perfect hash)。但是不管使用什么样的方法加速，如果能够将总量减少(多个方法可能对应同一个SEL),那将是最犀利的方法。那么，我们就不难理解，为什么SEL仅仅是函数名了。 到这里，我们明白了，本质上，SEL只是一个指向方法的指针(准确的说，只是一个根据方法名hash化了的KEY值，能唯一代表一个方法)，它的存在只是为了加快方法的查询速度。 通过下面三种方法可以获取SEL： sel_registerName函数 Objective-C 编译器提供的@selector() NSSelectorFromString()方法 IMP，方法实现的指针IMP在objc.h中是如此定义的： 1typedef id(*IMP)(id, SEL, ...); 第一个参数：是指向self的指针(如果是实例方法，则是类实例的内存地址；如果是类方法，则是指向元类的指针)，这个比SEL要好理解多了，熟悉C语言的同学都知道，这其实是一个函数指针。第二个参数：是方法选择器(selector) 接下来的参数：方法的参数列表 前面介绍过的SEL就是为了查找方法的最终实现IMP的，由于每个方法对应唯一的SEL，因此我们可以通过SEL方便快速准确的获得它所对应的IMP，查找过程将在下面讨论。取得IMP后，我们就获得了执行这个方法代码的入口点，此时，我们可以像调用普通的C语言函数一样来使用这个函数指针了。 下面的例子，介绍了取得函数指针，即函数指针的用法： 123void(* performMessage)(id, SEL);//定义一个IMP(函数指针)performMessage = (void)(*)(id, SEL)[self methodForSelector: @selector(message)];//通过methodForSelector方法根据SEL获取对应的函数指针performMessage(self, @selector(message));//通过取到的IMP（函数指针）跳过runtime消息传递机制，直接执行message方法 用IMP的方式，省去了runtime消息传递过程中所做的一系列动作，比直接向对象发送消息效率高效一些。 MethodMethod用于表示类定义中的方法，则定义如下： 12345typedef struct objc_method *Methodstructobjc_method &#123; SEL method_name OBJC2_UNAVAILABLE; //方法名 char *method_types OBJC2_UNAVAILABLE; IMP method_imp OBJC2_UNAVAILABLE; //方法实现&#125; 我们可以看到该结构体中包含一个SEL和IMP，实际上相当于在SEL和IMP之间作了一个映射。有了SEL，我们便可以找到对应的IMP，从而调节方法的实现代码 元类(Meta Class)meta-class是一个类对象的类(注意是类对象)。在上面我们提到，所有的类自身也是一个对象，我们可以向这个对象发送消息(即调用类方法)。既然是对象，那么它也是一个objc_object指针，它包含了一个指向其类的一个isa指针。那么，这个isa指针指向什么呢？为了调用类方法，这个类的isa指针必须指向一个包含这些类方法的一个objc_class结构体。这就引出了meta-class的概念，meta-class中存储着一个类的所有类方法。 所以，调用类方法的这个类对象的isa指针指向的就是meta-class。 当我们向一个对象发送消息时，runtime会在这个对象所属的这个类的方法列表中查找方法；而向一个类发送消息时，会在这个类的meta-class的方法列表中查找。 再深入一下，meta-class也是一个类，也可以向他发送一个消息，那么它的isa又是指向什么呢？为了不让这种结构无线延伸下去，Objective-C的设计者让所有的meta-class的isa指向基类的meta-class，以此作为他们的所属类。即，任何NSObject继承体系下的meta-class都使用NSObject的meta-class作为自己的所属类，而基类的meta-class的isa指针是指向它自己。 通过上面的描述，再加上对objc_class结构体中super_class指针的分析，我们就可以描绘出类及相对应meta-class类的一个继承体系，如下图： CategoryCategory是表示一个指向分类的结构体的指针，其定义如下： 1234567typedef struct objc_category* Category &#123; char *category_name OBJC2_UNAVAILABLE; //分类名char *cla ss_name OBJC2_UNAVAILABLE; //分类所属的类名structobjc _method_list *instance_methods OBJC2_UNAVAILABLE; //实例方法列表struc tobjc_method_list *class_methods OBJC2_UNAVAILABLE; //类方法列表str uctobjc_protocol_list *protocols OBJC2_UNAVAILABLE; //分类所实现的协议列表&#125; 这个结构体主要包含了分类定义的实例方法与类方法，其中instance_methods列表是objc_class中方法列表的一个子集，而class_methods列表是元类方法列表的一个子集。 可发现，类别中没有ivar成员变量指针，也就意味着：类别中不能够添加实例变量和属性 1struct objc_ivar_list *ivars OBJC2_UNAVAILABLE; //该类的成员变量链表 objc_classObjective-C类是由Class类型来表示的，它实际上是一个指向objc_class结构体的指针。 1typedef struct object_class *Class 它的定义如下： 查看objc/runtime.h中objc_class结构体的定义如下： 1234567891011121314struct object_class &#123; Class isa OBJC_ISA_AVAILABILITY; #if!__OBJC2__ Class super_class OBJC2_UNAVAILABLE; //父类 const char *name OBJC2_UNAVAILABLE; //类名 long version OBJC2_UNAVAILABLE; //类的版本信息，默认0 long info OBJC2_UNAVAILABLE; //类信息，供运行期使用的一些位标识 long instance_size OBJC2_UNAVAILABLE; //该类的实例变量大小 struct objc_ivar_list *ivars OBJC2_UNAVAILABLE; //该类的成员变量链表 struct objc_method_list *methodLists OBJC2_UNAVAILABLE; //方法定义的链表 struct objc_cache *cache OBJC2_UNAVAILABLE; //方法缓存 struct objc_protocol_list *protocol OBJC2_UNAVAILABLE; //协议链表 #endif&#125; OBJC2_UNAVAILABLE; objc_objectobjc_object是表示一个类的实例的结构体 它的定义如下(objc/objc.h):struct objc_object { Class isa OBJC_ISA_AVAILABILITY;};typedef struct objc_object *id; 可以看到，这个结构体只有指向类的isa指针。这样，当我们向一个Objective-C对象发送消息时，运行时库会根据实例对象的isa指针找到这个实例对象所属的类。runtime库会在类的方法列表及父类的的方法列表中去寻找与消息对应的selector指向的方法，找到后即运行这个方法。 消息调用流程传递消息所用的几个runtime方法前面我们说过，下面的方法： [receiver message]objc_msgSend(receiver, selector) 实际上，同objc_msgSend方法类似的还有几个： 1234objc_msgSend_stret (返回值是结构体)objc_msgSend_fpret (返回值是浮点型)objc_msgSendSuper (调用父类方法)objc_msgSendSuper_stret (调用父类方法，返回值是结构体) 它们的作用都是类似的，为了简单起见，后续介绍消息和消息传递机制都以objc_msgSend方法为例。 消息调用一切还是从消息表达式[receiver message]开始，在被转换成objc_msgSend(receiver, SEL)后，在运行时，runtime system会做以下事情： 检查忽略的Selector，比如当我们运行在有垃圾回收机制的环境中，将会忽略retain和release消息。 检查receiver是否为nil。不像其他语言，nil在Objective-C中是完全合法的，并且这里有很多原因你也愿意这样，比如，至少我们省去了给一个对象发送消息前检查对象是否为空的操作。如果receiver为空，则会将selector也设置为空，并且直接返回到消息调用的地方。如果对象非空，就继续下一步。 接下来会根据SEL到当前类中查找对应的IMP，首先会在cache中检索它，如果找到了就根据函数指针跳转到这个函数执行，否则进行下一步。 检索当前类对象中的方法表(method list)，如果找到了，加入cache中，并且跳转到这个函数执行，否则进行下一步。 从父类中寻找，直到根类：NSObject类。找到了就将方法加入对应类的cache表中，如果仍未找到，则要进入后文介绍的内容：动态方法决议。 如果动态方法决议仍不能解决问题，只能进行最后一次尝试，进入消息转发流程。 如果还不行，会奔溃。 这里的调用可以分成两部分1、调用的方法可以找到（执行步骤1-4）下面的图部分展示了这个调用过程：当消息发送给一个对象时，首先从运行时系统缓存使用过的方法中寻找。如果找到，执行方法，如果没有找到继续执行下面的步骤。objc_msgSend通过对象的isa指针获取到类的结构体，然后在方法分发表里面查找方法的selector。如果没有找到selector， objc_msgSend结构体中的指向父类的指针找到其父类，并在父类的分发表里面查找方法的selector。依此，会一直沿着类的继承体系到达NSObject类。一旦定位到selector，函数就获取到了实现的入口点，并传入相应的参数来执行方法的具体实现，并将该方法添加进入缓存中，如果最后没有定位到selector，则会走动态解析流程。2、调用的方法找不到（消息转发机制）当一个对象能接收一个消息时，就会走正常的方法调用流程。但如果一个对象无法接收指定消息时，又会发生什么事呢？默认情况下，如果是以[objc message]的方式调用方法，如果object无法响应message消息时，编译器会报错。但如果是以perform…的形式来调用，此时编译器不会报错，需要等到运行时才能确定object是否能接收message消息。如果不能，则程序奔溃。 通常，我们不能确定一个对象是否能接受某个消息时，会先调用respondsToSelector: 来判断一下。如下代码所示： 123if (self respondsToSelector: @selector(method)) &#123; [self performSelector: @selector(method)];&#125; 不过，我们这边想讨论下不使用respondsToSelector: 判断的情况。当一个对象无法接收某一消息时，就会启动所谓”消息转发(message forwarding)”机制，通过这一机制，我们可以告诉对象如何处理位置消息。默认情况下，对象接收到未知的消息，会导致程序奔溃，通过控制台，我么可以看到以下异常信息：这段异常信息实际上是由NSObject的“doesNotRecongnizeSelector”方法抛出的。不过，我们可以采取一些措施，在程序奔溃前执行特定的逻辑，而避免程序奔溃。消息转发机制基本上分为三个步骤： 动态方法解析 备用接收者 完整转发 消息的转发流程图： 动态方法解析对象在接收到未知消息时，首先会调用所属类的类方法 12+ resolveInstanceMethod: (实例方法) 或者+ resolveClassMethod: (类方法) 让我们可以在程序运行时动态的为一个selector提供实现，如果我们添加了函数的实现，并返回YES，运行时系统会重启一次消息的放松过程，调用动态添加的方法。例如，下面的例子： 123456789101112+ (BOOL)resolveInstanceMethod: (SEL)sel &#123; if (sel == @selector(foo)) &#123; class_addMethod([self class], sel, (IMP)dynamicMethodIMP, &quot;V@:&quot;); return YES; &#125; return [super resolveInstanceMethod: sel];&#125;void dynamicMethodIMP(id self, SEL _cmd) &#123; NSLog(@&quot;%s&quot;, __PRETTY_FUNCTION__);&#125; 在这个方法中，我们有机会为该未知消息新增一个“处理方法”，通过运行时class_addMethod函数动态的添加到类里面就可以了。 这种方案更多的是为了实现@dynamic属性。注：@dynamic 关键字就是告诉编译器不要做这些事，同时在使用了存储方法时也不要报错，即让编译器相信存储方法会在运行时找到。 备用接收者 1- (id)forwardingTargetForSelector: (SEL)aSelector 如果在上一步无法处理消息，则runtime会继续调用以下方法：如果一个对象实现了这个方法，并返回一个非nil的结果，则这个对象会作为消息的新接收者，且消息会被分发到这个对象。当然这个对象不能是self自身，否则就是出现无限循环。当然，如果我们没有指定相应的对象来处理aSelector，则应该调用父类的实现来返回结果。 这一步合适于我们只想将消息转发到另一个能处理该消息的对象上。但这一步无法对消息进行处理，如操作消息的参数和返回值。 完整消息转发如果在上一步还不能处理未知消息，则唯一能做的就是启用完整的消息转发机制。我们首先要通过，指定方法签名，若返回nil，则表示不处理。如下代码： 1234567- (NSMethodSignature *)methodSignatureForSelector: (SEL)aSelector &#123; if ([NSStringFromSelector(aSelector) isEqualToString: @&quot;testInstanceMethod&quot;]) &#123; return [NSMethodSignature signatureWithObjcTypes: &quot;v@:&quot;]; &#125; return [super methodSignatureForSelector];&#125; 若返回方法签名，则会进入下一步调用以下方法，对象会创建一个表示消息的NSInvocation对象，把与尚未处理的消息有关的全部细节都封装在Invocation中，包括selector，目标(target)和参数。我们可以在forwardInvocation方法中选择将消息转发给其它对象。我们可以通过Invocation做很多处理，比如修改实现方法，修改响应对象等。 12345- (void)forwardInvaocation: (NSInvocation)anInvocation &#123; [anInvocation invokeWithTarget: _helper]; [anInvocation setSelector: @selector(run)]; [anInvocation invokeWithTarget: self];&#125; 函数检索优化措施通过SEL进行IMP匹配先来看看类对象中保存的方法列表和方法的数据结构： 1234567891011typedef struct method_list_t &#123; uint32_t entsize_NEVER_USE; uint32_t count; struct method_t first; &#125; method_list_t;typedef struct method_t &#123; SEL name; const char *types; //参数类型和返回值类型 IMP imp;&#125; method_t; 在前面介绍SEL的时候，我们已经说过了苹果在通过SEL检索IMP时做的努力，这里不再累述。 cache缓存cache的原则就是缓存那些可能要执行的函数地址，那么下次调用的时候，速度就可以快速很多。这个和CPU的各种缓存原理相同。说了这么多，再来认识几个名词： 1234567891011struct objc_cache &#123; uintptr_tmask; uintptr_toccupied; cache_entry *buckets[1];&#125;;typedef struct &#123; SEL name; void *unused; IMP imp;&#125; cache_entry; 看这个结构，还是hash table。objc_msgSend 首先在cache list中找SEL，没有找到就在class method中找，super class method中找（当然super class 也有cache list）。而cache的缓存机制则非常复杂了，由于Objective-C是动态语言。所以，这里面还有很多的多线程同步问题，而这些锁又是效率的大敌，相关的内容已经远远超过文本讨论的范围。如果在缓存中已经有了需要的方法选标，则消息仅仅比函数调用慢一点。如果程序运行了足够长的时间，几乎每个消息都能在缓存中找到方法实现。程序运行时，缓存也讲随着新的消息的增加而增加。据牛人说(没有亲测过)，苹果通过这些优化，在消息传递和直接的函数调用上的差距已经相当的小了。 方法调用中的隐藏参数在进行面向对象编程的时候，在实例方法中都是用过self关键字，可是你有没有想过，为什么在一个实例方法中，通过self关键字就能调取到当前方法的对象呢？这就要归功于runtime system消息的隐藏参数了。当objc_msgSend找到方法对应的实现时，它将直接调用该方法实现，并将消息中所有的参数都传递给方法实现，同时，它还将传递两个隐藏的参数： 接收消息的对象（也就是self指向的内容） 方法选标（_cmd指向的内容） 这些参数帮助方法实现获得了消息表达式的信息。它们被认为是“隐藏”的，是因为它们并没有在在定义方法的源码中声明，而是在代码编译时是插入方法的实现中的。尽管这些参数没有被显示声明，但在源码中仍然可以引用它们（就像可以引用消息接收者对象的实例变量一样）。在方法中可以通过self来引用消息接收者，通过标选_cmd来引用方法本身。下面的例子很好的说明了这个问题： 123456- (void)message &#123; self.name = @&quot;James&quot;; //通过self关键字给当前对象的属性赋值 SEL currentSel = _cmd; //通过_cmd关键字取到当前函数对应的SEL NSLog(@&quot;currentSel is: %s&quot;, (char *)currentSel);&#125;打印结果：ObjcRuntime[693:403] currentSel is: message 当然，在这两参数中，self更有用，更常用一些。实际上，它是在方法实现中访问消息接收者对象的实例变量的途径。 方法交换Swizzling使用场景：系统自带的方法功能不够，给系统自带的方法扩展一些功能，并且保持原有的功能。方式一：继承系统的类，重写方法。方式二：使用runtime，交换方法。在Objective-C中调用一个方法，其实是向一个对象发送消息，而查找消息的唯一依据是selector的名字。所以，我们可以利用Objective-C的runtime机制，实现在运行时交换selector对应的方法实现以达到我们的目的。每个类都有一个方法列表，存放着selector的名字和方法实现的映射关系。IMP有点类似函数指针，指向具体的Method实现。我们先看看SEL与IMP之间的关系图：从上图可以看出来，每一个SEL与一个IMP一一对应，正常情况下通过SEL可以查找到对应消息的IMP实现。但是，现在我们要做的就是把链接线解开，然后链接到我们自定义的函数的IMP上。当然，交换了两个SEL的IMP，还是可以再次交换回来了。交换后变成这样的，如下图从图中可以看出，我们通过swizzling特性，将selectorC的方法实现IMPc与selectorN的方法实现IMPn交换了，当我们调用selectorC，也就是给对象发送selectorC消息时，所查找到的对应的方法实现就是IMPn而不是IMPc了。 123456789101112131415161718192021222324252627282930313233343536#import &quot;UIViewController+swizzling.h&quot;@implementation UIViewController(swizzling)//load方法会在类第一次加载的时候被调用，调用的时间比较靠前，适合在这个方法里做方法交换+ (void)load &#123; //方法交换应该被保证，在程序中只会执行一次 static dispatch_once_t onceToken; dispatch_once(&amp;onceToken, ^&#123; //获得viewController的生命周期方法的selector SEL systemSel = @selector(viewWillAppear:); //自己实现的将要被交换的方法的selector SEL swizzSel = @selector(swiz_viewWillAppear:); //两个方法的Method Method systemMethod = class_getInstanceMethod([self class], systemSel); Method swizzMethod = class_getInstanceMethod([self class], swizzSel); //首先动态添加方法，实现是被交换的方法，返回值表示添加成功还是失败 BOOL isAdd = class_addMethod(self, swizzMethod, method_getImplementation(swizzMethod), method_getTypeEncoding(swizzMethod)); if (isAdd) &#123; //如果成功，说明类中不存在这个方法的实现 //将被交换方法的实现替换到这个并不存在的实现 class_replaceMethod(self, swizzMethod, method_getImplementation(systemMethod), method_getTypeEncoding(systemMethod)); &#125; else &#123; //否则，交换两个方法的实现 method_exchangeImplementations(systemMethod, swizzMethod); &#125; &#125;);&#125;- (void)swiz_viewWillApper: (BOOL)animated &#123; //这时候调用自己，看起来像死循环 //但是其实自己的实现已经被替换了 [self swiz_ViewWillAppear: animated]; NSLog(@&quot;swizzle&quot;);&#125;@end 在一个自己定义的viewController中重写viewWillAppear 1234- (void)viewWillAppear: (BOOL)animated &#123; [super viewWillAppear: animated]; NSLog(@&quot;viewWillAppear&quot;);&#125; 设置关联值使用场景：现在你准备一个系统的类，但是系统的类并不能满足你的需求，你需要额外添加一个属性。给一个类声明属性，其实本质就是给这个类添加关联，并不会直接把这个值的内存空间添加到类存储空间。分类只能添加方法。设置关联值这种情况的一般解决办法就是继承。但是只增加一个属性，就去继承一个类，总觉得太麻烦。这个时候，runtime的关联属性就发挥它的作用了。添加关联对象 1234567- (void)addAssociatedObject: (id)object &#123; objc_setAssociatedObject(self, @selector(getAssociatedObject), object, OBJC_ASSOCIATION_RETAIN_NONATOMIC)&#125;//获取关联对象- (id)getAssociatedObject &#123; return objc_getAssociatedObject(self, _cmd);&#125; 注意，这里面我们把getAssociatedObject方法的地址作为唯一的key，_cmd代表当前调用方法的地址。参数说明：object：与谁关联，通常是传selfkey：唯一键，在获取值时通过该键获取，通常是使用static const void * 来声明value：关联所设置的值policy：内存管理策略，比如使用copy 1void objc_setAssociatedObject(id object, const void *key, id value, objc_AssociationPolicy policy) 获取关联值参数说明：object：与谁关联，通常是传self，在设置关联时所指定的与哪个对象关联的那个对象key：唯一键，在设置关联时所指定的键 1id objc_getAssociatedObject(id object, const void *key) 取消关联 1void objc_removeAssociatedObjects(id object) 关联策略 1234567891011121314151617181920212223242526272829303132333435typedef OBJC_ENUM(uintptr_t, objc_AssociationPolicy) &#123; OBJC_ASSOCIATION_ASSIGN = 0, //表示弱引用关联，通常是基本数据类型 OBJC_ASSOCIATION_RETAIN_NONATOMIC = 1, //表示强引用关联对象，是线程安全的 OBJC_ASSOCIATION_COPY_NONATOMIC = 3, //表示关联对象copy，是线程安全的 OBJC_ASSOCIATION_RETAIN = 01401, //表示强引用关联对象，不是线程安全的 OBJC_ASSOCIATION_COPY = 01403 //表示关联对象copy，不是线程安全的&#125;；@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad]; //给系统NSObject类动态添加属性name NSObject *objc = [[NSObject alloc] init]; objc.name = @&quot;123&quot;; NSLog(@&quot;%@&quot;, objc.name);&#125;@end//定义关联的key static const char *key = &quot;name&quot;; @implementation NSObject(Property)- (NSString *)name &#123; //根据关联的key，获取关联的值。 return objc_getAssociatedObject(self, key);&#125;- (void)setName: (NSString *)name &#123; //第一个参数：给对象添加关联 //第二个参数：关联的key，通过这个key获取 //第三个参数：关联的value //第四个参数：关联的策略 objc_setAssociatedObject(self, key, name, OBJC_ASSOCIATION_RETAIN_NONATOMIC);&#125;@end 动态添加方法使用场景：如果一个类方法非常多，加载类到内存的时候也比较耗费资源，需要给每个方法生成映射表，可以使用动态给某个类添加方法解决。 1234567891011121314151617181920212223242526272829303132@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad]; Person *p = [[Person alloc] init]; //默认person，没有实现eat方法，可以通过performSelector调用，但是会报错。 //动态添加方法就不会报错 [p performSelector: @selector(eat)];&#125;@end@implementation Person void(*)() //默认方法都有两个隐式参数void eat(id self, SEL sel) &#123; NSLog(@&quot;%@ %@&quot;, self, NSStringFromSelector(sel));&#125;// 当一个对象调用未实现的方法，会调用这个方法处理，并且会吧对应的方法列表传过来// 刚好可以用来判断，未实现的方法是不是我们想要动态添加的方法+ (BOOL)resolveInstanceMethod: (SEL)sel &#123; if (sel == @selector(eat)) &#123; //动态添加eat方法 //第一个参数：给哪个类添加方法 //第二个参数：添加方法的方法编号 //第三个参数：添加方法的函数实现（函数地址） //第四个参数：函数的类型（返回值+参数类型）v:void @:对象-&gt;self :表示SEL-&gt;_cmd class_addMethod(self, @selector(eat), eat, &quot;v@:&quot;); &#125; return [super resolveInstanceMethod];&#125;@end 字典转模型设计模式模型属性，通常需要跟字典中的key一一对应问题：一个一个的生成模型属性，很慢？需求：能不能自动根据一个字典，生成对应的属性。解决：提供一个分类，专门根据字典生成对应的属性字符串 1234567891011121314151617181920212223242526272829303132333435@implementation NSObject(Log)//自动打印属性字符串+ (void)resolveDict: (NSDictionary *)dict &#123; //拼接属性字符串代码 NSMutableString *strM = [NSMutableString string]; //1、遍历字典，把字典中的所有key取出来，生成对应的属性代码 [dict enumerateKeysAndObjectsUsingBlock:^(id_Nonnull key, id_Nonnull obj, BOOL_Nonnull stop)&#123; //类型经常变，抽出来 NSString *type; if ([obj isKindOfClass:NSClassFromString(@&quot;__NSCFString&quot;)]) &#123; type = @&quot;NSString&quot;; &#125; else if ([obj isKindOfClass:NSClassFromString(@&quot;__NSCFArray&quot;)]) &#123; type = @&quot;NSArray&quot;; &#125; else if ([obj isKindOfClass:NSClassFromString(@&quot;__NSCFNumber&quot;)]) &#123; type = @&quot;NSNumber&quot;; &#125; else if ([obj isKindOfClass:NSClassFromString(@&quot;__NSCFDictionary&quot;)]) &#123; type = @&quot;NSDictionary&quot;; &#125; //属性字符串 NSString *str; if ([type containsString: @&quot;NS&quot;]) &#123; str = [NSString stringWithFormat: @&quot;@property(nonatomic, strong) %@ *%@;&quot;, type, key]; &#125; else &#123; str = [NSString stringWithFormat: @&quot;@property(nonatomic, assign) %@ %@;&quot;, type, key]; &#125; //每生成属性字符串，就自动换行。 [strM appendFormat: @&quot;\\n%@\\n&quot;, str]; &#125;]; //把拼接好的字符串打印出来 NSLog(@&quot;%@&quot;, strM);&#125;@end 字典转模型的方式一：KVC 1234567@implementation Status+ (instancetype)statusWithDict: (NSDictionary *)dict &#123; Status *status = [[self alloc] init]; [status setValuesForKeysWithDictionary: dict]; return status;&#125;@end KVC字典转模型的弊端：必须保证，模型中的属性和字典中的key一一对应。如果不一致，就会调用[setValue:forUndefinedKey:],报key找不到的错。分析：模型中的属性和字典的ke不一一对应，系统就会调用[setValue:forUndefinedKey:]报错。解决：重写对象的[setValue:forUndefinedKey:]，把系统方法覆盖，就能继续使用KVC，字典转模型了。 1- (void)setValue: (id)Value forUndefinedKey:(NSString *)key&#123;&#125; 字典转模型的方式二：Runtime思路：利用运行时，遍历模型中所有属性，根据模型的属性名，去字典中查找key，取出对应的值，给模型的属性赋值。步骤：提供一个NSObject类，专门字典转模型，以后所有的模型都可以通过这个分类转。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad]; //解析plist文件 NSString *filePath = [[NSBundle mainBundle] pathForResource:@&quot;status.plist&quot; ofType:nil]; NSDictionary *statusDic = [NSDictionary dictionaryWithContentsOfFile:filePath]; //获取字典数组 NSArray *dictArr = statusDict[@&quot;statuses&quot;]; //自动生成模型的属性字符串 [NSObject resolveDict:dictArr[0][@&quot;user&quot;]]; _statuses = [NSMutableArray array]; //遍历字典数组 for(NSDictionary *dict in dictArr) &#123; Status *status = [Status modelWithDict: dict]; [_statuses addObject:status]; &#125;&#125;@end@implementation NSObject(Model)+ (instancetype)modelWithDict:(NSDictionary *)dict &#123; // 思路：遍历模型中所有属性 -&gt;使用运行时 // 0、创建对应的对象 id objc = [[self alloc] init]; // 1、利用runtime给对象中成员属性赋值 // class_copyIvarList: 获取类中的所有成员属性 // Ivar: 成员属性的意思 // 第一个参数：表示获取哪个类中的成员属性 // 第二个参数：表示这个类有多少成员属性，传入一个int变量地址，会自动给这个变量赋值 // 返回值Ivar *：指的是一个ivar数组，会把所有的成员属性放在一个数组中，通过返回的数组就能全部获取到。 /* Ivar ivar; Ivar ivar1; Ivar ivar2; //定义一个ivar的数组a Ivar a[] = &#123;ivar, ivar1, ivar2&#125;; //用一个Ivar *指针指向数组的第一个元素 Ivar *ivarList = a; //根据指针访问数组的第一个元素 ivarList[0]; */ unsigned int count; //获取类中的所有成员属性 Ivar *ivarList = class_copyIvarList(self, &amp;count); for (int i = 0; i &lt; count; i++) &#123; //根据角标，从数组取出对应的成员属性 Ivar ivar = ivarList[i]; //获取成员属性名 NSString *name = [NSString stringWithUTF8String:ivar_getName(ivar)]; //处理成员属性名-&gt;字典中的key //从第一个角标开始截取 NSString *key = [name substringFromIndex: 1]; //根据成员属性名去字典中查找对应的value id value = dict[key]; //二级转换：如果字典中还有字典，也需要把对应的字典转成模型 //判断下value是否是字典 if ([value isKindOfClass: [NSDictionary class]]) &#123; //字典转模型 //获取模型的类对象，调用modelWithDict //模型的类名已知，就是成员属性的类型 //获取成员属性类型 NSString *type = [NSString stringWithUTF8String: ivar_getTypeEncoding(ivar)]; //生成的是这种&quot;@\\&quot;User\\&quot;&quot;类型 -&gt; @&quot;User&quot; 在OC字符串中\\&quot; -&gt; \\是转义的意思，不占用字符串 //裁剪类型字符串 NSRanger ranger = [type rangeOfString:@&quot;\\&quot;&quot;]; type = [type substringFromIndex:ranger.location + ranger.length]; range = [type rangeOfString:@&quot;\\&quot;&quot;]; //裁剪到哪个角标，不包括当前角标 type = [type substringToIndex:range.location]; //根据字符串类名生成类对象 Class modelClass = NSClassFromString(type); if (modelClass) &#123; //有对应的模型才需要转 //把字典转模型 value = [modelClass modelWithDict:value]; &#125; &#125; //三级转换：NSArray中也是字典，把数组中的字典转换成模型 //判断值是否是数组 if ([value isKindOfClass:[NSArray class]]) &#123; //判断对应类有没有实现字典数组转模型数组的协议 if ([self respondsToSelector:@selector(arrayContainModelClass)]) &#123; //转换成id类型，就能调用任何对象的方法id id Self = self; //获取数组中字典对应的模型 NSString *type = [Self arrayContainModelClass][key]; //生成模型 Class classModel = NSClassFromString(type); NSMutableArray *arrM = [NSMutableArray array]; //遍历字典数组，生成模型数组 for (NSDictionary *dict in value) &#123; //字典转模型 id model = [classModel modelWithDict: dict]; [arrM addObject: model]; &#125; //把模型数组赋值给value value = arrM; &#125; &#125; if (value) &#123; //有值，才需要给模型的属性赋值 //利用KVC给模型中的属性赋值 [objc setValue:value forKey:key]; &#125; &#125; return objc;&#125;@end 参考文章http://www.jianshu.com/p/e071206103a4http://www.jianshu.com/p/adf0d566c887http://www.jianshu.com/p/927c8384855ahttp://chun.tips/2014/11/05/objc-runtime-1/#morehttp://blog.sunnyxx.com/2016/08/13/reunderstanding-runtime-0/http://blog.csdn.net/wzzvictory/article/details/8624057http://www.cocoachina.com/ios/20151208/14595.htmlhttp://www.jianshu.com/p/46dd81402f63","categories":[{"name":"iOS 深入学习","slug":"iOS-深入学习","permalink":"http://yoursite.com/categories/iOS-深入学习/"}],"tags":[{"name":"Runtime","slug":"Runtime","permalink":"http://yoursite.com/tags/Runtime/"}]},{"title":"iOS深入学习 - 多线程","slug":"2017-10-19-thread","date":"2017-10-18T16:00:00.000Z","updated":"2019-07-24T08:16:11.270Z","comments":true,"path":"2017-10-19-thread/","link":"","permalink":"http://yoursite.com/2017-10-19-thread/","excerpt":"","text":"多线程简单介绍进程和线程1、什么是进程进程是指在系统中正在运行的一个应用程序，每个进程之间是相互独立的，每个进程均运行在其专用且受保护的内存空间内。比如同时打开QQ、Xcode，系统会分别启动2个进程，通过“活动监视器”可以查看Mac系统中所开启的进程。2、什么是线程1个进程想要执行任务，必须得有线程(每一个进程至少要有一条线程即：主线程)，线程是进程的基本执行单元，一个进程(程序)的所有任务都在线程中执行，比如使用音乐播放器播放音乐，使用下载器下载电影，都需要在线程中执行。3、线程的串行1个线程中任务的执行是串行的，如果要在1个线程中执行多个任务，那么只能一个一个的按照顺序执行这些任务。也就是说，在同一时间内，1个线程只能执行1个任务。比如在1个线程中下载3个文件(分别是文件A、文件B、文件C)。 多线程1、什么是多线程1个进程中可以开启多条线程，每条线程可以并行(同时)执行不同的任务。进程-&gt;车间，线程-&gt;车间工人。多线程技术可以提高程序的执行效率。比如同时开启3条线程分别下载3个文件(分别是文件A、文件B、文件C)。2、多线程原理同一时间，CPU只能处理1条线程，只有1条线程在工作(执行)。多线程并发(同时)执行，其实是CPU快速的在多线程之间调度(切换)。如果CPU调度线程的时间足够快，就造成了多线程并发执行的假象。思考：如果线程非常非常多，会发生什么情况？CPU会在N多个线程之间调度，CPU会累死，消耗大量的CPU资源，每条线程被调度执行的频率会降低(线程的执行效率降低)。3、多线程的优缺点多线程的优点： 能适当提高程序的执行效率 能适当的提高资源的利用率(CPU、内存利用率) 多线程的缺点： 开启线程需要占用一定的内存空间(默认情况下，主线程占用1M，子线程占用512k)，如果开启大量的线程，会占用大量的内存空间，CPU在调度线程上的开销就越大。程序设计更加复杂：比如线程之间的通信、多线程的数据共享。4、多线程在iOS开发中的应用主线程：一个iOS程序运行后，默认会开启1条线程，称为“主线程”或“UI线程”。主线程的主要作用：显示/刷新UI界面；处理UI事件(比如点击事件、滚动事件、拖拽事件等)主线程的使用注意：别将比较耗时的操作放到主线程中。耗时操作会卡住主线程，严重影响UI的流畅度，给用户一种“卡”的体验5、代码示例 123456789101112131415161718192021#import &quot;ViewController.h&quot;@interface ViewController ()- (IBAction)btnClick;@end@implementation ViewController- (void)viewDidLoad&#123; [super viewDidLoad];&#125;//按钮的点击事件- (IBAction)btnClick&#123; //1、获取当前线程 NSThread *current = [NSThread currentThread]; //2、使用for循环执行一些耗时操作 for (int i = 0; i &lt; 10000; i ++) &#123; //3、输出线程 NSLog(@&quot;btnClick---%d---%@&quot;, i, current); &#125;&#125;@end 执行效果：说明：当点击按钮的时候，textView点击没反应执行分析：等待主线程串行执行。开启子线程 线程安全多线程的安全隐患资源共享1块资源可能会被多个线程共享，也就是多个线程可能会访问同一块资源。比如多个线程访问同一个对象、同一个变量、同一个文件。当多个线程访问同一块资源时，很容易引发数据错乱和数据安全问题。示例一：示例二：问题代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import &quot;ViewController.h&quot;@interface ViewController()//剩余票数@property(nonatomic, assign)int leftTicketsCount;@property(nonatomic, assign)NSThread *thread1;@property(nonatomic, assign)NSThread *thread2;@property(nonatomic, assign)NSThread *thread3;@end@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad]; //默认有20张票 self.leftTicketsCount = 10; //开启多个线程，模拟售票员售票 self.thread1 = [[NSThread alloc] initWithTarget: self selector: @selector(sellTickets) object: nil]; self.thread1.name = @&quot;售票员A&quot;; self.thread2 = [[NSThread alloc] initWithTarget: self selector: @selector(sellTickets) object: nil]; self.thread2.name = @&quot;售票员B&quot;; self.thread3 = [[NSThread alloc] initWithTarget: self selector: @selector(sellTickets) object: nil]; self.thread3.name = @&quot;售票员C&quot;;&#125;- (void)sellTickets &#123; while(1) &#123; //1、先检查票数 int count = self.leftTicketsCount; if (count &gt; 0) &#123; //暂停一段时间 [NSThread sleepForTimeInterval: 0.002]; //2、票数-1 self.leftTicketsCount = count - 1; //获取当前线程 NSThread *current = [NSThread currentThread]; NSLog(@&quot;%@--卖了一张票，还剩余%d张票&quot;, current, self.leftTicketsCount); &#125; else &#123; //退出线程 [NSThread exit]; &#125; &#125; &#125;- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event &#123; //开启多线程 [self.thread1 start]; [self.thread2 start]; [self.thread3 start];&#125;@end 打印结果： 安全隐患分析 如何解决互斥锁使用格式 123@synchronized(锁对象)&#123; //需要锁定的代码&#125; 注意：锁定1份代码只用1把锁，用多把锁是无效的代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#import &quot;ViewController.h&quot;@interface ViewController ()//剩余票数@property(nonatomic, assign)int leftTicketsCount;@property(nonatomic, strong)NSThread *thread1;@property(nonatomic, strong)NSThread *thread2;@property(nonatomic, strong)NSThread *thread3;@end@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad]; //默认有20张票 self.leftTicketsCount = 20; //开启多个线程，模拟售票员售票 self.thread1 = [[NSThread alloc] initWithTarget: self selector: @selector(sellTickets) object: nil]; self.thread1.name = @&quot;售票员A&quot;; self.thread2 = [[NSThread alloc] initWithTarget: self selector: @selector(sellTickets) object: nil]; self.thread2.name = @&quot;售票员B&quot;; self.thread3 = [[NSThread alloc] initWithTarget: self selector: @selector(sellTickets) object: nil]; self.thread3.name = @&quot;售票员C&quot;;&#125;- (void)sellTickets &#123; while (1) &#123; @synchronized(self) &#123; //只能加一把锁 //1、先检查票数 int count = self.leftTicketsCount; if (count &gt; 0) &#123; //暂停一段时间 [NSThread sleepForTimeInterval: 0.002]; //2、票数-1 self.leftTicketsCount = count - 1; //获取当前线程 NSThread *current = [NSThread currentThread]; NSLog(@&quot;%@--卖了一张票，还剩余%d张票&quot;, current, self.leftTicketsCount); &#125; else &#123; //退出线程 [NSThread exit]; &#125; &#125; &#125;&#125;- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event &#123; //开启多线程 [self.thread1 start]; [self.thread2 start]; [self.thread3 start];&#125;@end 执行效果图： 互斥锁的优缺点 优点：能有效防止因多线程抢夺资源造成的数据安全问题 缺点：需要消耗大量的CPU资源 互斥锁的使用前提：多条线程抢夺同一块资源 相关专业术语：线程同步，多条线程按照顺序的执行任务。互斥锁，就是使用了线程同步技术。 原子和非原子属性OC在定义属性时有nonatomic和atomic两种选择atomic：源自属性，为setter方法加锁（默认就是atomic）nonatomic：非原子属性，不会为setter方法加锁 atomic加锁原理： 123456@property(assign, atomic) int age;- (void)setAge:(int)age &#123; @synchronized(self) &#123; _age = age; &#125;&#125; 原子和非原子属性的选择： nonatomic和atomic对比 atomic：线程安全，需要消耗大量的资源 nonatomic：非线程安全，适合内存小的移动设备 iOS开发的建议： 所有的属性都声明为nonatomic 尽量避免多线程抢夺同一块资源 尽量加锁、资源抢夺的业务逻辑交给服务器处理，减小移动客户端的压力 线程间的通信简单说明线程间通信：在1个进程中，线程往往不是孤立存在的，多个线程之间需要经常进行通信。线程通信间的体现：1个线程传递数据给另1个线程；在1个线程中执行完特定任务后，转到另1个线程继续执行任务。线程间通信常用方法： 12- (void)performSelectorOnMainThread:(SEL)aSelector withObject:(id)arg waitUntilDone:(BOOL)wait;- (void)performSelector:(SEL)aSelector onThread:(NSThread *)thread withObject:(id)arg waitUntilDone:(BOOL)wait; 线程间通信示例-图片下载代码1： 1234567891011121314151617181920212223242526272829303132#import &quot;ViewController.h&quot;@interface ViewController()@property (weak, nonatomic) IBOutlet UIImageView *iconView;@end@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad];&#125;- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event &#123; //在子线程中调用download方法下载 [self performSelectorInBackground:@selector(download) withObject:nil];&#125;- (void)download &#123; //1、根据URL下载图片 //从网络中下载图片 NSURL *urlstr = [NSURL URLWithString:@&quot;fdsf&quot;]; //把图片转换为二进制的数据 NSData *data = [NSData dataWithContentsOfURL:urlstr];//这一操作会比较耗时 //把数据转换成图片 UIImage *image = [UIImage imageWithData:data]; //2、回到主线程中设置图片 [self performSelectorOnMainThread:@selector(settingImage:) withObject:image waitUntilDone:NO];&#125;//设置显示图片- (void)settingImage:(UIImage *)image &#123; self.iconView.image = image;&#125;@end 代码2: 12345678910111213141516171819202122232425262728293031323334353637383940#import &quot;ViewController.h&quot;#import &lt;NSData.h&gt;@interface ViewController()@property (weak, nonatomic) IBOutlet UIImageView *iconView;@end@implementation ViewController- (void)viewDidLoad &#123; [super viewDidLoad];&#125;- (void)touchesBegan: (NSSet *)touches withEvent:(UIEvent *)event &#123; //在子线程中调用download方法下载图片 [self performSelectorInBackground:@selector(download) withObject:nil];&#125;- (void)download &#123; //1、根据url下载图片 //从网络下载图片 NSURL *urlstr = [NSURL URLWithString:@&quot;fdsf&quot;]; //把图片转换为二进制的数据 NSData *data = [NSData dataWithContentsOfURL:urlstr];//这一行操作比较耗时 //把数据转成图片 UIImage *image = [UIImage imageWithData:data]; //2、回到主线程设置图片 //第一种方式 //[self performSelectorOnMainThread:@selector(settingImage:) withObject:image waitUntilDone:NO]; //第二种方式 // [self.iconView performSelector:@selector(setImage:) onThread:[NSThread mainThread] withObject:image waitUntilDone:NO]; //第三种方式 [self.iconView performSelectorOnMainThread:@selector(setImage:) withObject:image waitUntilDone:NO];&#125;//设置显示图片//- (void)settingImage: (UIImage *)image &#123;// self.iconView.image = image;//&#125;@end 多线程之[pthread、NSThread]pthreadpthread简单介绍一下，pthread是一套通用的多线程API，可以在Unix/Linux/Windows等系统跨平台使用，使用C语言编写，需要程序员自己管理线程的生命周期，使用难度较大，所以我们在iOS开发中几乎不使用pthread。 引自百度百科POSIX线程(POSIX threads)，简称Pthreads，是线程的POSIX标准。该标准定义了创建和操纵线程的一整套API。在类Unix操作系统(Unix、Linux、Mac OS X等)中，都使用Pthreads作为操作系统的线程。Windows操作系统也有其移植版pthreads-win32. 引自维基百科POSIX线程(英语：POSIX Threads，常被缩写为Pthreads)是POSIX的线程标准，定义了创建和操纵线程的一套API。实现POSIX线程标准的库常被称为Pthreads，一般基于Unix-like POSIX系统，如Linux、Solaris。但是Microsoft Windows上的实现也存在，例如直接使用Windows API实现的第三方库pthreads-w32；而利用windows的SFU/SUA子系统，则可以使用微软提供的一部分原生POSIX API。 pthread的使用方法 首先要包含头文件#import &lt;pthread.h&gt; 其次要创建线程，并开启线程执行任务 1234567891011//创建线程：定义一个pthread_t类变量pthread_t thread;//开启线程--执行任务pthread_create(&amp;thread, NULL, run, NULL);void *run(void *param)&#123; //新线程调用方法，里边为需要执行的任务 NSLog(@&quot;%@&quot;, [NSThread currentThread]); return NULL;&#125; pthread_create(&amp;thread, NULL, run, NULL);中各项参数含义： 第一个参数&amp;thread是线程对象 第二个和第四个是线程属性，可赋值NULL 第三个run表示指向函数的指针(run对应函数里是需要在新线程中执行的任务) NSThread NSThread是苹果官方提供的，使用起来比pthread更加面向对象，简单易用，可以直接操作线程对象。不过也需要程序自己管理线程的生命周期(主要是创建)，我们在开发的过程中偶尔使用NSThread。比如我们会经常调用[NSThread currentThread]来显示当前的进程信息。 下边我们说说NSThread如何使用 1、创建、启动线程 先创建线程，再启动线程 12NSThread *thread = [[NSThread alloc] initWithTarget:self selector:@selector(run) object:nil];[thread start]; //线程一启动，就会在线程thread中执行self的run方法。 创建线程后自动启动线程 1[NSThread detachNewThreadSelector:@selector(run) toTarget:self withObject:nil]; 隐式创建并启动线程 1[self performSelectorInBackground:@selector(run) withObject:nil]; 2、线程相关用法 1234567891011121314151617181920//获得主线程+ (NSThread *)mainThread;//判断是否为主线程(对象方法)- (BOOL)isMainThread;//判断是否为主线程(类方法)+ (BOOL)isMainThread;//判断是否为主线程+ (BOOL)isMultiThreaded;//获取当前线程NSThread *current = [NSThread currentThread];//线程的名字-setter方法- (void)setName:(NSString *)n;//线程的名字-getter方法- (NSString *)name;//线程是否在执行- (BOOL)isExecuting;//线程是否被取消- (BOOL)isCancelled;//线程是否完成- (BOOL)isFinished; 3、线程状态控制方法 启动线程方法 12- (void)start;//线程进入就绪状态-&gt;运行状态。当线程任务执行完毕，自动进入死亡状态 阻塞(暂停)线程方法 123+ (void)sleepUntilDate:(NSDate *)date;+ (void)sleepForTimeInterval:(NSTimeInterval)ti;//线程进入阻塞状态 强制停止线程 12+ (void)exit;//线程进入死亡状态 4、线程的状态转换 当我们新建一条线程NSThread *thread = [[NSThread alloc] initWithTarget:self selector:@selector(run) object:nil];,在内存中表现为： 当调用[thread start];后，系统把线程对象放入可调度线程池中，线程对象进入就绪状态，如下图所示： 当然，可调度线程池中，会有其他的线程对象，如下图所示：（在这里我们只关心左边的线程对象） 下边我们来看看当前线程的状态转换： 如果CPU现在调度当前线程对象，则当前线程对象进入运行状态，如果CPU调度其他线程对象，则当前线程对象回到就绪状态。 如果CPU在运行当前线程对象的时候调用了sleep方法/等待同步锁，则当前线程对象就进入了阻塞状态，等到sleep到时/得到同步锁，则回到就绪状态。 如果CPU在运行当前线程对象的时候，线程任务执行完毕/异常强制退出，则当前线程对象进入死亡状态。 只看文字可能不太好理解，具体当前线程对象的状态变化如下图所示： GCDGCD简介什么是GCD呢？我们先来看看百度百科的解释简单了解下概念 引自百度百科Grand Central Dispatch(GCD)是Apple开发的一个多核编程的较新的解决方法。它主要用于优化应用程序以支持多核处理器以及其他对称多处理系统。它是一个在线程池模式的基础上执行的任务。在Mac OS X10.6雪豹中首次推出的，也可以在iOS4及以上版本使用 为什么要用GCD呢？ 因为GCD有很多好处啊，具体如下： GCD可用于多核的并行运算 GCD会自动利用更多的CPU内核（比如双核、四核） GCD会自动管理线程的生命周期（创建线程、调度任务、销毁线程） 程序员只需要告诉GCD想要执行什么任务，不需要编写任何线程管理代码 既然GCD有这么多的好处，那下面我们就来系统的学习一下GCD的使用方法。 任务和队列学习GCD之前，先来了解GCD中两个核心概念：任务和队列。任务：就是执行操作的意思，换句话说就是你在线程中执行的那段代码。在GCD中是放在block中的。执行任务有两种方式：同步执行和异步执行。两者的主要区别是：是否具有开启新线程的能力。 同步执行(sync)：只能在当前线程中执行任务，不具备开启新线程的能力。 异步执行(async)：可以在新的线程中执行任务，具备开启新线程的能力。 队列：这里的队列指任务队列，即用来存放任务的队列。队列是一种特殊的线性表，采用FIFO(先进先出)的原则，即新任务总是被插入到队列的末尾，而读取任务的时候总是从队列的头部开始读取。每读取一个任务，则从队列中释放一个任务。在GCD中有两种队列：串行队列和并行队列。 并行队列(Concurrent Dispatch Queue)：可以让多个任务并行（同时）执行（自动开启多个线程同时执行任务）。 并行功能只有在异步（dispatch_async）函数下才有效 串行队列（Serial Dispatch Queue）：让任务一个接一个的执行（一个任务执行完毕后，再执行下一个任务） GCD的使用步骤GCD的使用步骤其实很简单，只有两步。 创建一个队列（串行队列或者并行队列） 将任务添加到队列中，然后系统就会根据任务类型执行任务（同步执行或者异步执行） 下边来看看队列的创建方法和任务的创建方法 1、队列的创建方法 可以使用dispatch_queue_create来创建对象，需要传入两个参数，第一个参数表示队列的唯一标识符，用于debug，可为空；第二个参数用来识别是串行队列还是并行队列。DISPATCH_QUEUE_SERIAL表示串行队列，DISPATCH_QUEUE_CONCURRENT表示并行队列。 1234//串行队列的创建方法dispatch_queue_t queue = dispatch_queue_create(&quot;test.queue&quot;, DISPATCH_QUEUE_SERIAL);//并行队列的创建方法dispatch_queue_t queue = dispatch_queue_create(&quot;test.queue&quot;, DISPATCH_QUEUE_CONCURRENT); 对于并行队列，还可以使用dispatch_get_global_queue来创建全局并行队列。GCD默认提供了全局的并行队列，需要传入两个参数。第一个参数表示队列优先级，一般用DISPATCH_QUEUE_PRIORITY_DEFAULT。第二个参数暂时没用，用0表示即可。 2、任务的创建方法 123456789//同步执行任务创建方法dispatch_sync(queue, ^&#123; NSLog(@&quot;%@&quot;, [NSThread currentThread]);//这里放任何代码&#125;);//异步执行任务创建方法dispatch_async(queue, ^&#123; NSLog(@&quot;%@&quot;, [NSThread currentThread]);//这里放任何代码&#125;); 虽然使用GCD只需要两步，但是既然我们有两种队列，两种任务执行方式，那么我们就有了4种不同的组合方式。这四种不同的组合方式是： 1、并行队列 + 同步执行2、并行队列 + 异步执行3、串行队列 + 同步执行4、串行队列 + 异步执行 实际上，我们还有一种特殊的队列是主队列，那样就有6种不同的组合方式了。 5、主队列 + 同步执行6、主队列 + 异步执行 那么这几种不同组合方式各有什么区别呢？这里为了方便，先上结果，再来讲解。为图省事儿，直接查看表格结果。 并行队列 串行队列 主队列 同步(sync) 没有开启新线程，串行执行任务 没有开启新线程，串行执行任务 没有开启新线程，串行执行任务 异步(async) 有开启新线程，并行执行任务 有开启新线程(1条)，串行执行任务 没有开启新线程，串行执行任务 下边我们来分别看看那这几种组合方式的使用方法 GCD的基本使用并行队列的两种使用方法： 1、并行队列 + 同步执行 不会开启新线程，执行完一个任务，再执行下一个任务 1234567891011121314151617181920- (void)syncConcurrent &#123; NSLog(@&quot;syncConcurrent---begin&quot;); dispatch_queue_t queue = dispatch_queue_create(&quot;test.queue&quot;, DISPATCH_QUEUE_CONCURRENT); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;2------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;3------%@&quot;,[NSThread currentThread]); &#125; &#125;); NSLog(@&quot;syncConcurrent---end&quot;); 输出结果：2016-09-03 19:22:27.577 GCD[11557:1897538] syncConcurrent—begin2016-09-03 19:22:27.578 GCD[11557:1897538] 1——&lt;NSThread: 0x7f82a1d058b0&gt;{number = 1, name = main}2016-09-03 19:22:27.578 GCD[11557:1897538] 1——&lt;NSThread: 0x7f82a1d058b0&gt;{number = 1, name = main}2016-09-03 19:22:27.578 GCD[11557:1897538] 2——&lt;NSThread: 0x7f82a1d058b0&gt;{number = 1, name = main}2016-09-03 19:22:27.579 GCD[11557:1897538] 2——&lt;NSThread: 0x7f82a1d058b0&gt;{number = 1, name = main}2016-09-03 19:22:27.579 GCD[11557:1897538] 3——&lt;NSThread: 0x7f82a1d058b0&gt;{number = 1, name = main}2016-09-03 19:22:27.579 GCD[11557:1897538] 3——&lt;NSThread: 0x7f82a1d058b0&gt;{number = 1, name = main}2016-09-03 19:22:27.579 GCD[11557:1897538] syncConcurrent—end 从并行队列 + 同步执行中可以看到，所有任务都是在主线程中执行的。由于只有一个线程，所以任务只能一个一个的执行。 同时我们还可以看到，所有任务都在打印的syncConcurrent—begin和syncConcurrent—end之间，这说明任务是添加到队列中么马上执行的。 2、并行队列 + 异步执行 可同时开启多线程，任务交替完成 1234567891011121314151617181920- (void)asyncConcurrent &#123; NSLog(@&quot;asyncConcurrent---begin&quot;); dispatch_queue_t queue = dispatch_queue_create(&quot;test.queue&quot;, DISPATCH_QUEUE_CONCURRENT); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;2------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;3------%@&quot;,[NSThread currentThread]); &#125; &#125;); NSLog(@&quot;asyncConcurrent---end&quot;); 输出结果：2016-09-03 19:27:31.503 GCD[11595:1901548] asyncConcurrent—begin2016-09-03 19:27:31.504 GCD[11595:1901548] asyncConcurrent—end2016-09-03 19:27:31.504 GCD[11595:1901626] 1——&lt;NSThread: 0x7f8309c22080&gt;{number = 2, name = (null)}2016-09-03 19:27:31.504 GCD[11595:1901625] 2——&lt;NSThread: 0x7f8309f0b790&gt;{number = 4, name = (null)}2016-09-03 19:27:31.504 GCD[11595:1901855] 3——&lt;NSThread: 0x7f8309e1a950&gt;{number = 3, name = (null)}2016-09-03 19:27:31.504 GCD[11595:1901626] 1——&lt;NSThread: 0x7f8309c22080&gt;{number = 2, name = (null)}2016-09-03 19:27:31.504 GCD[11595:1901625] 2——&lt;NSThread: 0x7f8309f0b790&gt;{number = 4, name = (null)}2016-09-03 19:27:31.505 GCD[11595:1901855] 3——&lt;NSThread: 0x7f8309e1a950&gt;{number = 3, name = (null)} 在并行队列 + 异步执行中可以看出，除了主线程，又开启了3个线程，并且交替着同时执行。 另一方面可以看出，所有任务是在打印的asyncConcurrent—begin 和 asyncConcurrent—end之后才开始执行的。说明任务不是马上执行的，而是将所有任务添加到队列之后才开始异步执行的。 接下来看看串行队列的执行方法。 3、串行队列 + 同步执行 不会开启新线程，在当前线程执行任务。任务是串行的，执行完一个任务，再执行下一个任务 123456789101112131415161718192021- (void)syncSerial&#123; NSLog(@&quot;syncSerial----begin&quot;); dispatch_queue_t queue = dispatch_queue_create(&quot;test.queue&quot;, DISPATCH_QUEUE_SERIAL); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;2------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;3------%@&quot;,[NSThread currentThread]); &#125; &#125;); NSLog(@&quot;syncSerial---end&quot;);&#125; 输出结果为：2016-09-03 19:29:00.066 GCD[11622:1903904] syncSerial—begin2016-09-03 19:29:00.067 GCD[11622:1903904] 1——&lt;NSThread: 0x7fa2e9f00980&gt;{number = 1, name = main}2016-09-03 19:29:00.067 GCD[11622:1903904] 1——&lt;NSThread: 0x7fa2e9f00980&gt;{number = 1, name = main}2016-09-03 19:29:00.067 GCD[11622:1903904] 2——&lt;NSThread: 0x7fa2e9f00980&gt;{number = 1, name = main}2016-09-03 19:29:00.067 GCD[11622:1903904] 2——&lt;NSThread: 0x7fa2e9f00980&gt;{number = 1, name = main}2016-09-03 19:29:00.067 GCD[11622:1903904] 3——&lt;NSThread: 0x7fa2e9f00980&gt;{number = 1, name = main}2016-09-03 19:29:00.068 GCD[11622:1903904] 3——&lt;NSThread: 0x7fa2e9f00980&gt;{number = 1, name = main}2016-09-03 19:29:00.068 GCD[11622:1903904] syncSerial—end 在串行队列 + 同步执行可以看到，所有任务都是在主线程中执行的，并没有开启新的线程。而且由于串行队列，所以按顺序一个一个执行。 同时我们还可以看到，所有任务都在打印的syncSerial—begin和syncSerial—end之间，这说明任务是添加到队列中马上执行的。 4、串行队列 + 异步执行 会开启新线程，但是因为任务是串行的，执行完一个任务，再执行下一个任务 1234567891011121314151617181920212223- (void)asyncSerial&#123; NSLog(@&quot;asyncSerial---begin&quot;); dispatch_queue_t queue = dispatch_queue_create(&quot;test.queue&quot;, DISPATCH_QUEUE_SERIAL); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;2------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;3------%@&quot;,[NSThread currentThread]); &#125; &#125;); NSLog(@&quot;asyncSerial---end&quot;);&#125; 输出结果为：2016-09-03 19:30:08.363 GCD[11648:1905817] asyncSerial—begin2016-09-03 19:30:08.364 GCD[11648:1905817] asyncSerial—end2016-09-03 19:30:08.364 GCD[11648:1905895] 1——&lt;NSThread: 0x7fb548c0e390&gt;{number = 2, name = (null)}2016-09-03 19:30:08.364 GCD[11648:1905895] 1——&lt;NSThread: 0x7fb548c0e390&gt;{number = 2, name = (null)}2016-09-03 19:30:08.364 GCD[11648:1905895] 2——&lt;NSThread: 0x7fb548c0e390&gt;{number = 2, name = (null)}2016-09-03 19:30:08.364 GCD[11648:1905895] 2——&lt;NSThread: 0x7fb548c0e390&gt;{number = 2, name = (null)}2016-09-03 19:30:08.365 GCD[11648:1905895] 3——&lt;NSThread: 0x7fb548c0e390&gt;{number = 2, name = (null)}2016-09-03 19:30:08.365 GCD[11648:1905895] 3——&lt;NSThread: 0x7fb548c0e390&gt;{number = 2, name = (null)} 在串行队列 + 异步执行可以看到，开启了一个新线程，但是任务还是串行，所以任务是一个一个执行的。 另一方面可以看出，所有任务是在打印的asyncSerial—begin 和 asyncSerial—end之后才开始执行的。说明任务不是马上执行，而是将所有任务添加到队列之后才开始同步执行。 下面我们看看特殊的队列—主队列 主队列：GCD自带的一种特殊的串行队列 所有放在主队列中的任务，都会放到主线程中执行。可使用dispatch_get_main_queue()获得主队列 我们再看看主队列的两种组合方式 5、主队列 + 同步执行 互等卡住不可行（在主线程中调用） 123456789101112131415161718192021- (void)syncMain &#123; NSLog(@&quot;syncMain---begin&quot;); dispatch_queue_t = dispatch_get_main_queue(); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;2------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_sync(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;3------%@&quot;,[NSThread currentThread]); &#125; &#125;); NSLog(@&quot;syncMain---end&quot;);&#125; 输出结果2016-09-03 19:32:15.356 GCD[11670:1908306] syncMain—begin 这时候，我们惊奇的发现，在主线程中使用主队列 + 同步执行，任务不再执行了，而且syncMain—end也没有打印。这是为什么呢？ 这是因为我们在主线程中执行这段代码。我们把任务放到了主队列中，也就是放到了主线程的队列中。而同步执行有个特点，就是对于任务是立马执行的。那么当我们把第一个任务放进主队列中，它就会立马执行。但是主线程现在在处理syncMain方法，所以任务需要等syncMain执行完才能执行。而syncMain执行到第一个任务的时候，又要等第一个任务执行完才能往下执行第二个和第三个任务。 那么，现在的情况就是syncMain方法和第一个任务都在等对方执行完毕。这样大家互相等待。所以就卡住了，所以我们的任务执行不了，而且syncMain–end也没有打印。 如果不在主线程中调用，而在其他线程中调用会如何呢？ 不会开启新线程，执行完一个任务，再执行下一个任务(在其他线程中调用) 12345dispatch_queue_t queue = dispatch_queue_create(&quot;test.queue&quot;, DISPATCH_QUEUE_CONCURRENT);dispatch_async(queue, ^&#123; [self syncMain];&#125;); 输出结果：2016-09-03 19:32:45.496 GCD[11686:1909617] syncMain—begin2016-09-03 19:32:45.497 GCD[11686:1909374] 1——&lt;NSThread: 0x7faef2f01600&gt;{number = 1, name = main}2016-09-03 19:32:45.498 GCD[11686:1909374] 1——&lt;NSThread: 0x7faef2f01600&gt;{number = 1, name = main}2016-09-03 19:32:45.498 GCD[11686:1909374] 2——&lt;NSThread: 0x7faef2f01600&gt;{number = 1, name = main}2016-09-03 19:32:45.498 GCD[11686:1909374] 2——&lt;NSThread: 0x7faef2f01600&gt;{number = 1, name = main}2016-09-03 19:32:45.499 GCD[11686:1909374] 3——&lt;NSThread: 0x7faef2f01600&gt;{number = 1, name = main}2016-09-03 19:32:45.499 GCD[11686:1909374] 3——&lt;NSThread: 0x7faef2f01600&gt;{number = 1, name = main}2016-09-03 19:32:45.499 GCD[11686:1909617] syncMain—end 在其他线程中使用主队列+同步执行可看到：所有的任务都是在主线程中执行的，并没有开启新的线程。而且由于主队列是串行队列，所以按照顺序一个一个执行。 同时我们还可以看到，所有任务都在打印的syncConcurrent—begin和syncConcurrent—end之间，这说明任务是添加到队列中马上执行的。 6、主队列 + 异步执行 只在主线程中执行任务，执行完一个任务，再执行下一个任务 12345678910111213141516171819202122- (void)asyncMain &#123; NSLog(@&quot;asyncMain--begin&quot;); dispatch_queue_t queue = dispatch_get_main_queue(); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;2------%@&quot;,[NSThread currentThread]); &#125; &#125;); dispatch_async(queue, ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;3------%@&quot;,[NSThread currentThread]); &#125; &#125;); NSLog(@&quot;asyncMain---end&quot;);&#125; 输出结果：2016-09-03 19:33:54.995 GCD[11706:1911313] asyncMain—begin2016-09-03 19:33:54.996 GCD[11706:1911313] asyncMain—end2016-09-03 19:33:54.996 GCD[11706:1911313] 1——&lt;NSThread: 0x7fb623d015e0&gt;{number = 1, name = main}2016-09-03 19:33:54.997 GCD[11706:1911313] 1——&lt;NSThread: 0x7fb623d015e0&gt;{number = 1, name = main}2016-09-03 19:33:54.997 GCD[11706:1911313] 2——&lt;NSThread: 0x7fb623d015e0&gt;{number = 1, name = main}2016-09-03 19:33:54.997 GCD[11706:1911313] 2——&lt;NSThread: 0x7fb623d015e0&gt;{number = 1, name = main}2016-09-03 19:33:54.997 GCD[11706:1911313] 3——&lt;NSThread: 0x7fb623d015e0&gt;{number = 1, name = main}2016-09-03 19:33:54.997 GCD[11706:1911313] 3——&lt;NSThread: 0x7fb623d015e0&gt;{number = 1, name = main} 我们发现所有任务都在主线程中，虽然异步执行，具备开启线程的能力，但因为是主队列，所以所有任务都在主线程中，并且一个接一个执行。 另一方面可以看出，所有任务是在打印的asyncMain—begin和asyncMain—end之后才开始执行的。说明任务不是马上执行，而是将所有任务添加到队列之后才开始同步执行。 弄懂了难理解、绕来绕去的队列 + 任务之后，我们来看看一个简单的东西–GCD线程之间的通信 GCD线程之间的通讯在iOS开发过程中，我们一般在主线程里边进行UI刷新，例如：点击、滚动、拖拽等事件。我们通常把一些耗时的操作放在其它线程，比如说图片下载、文件上传等耗时操作。而当我们有时候在其他线程完成了耗时操作时，需要回到主线程，那么就用到了线程之间的通讯。 12345678910dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1------%@&quot;,[NSThread currentThread]); &#125; // 回到主线程 dispatch_async(dispatch_get_main_queue(), ^&#123; NSLog(@&quot;2-------%@&quot;,[NSThread currentThread]); &#125;);&#125;); 输出结果：2016-09-03 19:34:59.165 GCD[11728:1913039] 1——&lt;NSThread: 0x7f8319c06820&gt;{number = 2, name = (null)}2016-09-03 19:34:59.166 GCD[11728:1913039] 1——&lt;NSThread: 0x7f8319c06820&gt;{number = 2, name = (null)}2016-09-03 19:34:59.166 GCD[11728:1912961] 2——-&lt;NSThread: 0x7f8319e00560&gt;{number = 1, name = main} 可以看到在其他线程中先执行操作，执行完了之后回到主线程执行主线程的相应操作。 GCD其他方法1、GCD的栅栏方法 dispatch_barrier_async 我们有时需要异步执行两组操作，而且第一组操作执行完之后，才能开始执行第二组操作。这样我们就需要一个相当于栅栏一样的一个方法将两组异步执行的操作组给分割起来，当然这里的操作组里可以包含一个或多个任务。这就需要用到dispatch_barrier_async方法在两个操作组间形成栅栏。 12345678910111213141516171819202122- (void)barrier&#123; dispatch_queue_t queue = dispatch_queue_create(&quot;12312312&quot;, DISPATCH_QUEUE_CONCURRENT); dispatch_async(queue, ^&#123; NSLog(@&quot;----1-----%@&quot;, [NSThread currentThread]); &#125;); dispatch_async(queue, ^&#123; NSLog(@&quot;----2-----%@&quot;, [NSThread currentThread]); &#125;); dispatch_barrier_async(queue, ^&#123; NSLog(@&quot;----barrier-----%@&quot;, [NSThread currentThread]); &#125;); dispatch_async(queue, ^&#123; NSLog(@&quot;----3-----%@&quot;, [NSThread currentThread]); &#125;); dispatch_async(queue, ^&#123; NSLog(@&quot;----4-----%@&quot;, [NSThread currentThread]); &#125;);&#125; 输出结果：2016-09-03 19:35:51.271 GCD[11750:1914724] —-1—–&lt;NSThread: 0x7fb1826047b0&gt;{number = 2, name = (null)}2016-09-03 19:35:51.272 GCD[11750:1914722] —-2—–&lt;NSThread: 0x7fb182423fd0&gt;{number = 3, name = (null)}2016-09-03 19:35:51.272 GCD[11750:1914722] —-barrier—–&lt;NSThread: 0x7fb182423fd0&gt;{number = 3, name = (null)}2016-09-03 19:35:51.273 GCD[11750:1914722] —-3—–&lt;NSThread: 0x7fb182423fd0&gt;{number = 3, name = (null)}2016-09-03 19:35:51.273 GCD[11750:1914724] —-4—–&lt;NSThread: 0x7fb1826047b0&gt;{number = 2, name = (null)} 可以看出在执行完栅栏前面的操作之后，才执行栅栏操作，最后再执行栅栏后边的操作。 2、GCD延时执行方法 dispatch_after 当我们需要延迟执行一段代码时，就需要用到GCD的dispatch_after方法 1234dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(2.0 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^&#123; // 2秒后异步执行这里的代码... NSLog(@&quot;run-----&quot;);&#125;); 3、GCD的一次性代码（只执行一次）dispatch_once *我们在创建单例、或者有整个程序运行过程中只执行一次的代码时，我们就用到了GCD的dispatch_once方法。使用dispatch_once函数能保证某段代码在程序运行过程中只执行1次。 1234static dispatch_once_t onceToken;dispatch_once(&amp;onceToken, ^&#123; // 只执行1次的代码(这里面默认是线程安全的)&#125;); 4、GCD的快速迭代方法 dispatch_apply 通常我们会for循环遍历，但是GCD给我们提供了快速迭代的方法dispatch_apply，使我们可以同时遍历。dispatch_apply可以同时遍历多个数字。 12345dispatch_queue_t queue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0);dispatch_apply(6, queue, ^(size_t index) &#123; NSLog(@&quot;%zd------%@&quot;,index, [NSThread currentThread]);&#125;); 输出结果：2016-09-03 19:37:02.250 GCD[11764:1915764] 1——&lt;NSThread: 0x7fac9a7029e0&gt;{number = 1, name = main}2016-09-03 19:37:02.250 GCD[11764:1915885] 0——&lt;NSThread: 0x7fac9a614bd0&gt;{number = 2, name = (null)}2016-09-03 19:37:02.250 GCD[11764:1915886] 2——&lt;NSThread: 0x7fac9a542b20&gt;{number = 3, name = (null)}2016-09-03 19:37:02.251 GCD[11764:1915764] 4——&lt;NSThread: 0x7fac9a7029e0&gt;{number = 1, name = main}2016-09-03 19:37:02.250 GCD[11764:1915884] 3——&lt;NSThread: 0x7fac9a76ca10&gt;{number = 4, name = (null)}2016-09-03 19:37:02.251 GCD[11764:1915885] 5——&lt;NSThread: 0x7fac9a614bd0&gt;{number = 2, name = (null)} 从输出结果中前边的时间中可以看出，几乎是同时便利的。 5、GCD的队列组 dispatch_group *有时候我们会有这样的需求：分别异步执行2个耗时操作，然后当2个耗时操作都执行完毕后再回到主线程执行操作。这时候我们可以用到GCD的队列组。 我们可以先把任务放到队列中，然后将队列放入队列组中 调用队列组的dispatch_group_notify回到主线程执行操作。 12345678910111213dispatch_group_t group = dispatch_group_create();dispatch_group_async(group, dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^&#123; // 执行1个耗时的异步操作&#125;);dispatch_group_async(group, dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^&#123; // 执行1个耗时的异步操作&#125;);dispatch_group_notify(group, dispatch_get_main_queue(), ^&#123; // 等前面的异步操作都执行完毕后，回到主线程...&#125;); 6、GCD dispatch_semaphore 信号量在GCD中提供了一种信号机制，也可以解决资源抢占问题（和同步锁的机制并不一样）。 GCD中信号量是dispatch_semaphore_t类型，支持信号通知和信号等待。每当发送一个信号通知，则信号量+1，每当发送一个等待信号时信号量-1。如果信号量为0则信号会处于等待状态，直到信号量大于0开始执行。根据这个原理我们可以初始化一个信号量变量，默认信号量设为1，每当有线程进入“加锁代码”之后就调用信号等待命令（此时信号量为0）开始等待，此时其他线程无法加入，执行完毕之后发送信号通知（此时信号量为1），其他线程开始进入执行，如此就达到了线程同步的目的。 12345678910111213141516171819202122dispatch_queue_t globalQueue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0); //设置等待超时时间（5秒） dispatch_time_t timeOutCount = dispatch_time(DISPATCH_TIME_NOW, 5ull * NSEC_PER_SEC); //设置等待超时时间(一直等下去) //dispatch_time_t timeOutCount = DISPATCH_TIME_FOREVER; //初始化信号量,参数是信号量初始值 dispatch_semaphore_t semaphore= dispatch_semaphore_create(1); dispatch_async(globalQueue, ^&#123; if (dispatch_semaphore_wait(semaphore, timeOutCount) != 0) &#123; //等待超时后处理 //show error alertView on main Thread or something else... &#125; else &#123; //&quot;加锁代码&quot; //do something... dispatch_semaphore_signal(semaphore);//信号通知（信号量+1） &#125; &#125;); 上述代码中用到的三个重要函数的具体介绍： dispatch_semaphore_create() 创建信号量。传入的参数为long型，且必须大于或者等于0，否则函数返回NULL。 dispatch_semaphore_wait() 方法为信号等待。如果信号量值为0，那么这个函数就阻塞当前线程等待timeOutCount,如果等待期间信号量大于0，则开始执行“加锁代码”，同时会使信号量-1。这个方法的返回值是当成功时则返回0，超时失败时则返回非0值。 dispatch_semaphore_signal() 方法会使信号量+1。返回值为long类型，当返回值为0时表示当前并没有线程等待其处理的信号量，其处理的信号量的值加1即可。当返回值不为0时，表示其当前有（一个或多个）线程等待其处理的信号量，并且该函数唤醒了一个等待的线程（当线程有优先级时，唤醒优先级最高的线程，否则随机唤醒）。 NSOperationNSOperation简介NSOperation是苹果提供给我们的一套多线程解决方案。实际上NSOperation是基于GCD更高一层的封装，但是比GCD更简单易用，代码可读性也高。NSOperation需要配合NSOperationQueue来实现多线程。因为默认情况下，NSOperation单独使用时系统同步执行操作，并没有开辟新线程的能力，只有配合NSOperationQueue才能实现异步操作。因为NSOperation是基于GCD的，那么使用起来也和GCD差不多，其中，NSOperation相当于GCD中的任务，而NSOperationQueue则相当于GCD中的队列。NSOperation实现多线程的使用步骤分为三步： 创建任务：现将需要执行的操作封装到一个NSOperation对象中。 创建队列：创建NSOperationQueue对象。 将任务加到队列中：然后将NSOperation对象添加到NSOperationQueue中。 之后呢，系统就会自动将NSOperationQueue中的NSOperation取出来，在新线程中执行操作。下面我们来看看NSOperation和NSOperationQueue的基本使用。 NSOperation和NSOperationQueue的基本使用1、创建任务NSOperation是个抽象类，并不能封装任务。我们只有使用它的子类来封装任务。我们有三种方式来封装任务。 使用子类NSInvocationOperation 使用子类NSBlockOperation 定义继承自NSOperation的子类，通过实现内部相应的方法来封装任务。 在不使用NSOperationQueue，单独使用NSOperation的情况下系统同步执行操作，下面我们看看以下任务的三种创建方式。 （1）、使用子类- NSInvocationOperation： 12345678//1、创建NSInvocationOperation对象NSInvocationOperation *op = [[NSInvocationOperation alloc] initWithTarget:self selector:@selector(run) object:nil];//2、调用start方法开始执行操作[op start];- (void)run &#123; NSLog(@&quot;------%@&quot;, [NSThread currentThread]);&#125; 输出结果：2016-09-05 14:29:58.483 NSOperation[15834:2384555] ——&lt;NSThread: 0x7fa3e2e05410&gt;{number = 1, name = main} 从中可以看到，在没有使用NSOperationQueue、单独使用NSInvocationOperation的情况下，NSInvocationOperation在主线程操作，并没有开启新线程。 （2）、使用子类- NSBlockOperation 123456NSBlockOperation *op = [NSBlockOperation blockOperationWithBlock:^&#123; //在主线程 NSLog(@&quot;-----%@&quot;, [NSThread currentThread]);&#125;];[op start]; 输出结果：2016-09-05 14:33:15.268 NSOperation[15884:2387780] ——&lt;NSThread: 0x7fb2196012c0&gt;{number = 1, name = main} 我们同样可以看到，在没有使用NSOperationQueue、单独使用NSBlockOperation的情况下，NSBlockOperation也是在主线程执行操作，并没有开启新线程。 但是，NSBlockOperation还提供了一个方法addExecutionBlock：，通过addExecutionBlock：就可以为NSBlockOperation添加额外的操作，这些额外的操作就会在其他线程并发执行。 12345678910111213141516171819- (void)blockOperation &#123; NSBlockOperation *op = [NSBlockOperation blockOperationWithBlock:^&#123; //在主线程 NSLog(@&quot;1--------%@&quot;, [NSThread currentThread]); &#125;]; //添加额外的任务(在子线程执行) [op addExecutionBlock:^&#123; NSLog(@&quot;2--------%@&quot;, [NSThread currentThread]); &#125;]; [op addExecutionBlock:^&#123; NSLog(@&quot;3--------%@&quot;, [NSThread currentThread]); &#125;]; [op addExecutionBlock:^&#123; NSLog(@&quot;4--------%@&quot;, [NSThread currentThread]); &#125;]; [op start];&#125; 输出结果：2016-09-05 14:36:59.353 NSOperation[15896:2390616] 1——&lt;NSThread: 0x7ff633f03be0&gt;{number = 1, name = main}2016-09-05 14:36:59.354 NSOperation[15896:2390825] 2——&lt;NSThread: 0x7ff633e24600&gt;{number = 2, name = (null)}2016-09-05 14:36:59.354 NSOperation[15896:2390657] 3——&lt;NSThread: 0x7ff633c411e0&gt;{number = 3, name = (null)}2016-09-05 14:36:59.354 NSOperation[15896:2390656] 4——&lt;NSThread: 0x7ff633f1d3e0&gt;{number = 4, name = (null)} 可以看出，blockOperationWithBlock:方法中的操作是在主线程中执行的，而addExecutionBlock：方法中的操作是在其他线程中执行的。 （3）、定义继承自NSOperation的子类先定义一个继承自NSOperation的子类，重写main方法 12345678910111213141516#import &lt;Foundation/Foundation.h&gt;@interface YSCOperation : NSOperation@end#import &quot;YSCOperation.h&quot;@implementation YSCOperation/** *需要执行的任务 */ - (void)main &#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1-------%@&quot;, [NSThread currentThread]); &#125; &#125;@end 然后使用的时候导入头文件YSCOperation.h 1234//创建YSCOperationYSCOperation *op1 = [[YSCOperation alloc] init];[op1 start]; 输出结果：2016-09-05 18:15:59.674 NSOperation[16566:2501606] 1—–&lt;NSThread: 0x7f8030d05150&gt;{number = 1, name = main}2016-09-05 18:15:59.675 NSOperation[16566:2501606] 1—–&lt;NSThread: 0x7f8030d05150&gt;{number = 1, name = main} 可以看出：在没有使用NSOperationQueue、单独使用自定义子类的情况下，是在主线程执行操作、并没有开启新线程。下边我们简单讲讲NSOperationQueue的创建 2、创建队列和GCD中的并发队列、串行队列略有不同的是NSOperationQueue一共有两种队列：主队列、其他队列。其中其他队列包含了串行、并发功能。下面是主队列、其他队列的基本创建方法和特点。 主队列 凡是添加到主队列中的任务(NSOperation)，都会放倒主线程中执行 1NSOperationQueue *queue = [NSOperationQueue mainQueue]; 其他队列(非主队列) 添加到这种队列中的任务(NSOperation)，就会自动放到子线程中执行； 同时包含了：串行、并发功能 1NSOperationQueue *queue = [[NSOperationQueue alloc] init]; 3、将任务加入到队列中前边说了，NSOperation需要配合NSOperationQueue来实现多线程。那么我们需要将创建好的任务加入到队列中去。总共有两种方法： - (void)addOperation:(NSOperation *)op; 需要先创建任务，再将创建好的任务加入到创建好的队列中去 1234567891011121314151617181920212223- (void)addOperation:(NSOperation *)op &#123; //1、创建队列 NSOperationQueue *queue = [[NSOperationQueue alloc] init]; //2、创建操作 //创建NSInvocationOperation NSInvocationOperation *op1 = [[NSInvocationOperation alloc] initWithTarget:self selector:@selector(run) object:nil]; //创建NSBlockOperation NSBlockOperation *op2 = [NSBlockOperation blockOperationWithBlock:^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;1-------%@&quot;, [NSThread currentThread]); &#125; &#125;]; //3、添加操作到队列中：addOperation: [queue addOperation:op1]; [queue addOperation:op2];&#125;- (void)run &#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;2-------%@&quot;, [NSThread currentThread]); &#125;&#125; 输出结果：2016-09-05 17:06:00.241 NSOperationQueue[16201:2452281] 1—–&lt;NSThread: 0x7fe4824080e0&gt;{number = 3, name = (null)}2016-09-05 17:06:00.241 NSOperationQueue[16201:2452175] 2—–&lt;NSThread: 0x7fe482404a50&gt;{number = 2, name = (null)}2016-09-05 17:06:00.242 NSOperationQueue[16201:2452175] 2—–&lt;NSThread: 0x7fe482404a50&gt;{number = 2, name = (null)}2016-09-05 17:06:00.241 NSOperationQueue[16201:2452281] 1—–&lt;NSThread: 0x7fe4824080e0&gt;{number = 3, name = (null)} 可以看出：NSInvocationOperation和NSOperationQueue结合后能够开启新线程，进行并发执行NSBlockOperation和NSOperationQueue也能够开启新线程，进行并发执行。 2.- (void)addOperationWithBlock:(void (^)(void))block; 无需先创建任务，在block中添加任务，直接将任务block加入到队列中。 1234567891011- (void)addOperationWithBlockToQueue &#123; //1、创建对联 NSOperationQueue *queue = [[NSOperationQueue alloc] init]; //2、添加操作到队列中：addOperationWithBlock: [queue addOperationWithBlock:^&#123; for (int i = 0; i &lt; 2; ++i) &#123; NSLog(@&quot;-------%@&quot;, [NSThread currentThread]); &#125; &#125;];&#125; 输出结果：2016-09-05 17:10:47.023 NSOperationQueue[16293:2457487] —–&lt;NSThread: 0x7ffa6bc0e1e0&gt;{number = 2, name = (null)}2016-09-05 17:10:47.024 NSOperationQueue[16293:2457487] —–&lt;NSThread: 0x7ffa6bc0e1e0&gt;{number = 2, name = (null)} 可以看出addOperationWithBlock:和NSOperationQueue能够开启新线程，进行并发执行。 4、控制串行执行和并发执行的关键之前我们说过，NSOperationQueue创建的其他队列同时具有串行、并发功能，上边我们演示了并发功能，那么他的串行功能是如何实现的？这里有个关键参数maxConcurrentOperationCount，叫做最大并发数。 最大并发数：maxConcurrentOperationCountmaxConcurrentOperationCount默认情况下为-1，表示不进行限制，默认并发执行。当maxConcurrentOperationCount为1时，进行串行执行。当maxConcurrentOperationCount大于1时，进行并发执行，当然这个值不应该超过系统限制，即使自己设置一个很大的值，系统也会自动调整。 123456789101112131415161718192021222324252627282930313233- (void)operationQueue &#123; //创建队列 NSOperationQueue *queue = [[NSOperationQueue alloc] init]; //设置最大并发操作数 //queue.maxConcurrentOperationCount = 2; queue.maxConcurrentOperationCount = 1;//就变成了串行队列 //添加操作 [queue addOperationWithBlock:^&#123; NSLog(@&quot;1------%@&quot;, [NSThread currentThread]); [NSThread sleepForTimeInterval:0,01]; &#125;]; [queue addOperationWithBlock:^&#123; NSLog(@&quot;2------%@&quot;, [NSThread currentThread]); [NSThread sleepForTimeInterval:0,01]; &#125;]; [queue addOperationWithBlock:^&#123; NSLog(@&quot;3------%@&quot;, [NSThread currentThread]); [NSThread sleepForTimeInterval:0,01]; &#125;]; [queue addOperationWithBlock:^&#123; NSLog(@&quot;4------%@&quot;, [NSThread currentThread]); [NSThread sleepForTimeInterval:0,01]; &#125;]; [queue addOperationWithBlock:^&#123; NSLog(@&quot;5------%@&quot;, [NSThread currentThread]); [NSThread sleepForTimeInterval:0,01]; &#125;]; [queue addOperationWithBlock:^&#123; NSLog(@&quot;6------%@&quot;, [NSThread currentThread]); [NSThread sleepForTimeInterval:0,01]; &#125;];&#125; 最大并发数为1输出结果：2016-09-05 17:21:54.124 NSOperationQueue[16320:2464630] 1—–&lt;NSThread: 0x7fc892d0b3a0&gt;{number = 2, name = (null)}2016-09-05 17:21:54.136 NSOperationQueue[16320:2464631] 2—–&lt;NSThread: 0x7fc892c0a7b0&gt;{number = 3, name = (null)}2016-09-05 17:21:54.148 NSOperationQueue[16320:2464630] 3—–&lt;NSThread: 0x7fc892d0b3a0&gt;{number = 2, name = (null)}2016-09-05 17:21:54.160 NSOperationQueue[16320:2464631] 4—–&lt;NSThread: 0x7fc892c0a7b0&gt;{number = 3, name = (null)}2016-09-05 17:21:54.171 NSOperationQueue[16320:2464631] 5—–&lt;NSThread: 0x7fc892c0a7b0&gt;{number = 3, name = (null)}2016-09-05 17:21:54.184 NSOperationQueue[16320:2464630] 6—–&lt;NSThread: 0x7fc892d0b3a0&gt;{number = 2, name = (null)} 最大并发数为2输出结果：2016-09-05 17:23:36.030 NSOperationQueue[16331:2466366] 2—–&lt;NSThread: 0x7fd729f0f270&gt;{number = 3, name = (null)}2016-09-05 17:23:36.030 NSOperationQueue[16331:2466491] 1—–&lt;NSThread: 0x7fd729f4e290&gt;{number = 2, name = (null)}2016-09-05 17:23:36.041 NSOperationQueue[16331:2466367] 3—–&lt;NSThread: 0x7fd729d214e0&gt;{number = 4, name = (null)}2016-09-05 17:23:36.041 NSOperationQueue[16331:2466366] 4—–&lt;NSThread: 0x7fd729f0f270&gt;{number = 3, name = (null)}2016-09-05 17:23:36.053 NSOperationQueue[16331:2466366] 6—–&lt;NSThread: 0x7fd729f0f270&gt;{number = 3, name = (null)}2016-09-05 17:23:36.053 NSOperationQueue[16331:2466511] 5—–&lt;NSThread: 0x7fd729e056c0&gt;{number = 5, name = (null)} 5、操作依赖NSOperation和NSOperationQueue最吸引人的地方是它能添加操作之间的依赖关系。比如说有A、B两个操作，其中A执行完操作，B才能执行操作，那么就需要让B依赖于A。具体如下： 1234567891011121314- (void)addDependency &#123; NSOperationQueue *queue = [[NSOperationQueue alloc] init]; NSBlockOperation *op1 = [NSBlockOperation blockOperationWithBlock:^&#123; NSLog(@&quot;1-----%@&quot;, [NSThread currentThread]); &#125;]; NSBlockOperation *op2 = [NSBlockOperation blockOperationWithBlock:^&#123; NSLog(@&quot;2-----%@&quot;, [NSThread currentThread]); &#125;]; [op2 addDepenDency:op1]; // 让op2 依赖于 op1，则先执行op1，在执行op2 [queue addOperation:op1]; [queue addOperation:op2];&#125; 输出结果：2016-09-05 17:51:28.811 操作依赖[16423:2484866] 1—–&lt;NSThread: 0x7fc138e1e7c0&gt;{number = 2, name = (null)}2016-09-05 17:51:28.812 操作依赖[16423:2484866] 2—–&lt;NSThread: 0x7fc138e1e7c0&gt;{number = 2, name = (null)} 可以看到，无论运行几次，其结果都是op1先执行，op2后执行。 6、一些其他方法 - (void)cancel;NSOperation提供的方法，可取消单个操作 - (void)cancelAllOperations;NSOperationQueue提供的方法，可以取消队列的所有操作 - (void)setSuspended:(BOOL)b;可设置任务的暂停和恢复，YES代表暂停队列，NO代表恢复队列 - (BOOL)isSuspended;判断暂停状态 注意： 这里的暂停和取消并不代表可以将当前的操作立即取消，而是当当前的操作执行完毕之后不再执行新的操作。 暂停和取消的区别在于：暂停操作之后还可以恢复操作，继续向下执行；而取消操作之后，所有的操作就清空了，无法再接着执行剩下的操作。","categories":[{"name":"iOS 深入学习","slug":"iOS-深入学习","permalink":"http://yoursite.com/categories/iOS-深入学习/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"}]},{"title":"iOS深入学习 - RunLoop","slug":"2017-10-9-runLoop","date":"2017-10-08T16:00:00.000Z","updated":"2019-07-24T04:02:28.327Z","comments":true,"path":"2017-10-9-runLoop/","link":"","permalink":"http://yoursite.com/2017-10-9-runLoop/","excerpt":"","text":"RunLoop概念：原文作者Blog地址点这里。一般来讲一个线程只能执行一个任务，执行完成后线程就会退出。如果我们需要一个机制，让线程能随时执行任务但不退出，代码逻辑通常如下：runloop处理事件的代码逻辑模拟（Event Loop） 1234567function loop() &#123; initialize(); do &#123; var message = get_next_messsage(); process_message(message); &#125; while (message != quite);&#125; 注意：实现这种模型的关键点在于：如何管理事件/消息，如何让线程在没有处理消息时休眠以避免资源占用、在有消息到来时立即被唤醒 1、OSX/iOS系统中提供了两个对象：NSRunLoop、CFRunLoopRef。CFRunLoopRef是在CoreFoundation框架内的，它提供了纯C函数的API，所有这些API都是线程安全的。NSRunLoop是基于CFRunLoopRef封装的，提供了面向对象的API，但是这些API不是线程安全的。 CFRunLoopRef源码 跨平台的CoreFoundation版本源码 RunLoop与线程的关系iOS开发中可能遇到两个线程对象：pthread_t和NSThread。过去苹果有份文档/tn/tn2028.html)标明了NSThread只是pthread_t的封装，但是那份文档已经失效了，现在它们也有可能都是直接包装自最底层的mach thread。苹果没有提供这两个对象相互转换的接口，但不管怎么样，可以肯定的是pthread_t和NSThread是一一对应的。比如，可以通过pthread_main_thread_np()或者[NSThread mainThread]来获取主线程；也可以通过pthread_self()或者[NSThread currentThread]来获取当前线程。CFRunLoop基于pthread来管理的。 苹果不允许直接创建RunLoop，它只提供了两个自动获取的函数：CFRunLoopGetMain() 和 CFRunLoopGetCurrent()。这两个函数内部的逻辑大概如下： 12345678910111213141516171819202122232425262728293031323334353637//全局的Dictionary，key是pthread_t, value是CFRunLoopRefstatic CFMutableDictionaryRef loopsDic;//访问loopsDic时的锁static CFSpinLock_t loopsLock;//获取一个pthread对应的RunloopCFRunLoopRef _CFRunLoopGet(pthread_t thread) &#123; OSSpinLockLock(&amp;loopsLock); if (!loopsDic) &#123; //第一次进入时，初始化全局Dic，并先为主线程创建一个RunLoop。 loopsDic = CFDictionaryCreateMutable(); CFRunLoopRef mainLoop = _CFRunLoopCreate(); CFDictionarySetValue(loopsDic, pthread_main_thread_np(), mainLoop); &#125; ///直接从Dictionary里获取 CFRunLoopRef loop = CFDictionaryGetValue(loopsDic, thread); if (!loop) &#123; ///取不到，创建一个 loop = _CFRunLoopCreate(); CFDictionarySetValue(loopsDic, thread, loop); ///注册一个回调，当线程销毁时，顺便也销毁对应的RunLoop _CFSetTSD(..., thread, loop, __CFFinalizeRunLoop); &#125; OSSPinLockUnlock(&amp;loopsLock); return loop;&#125;CFRunLoopRef CFRunLoopGetMain() &#123; return _CFRRunLoopGet(pthread_main_thread_np());&#125;CFRunLoopRef CFRunLoopGetCurrent() &#123; return _CFRunLoopGet(pthread_self());&#125; 从上面的代码可以看出，线程和RunLoop之间是一一对应的，其关系是保存在一个全局的Dictionary里。线程刚创建时并没有RunLoop，如果你不主动获取，拿它一直不会有。RunLoop的创建是发生在第一次获取时，RunLoop的销毁是发生在线程结束时。你只能在一个线程的内部获取其RunLoop（主线程除外） RunLoop对外的接口在CoreFoundation里面关于RunLoop有5个类： CFRunLoopRef CFRunLoopModeRef CFRunLoopSourceRef CFRunLoopTimerRef CFRunLoopObserverRef 其中CFRunLoopModeRef类并没有对外暴露，只是通过CFRunLoopRef的接口进行了封装。他们的关系如下： 一个RunLoop包含若干个Mode，每个Mode又包含若干个Source/Timer/Observer。每次调用RunLoop的主函数时，只能指定其中一个Mode，这个Mode被称作CurrentMode。如果需要切换Mode，只能退出Loop，再重新指定一个Mode进入。这样做主要是为了分隔开不同组的Source/Timer/Observer，让其互不影响。 CFRunLoopSourceRef是事件产生的地方。Source有两个版本：Source0和Source1. Source0 只包含了一个回调（函数指针），它并不能主动触发事件。使用时，你需要先调用CFRunLoopSourceSignal(source)，将这个Source标记为待处理，然后手动调用CFRunLoopWakeUp(runloop)来唤醒RunLoop，让其处理这个事件。 Source1包含了一个mach_port和一个回调（函数指针），被用于通过内核和其它线程互相发送消息。这种Source能主动唤醒RunLoop的线程，其原理下面会讲到。 CFRunLoopTimerRef是基于时间的触发器， 它和NSTimer是toll_free bridged（对象桥接）的，可以混用。其包含一个时间长度和一个回调（函数指针）。当其加入到RunLoop时，RunLoop会注册对应的时间点，当时间点到时，RunLoop会被唤醒已执行那个回调。 CFRunLoopObserverRef是观察者，每个Observer都包含了一个回调（函数指针），当RunLoop的状态发生变化的时候，观察者就能通过回调接受这个变化。可以观测的时间点有以下几个： 12345678typedef CF_OPTIONS(CFOptionFlags, CFRunLoopActivity) &#123; kCFRunLoopEntry = (1UL &lt;&lt; 0), //即将进入Loop kCFRunLoopBeforeTimers = (1UL &lt;&lt; 1), //即将处理Timer kCFRunLoopBeforeSources = (1UL &lt;&lt; 2), //即将处理Source kCFRunLoopBeforeWaiting = (1UL &lt;&lt; 5), //即将进入休眠 kCFRunLoopAfterWaiting = (1UL &lt;&lt; 6), //刚冲休眠中唤醒 kCFRunLoopExit = (1UL &lt;&lt; 7), //即将退出Loop&#125; 上面的Source/Timer/Observer被统称为mode item， 一个item可以被同时加入多个mode。但是一个item被重复加入同一个mode时是不会有效果的。如果一个mode中一个item都没有，则RunLoop会直接退出，不会进入循环。 RunLoop的ModeCFRunLoopMode和CFRunLoop的结构大致如下： 123456789101112131415struct __CFRunLoopMode &#123; CFStringRef _name; // Mode Name, 例如 @&quot;kCFRunLoopDefaultMode&quot; CFMutableSetRef _source0; CFMutableSetRef _source1; CFMutableArrayRef _observers; CFMutableArrayRef _timers; ...&#125;struct __CFRunLoop &#123; CFMutableSetRef _commonModes; CFMutableSetRef _commonModeItems; // Set&lt;Source/Observer/Timer&gt; CFRunLoopModeRef _currentMode; // Current Runloop Mode CFMutableSetRef _modes;&#125; 这里有个概念叫“CommonModes”：一个Mode可以将自己标为“Common”属性（通过将其ModeName添加到RunLoop的“commonModes”中）。每当RunLoop的内容发生变化时，RunLoop都会自动将_commonModeItems里的Source/Timer/Observer同步到具有“Common”标记的所有Mode里。 应用场景举例：主线程的RunLoop里有两个预置的Mode：kCFRunLoopDefaultMode和UITrackingRunLoopMode。这两个Mode都已经被标记为“Common”属性。DefaultMode是APP平时所处的状态，TrackingRunLoopMode是追踪ScrollView滑动时的状态。当你创建一个Timer并追加到DefaultModel时，Timer会得到重复回调，但此时滑动一个TableView时，RunLoop会将mode切换为TrackingRunLoopMode，这时Timer就不会被调用，并且也不会影响滑动操作。 有时你需要一个Timer，在两个Mode中都能得到回调，一种办法就是将这个Timer分别加入这两个Mode。还有一种方式，就是将Timer加入到顶层的RunLoop的”commonModeItems“中。”commonModeItems“被RunLoop自动更新到所有具有“Common”属性的Mode里去。 CFRunLoop对外暴露的管理Mode接口只有下面2个： 12CFRunLoopAddCommonMode(CFRunLoopRef runloop, CFStringRef modeName);CFRunLoopRunInMode(CFStringRef modeName, ...); Mode暴露的管理mode item 的接口有下面几个： 123456CFRunLoopAddSource(CFRunLoopRef r1, CFRunLoopSourceRef source, CFStringRef modeName);CFRunLoopAddObserver(CFRunLoopRef r1, CFRunLoopObserverRef observer, CFStringRef modeName);CFRunLoopAddTimer(CFRunLoopRef r1, CFRunLoopTimerRef timer, CFStringRef mode);CFRunLoopRemoveSource(CFRunLoopRef r1, CFRunLoopSourceRef source, CFStringRef modeName);CFRunLoopRemoveObserver(CFRunLoopRef r1, CFRunLoopObserverRef observer, CFStringRef modeName);CFRunLoopRemoveTimer(CFRunLoopRef r1, CFRunLoopTimerRef timer, CFStringRef mode); 你只能通过modeName来操作内部的mode，当你传入一个新的mode name但RunLoop内部没有对应的mode时，RunLoop会自动帮你创建对应的CFRunLoopModeRef。对于一个RunLoop来说，其内部的mode只能增加不能删除。 苹果公开提供的 Mode 有两个：kCFRunLoopDefaultMode (NSDefaultRunLoopMode) 和 UITrackingRunLoopMode，你可以用这两个 Mode Name 来操作其对应的 Mode。 同时苹果还提供了一个操作 Common 标记的字符串：kCFRunLoopCommonModes (NSRunLoopCommonModes)，你可以用这个字符串来操作 Common Items，或标记一个 Mode 为 “Common”。使用时注意区分这个字符串和其他 mode name。 RunLoop的内部逻辑根据苹果文档里的说明，RunLoop内部逻辑大致如下：其内部代码整理如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102///用DefaultMode启动void CFRunLoopRun(void) &#123; CFRunLoopRunSpecific(CFRunLoopGetCurrent(), KCFRunLoopDefaultMode, 1.0e10, false);&#125;///用指定的Mode启动， 允许设置RunLoop超时时间int CFRunLoopInMode(CFString modeName, CFTimeInterval seconds, Boolean stopAfterHandle) &#123; return CFRunLoopRunSpecific(CFRunLoopGetCurrent(), modeName, seconds, returnAfterSourceHandled);&#125;///RunLoop的实现int CFRunLoopRunSpecific(runloop, modeName, seconds, stopAfterHandle) &#123; //首先根据modeName找到对应的mode CFRunLoopModeRef currentMode = __CFRunLoopFindMode(runloop, modeName, false); //如果mode里没有Source/Timer/Observer，直接返回 if (__CFRunLoopModeIsEmpty(currentMode)) return; //1、通知Observer：RunLoop即将进入loop __CFRunLoopDoObservers(runloop, currentMode, kCFRunLoopEntry); //内部函数，进入loop __CFRunLoopRun(runloop, currentMode, seconds, returnAfterSourceHandled) &#123; Boolean sourceHandledThisLoop = NO; int retVal = 0; do &#123; //2、通知Observers：RunLoop即将触发Timer回调。 __CFRunLoopDoObservers(runloop, currentMode, kCFRunLoopBeforeTimers); //3、通知Observers：RunLoop即将触发Source0（非port）回调 __CFRunLoopDoObservers(runloop, currentMode, kCFRunLoopBeforeSources); //执行被加入的block __CFRunLoopDoBlocks(runloop, currentMode); //4、RunLoop触发Source0(非port)回调 sourceHandledThisLoop = __CFRunLoopDoSource0(runloop, currentMode, stopAfterHandle); //执行被加入的block __CFRunLoopDoBlocks(runloop, currentMode); //5、如果有Source1(基于port)处于ready状态，直接处理这个Source1然后跳转去处理消息 if (__Source0DidDispatchPortLastTime) &#123; Boolean hasMsg = __CFRunLoopServiceMachPort(dispatch, &amp;msg); if (hasMsg) &#123; goto handle_msg; &#125; &#125; //6、通知Observers： RunLoop的线程即将进入休眠(sleep) if (!sourceHandledThisLoop) &#123; __CFRunLoopDoObservers(runloop, currentMode, kCFRunLoopBeforeWaiting); &#125; //7、调用mach_msg等待接受mach_port的消息。线程即将进入休眠，直接被下面某一个事件唤醒 //一个基于port的Source事件 //一个Timer到时间了 //RunLoop自身超时时间到了 //被其他什么调用者手动唤醒 __CFRunLoopServiceMachPort(waitSet, &amp;msg, sizeof(msg_buff), &amp;livePort) &#123; mach_msg(msg, MACH_RCV_MSG, port); //线程等待接收消息 &#125; //8、通知Observers： RunLoop的线程刚刚被唤醒 __CFRunLoopDoObservers(runloop, currentMode, kCFRunLoopAfterWaiting); //收到消息，处理消息 handle_msg: if (msg_is_timer) &#123; //9.1 如果一个timer时间到了，触发这个timer的回调 __CFRunLoopDoTimers(runloop, currentMode, mach_absolute_time()); &#125; else if（msg_is_dispatch）&#123; //9.2 如果有dispatch到main_queue的block， 执行block __CFRUNLOOP_IS_SERVICING_THE_MAIN_DISPATCH_QUEUE__(msg); &#125; else &#123; //9.3 如果一个Source1(基于port)发出事件了，处理这个事件 CFRunLoopSourceRef source1 = __CFRunLoopModeFindSourceForMachPort(runloop, currentMode, livePort); sourceHandledThisLoop = __CFRunLoopSource1(runloop, current, source1, msg); if (sourceHandledThisLoop) &#123; mach_msg(reply, MACH_SEND_MSG, reply); &#125; &#125; //执行加入到Loop的Block __CFRunLoopDoBlocks(runloop, currentMode); if (sourceHandledThisLoop &amp;&amp; stopAfterHandle) &#123; //进入loop时参数说处理完事件就返回 retVal = kCFRunLoopRunHandledSource; &#125; else if (timeout) &#123; //超出传入参数标记的超市时间了 retVal = kCFRunLoopRunTimeOut; &#125; else if (__CFRunLoopIsStopped(runloop)) &#123; //被外部调用者强制停止了 retVal = kCFRunLoopRunStopped; &#125; else if (__kCFRunLoopModeIsEmpty(runloop, currentMode)) &#123; retVal = kCFRunLoopRunFinished; &#125; //如果没超时， mode里没空，loop没有被停止， 那继续loop &#125; while (retVal == 0); &#125; //10、通知Observers： RunLoop即将退出 __CFRunLoopDoObservers(r1, currentMode, kCFRunLoopExit);&#125; 可以看到，实际上RunLoop就是这样一个函数，其内部是一个do-while循环。当你调用CFRunLoopRun()时，线程就会一直停留在这个循环里；直到超时或被手动停止，该函数才会返回。 RunLoop的底层实现从上面代码可以看到，RunLoop的核心是基于mach port的，其进入休眠时调用的函数是mach_msg()。为了解释这个逻辑，下面稍微介绍一下OSX/iOS的系统架构。苹果官方将整个系统大致划分为上述4个层次：应用层包含用户能接触到的图形应用，例如：Spotlight、Aqua、SpringBoard等。应用框架层即开发人员接触到的Cocoa等框架。核心框架层包含各种核心框架、OpenGL等内容。Darwin即操作系统的核心，包含系统内核、驱动、Shell等内容，这一层是开源的，其所有源码都可以在opensource.apple.com里找到。 我们在深入看一下Darwin这个核心的架构： 其中，在硬件层上面的三个组成部分：Mach、BSD、IOKit（还包括一些上面没标注的内容），共同组成了XNU内核。 XNU内核的内环被称作Mach，其作为一个微内核，仅提供了诸如处理器调度、IPC（进程间通信）等非常少量的基础服务。 BSD层可以看作围绕Mach层的一个外环，其提供了诸如进程管理、文件系统和网络等功能。 IOKit层为设备驱动提供了一个面向对象（C++）的一个框架。 Mach 本身提供的API非常有限，而且苹果也不鼓励使用Mach的API，但是这些API非常基础，如果没有这些API的话，其他任何工作都无法实施。在Mach中，所有的东西都是通过自己的对象实现的，进程、线程和虚拟内存都被称为“对象”。和其他架构不同，Mach的对象间不能直接调用，只能通过消息传递的方式实现对象间的通信。“消息”是Mach中最基础的概念，消息在两个端口（port）之间传递，这就是Mach的IPC（进程通信）的核心。 Mach的消息定义是在&lt;mach/message.h&gt;头文件中，很简单： 12345678910111213typedef struct &#123; mach_msg_header_t header; mach_msg_body_t body;&#125; mach_msg_base_t;typedef struct &#123; mach_msg_bits_t msgh_bits; mach_msg_size_t msgh_size; mach_port_t msgh_remote_port; mach_port_t msgh_local_port; mach_port_name_t msgh_voucher_port; mach_msg_id_t msgh_id;&#125; mach_msg_header_t; 一条Mach消息实际上就是一个二进制数据包（BLOB），其头部定义了当前端口local_port和目标端口remote_port，发送和接收消息是通过同一个API进行的，其option标记了消息传递的方向： 12345678mach_msg_return_t mach_msg( mach_msg_header_t *msg, mach_msg_option_t *option, mach_msg_size_t send_size, mach_msg_size_t rcv_size, mach_port_name_t rcv_name, mach_msg_timeout_t timeout, mach_port_name_t notify); 为了实现消息的发送和接收，mach_msg() 函数实际上是调用一个Mach陷阱（trap），即函数 mach_msg_trap(),陷阱这个概念在Mach中等同于系统调用。当你在用户态调用mach_msg_trap()会触发陷阱机制，切换到内核态；内核态中内核实现的mach_msg()函数会完成实际的工作，如下图：这些概念可以参考维基百科：System_call、Trap_(computing))。 RunLoop 的核心就是一个 mach_msg() (见上面代码的第7步)，RunLoop调用这个函数去接收消息， 如果没有别人发送 port 消息过来，内核会将线程置于等待状态。例如你在模拟器里跑起一个iOS的App，然后App静止时点击暂停，你会看到主线程调用栈是停留在mach_msg_trap() 这个地方。 关于具体的如何利用mach_port 发送消息，可以看看NSHipster这一篇文章，或者这里的中文翻译。 关于Mach的历史可以看看这篇很有趣的文章：Mac OS X 背后的故事（三） Mach 之父 Avie Tevanian。 苹果用 RunLoop 实现的功能首先我们可以看一下 App 启动后 RunLoop 的状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153CFRunLoop &#123; current mode = kCFRunLoopDefaultMode common modes = &#123; UITrackingRunLoopMode kCFRunLoopDefaultMode &#125; common mode items = &#123; //source0 (manual) CFRunLoopSource &#123; order = -1, &#123; callout = _UIApplicationHandleEventQueue &#125; &#125; CFRunLoopSource &#123; order = -1, &#123; callout = PurpleEventSignalCallback &#125; &#125; CFRunLoopSource &#123; order = 0, &#123; callout = FBSSerialQueueRunLoopSourceHandler &#125; &#125; // source1 (mach port) CFRunLoopSource &#123;order = 0, &#123;port = 17923&#125;&#125; CFRunLoopSource &#123;order = 0, &#123;port = 12039&#125;&#125; CFRunLoopSource &#123;order = 0, &#123;port = 16647&#125;&#125; CFRunLoopSource &#123;order = -1, &#123; callout = PurpleEventCallback &#125; &#125; CFRunLoopSource &#123;order = 0, &#123; port = 2407, callout = _ZL20notify_port_callbackP12__CFMachPortPvlS1_ &#125; &#125; CFRunLoopSource &#123;order = 0, &#123; port = 1c03, callout = __IOHIDEventSystemClientAvailabilityCallback &#125; &#125; CFRunLoopSource &#123;order = 0, &#123; port = 1b03, callout = __IOHIDEventSystemClientQueueCallback &#125; &#125; CFRunLoopSource &#123;order = 1, &#123; port = 1903, callout = __IOMIGMachPortPortCallback &#125; &#125; // Observer CFRunLoopObserver &#123; order = -2147483647, activities = 0x1, // Entry callout = _wrapRunLoopWithAutoreleasePoolHandler &#125; CFRunLoopObserver &#123; order = 0, activities = 0x20, // BeforeWaiting callout = _UIGestureRecognizerUpdateObserver &#125; CFRunLoopObserver &#123; order = 1999000, activities = 0xa0, // BeforeWaiting | Exit callout = _afterCACommitHandler &#125; CFRunLoopObserver &#123; order = 2000000, activities = 0xa0, // BeforeWaiting | Exit callout = _ZN2CA11Transaction17observer_callbackEP19__CFRunLoopObservermPv &#125; CFRunLoopObserver &#123; order = 2147483647, activities = 0xa0, // BeforeWaiting | Exit callout = _wrapRunLoopWithAutoreleasePoolHandler &#125; // Timer CFRunLoopTimer &#123; firing = No, interval = 3.1536e+09, tolerance = 0, next fire date = 453098071 (-4421.76019 @ 96223387169499), callout = _ZN2CAL14timer_callbackEP16__CFRunLoopTimerPv (QuartzCore.framework) &#125; &#125;, modes ＝ &#123; CFRunLoopMode &#123; sources0 = &#123; /* same as &apos;common mode items&apos; */ &#125;, sources1 = &#123; /* same as &apos;common mode items&apos; */ &#125;, observers = &#123; /* same as &apos;common mode items&apos; */ &#125;, timers = &#123; /* same as &apos;common mode items&apos; */ &#125;, &#125;, CFRunLoopMode &#123; sources0 = &#123; /* same as &apos;common mode items&apos; */ &#125;, sources1 = &#123; /* same as &apos;common mode items&apos; */ &#125;, observers = &#123; /* same as &apos;common mode items&apos; */ &#125;, timers = &#123; /* same as &apos;common mode items&apos; */ &#125;, &#125;, CFRunLoopMode &#123; sources0 = &#123; CFRunLoopSource &#123; order = 0, &#123; callout = FBSSerialQueueRunLoopSourceHandler &#125; &#125; &#125;, sources1 = (null), observers = &#123; CFRunLoopObserver &gt;&#123; activities = 0xa0, order = 2000000, callout = _ZN2CA11Transaction17observer_callbackEP19__CFRunLoopObservermPv &#125; &#125;, timers = (null), &#125;, CFRunLoopMode &#123; sources0 = &#123; CFRunLoopSource &#123; order = -1, &#123; callout = PurpleEventSignalCallback &#125; &#125; &#125;, sources1 = &#123; CFRunLoopSource &#123; order = -1, &#123; callout = PurpleEventCallback &#125; &#125; &#125;, observers = (null), timers = (null), &#125;, CFRunLoopMode &#123; sources0 = (null), sources1 = (null), observers = (null), timers = (null), &#125; &#125;&#125; 可以看到系统默认注册了5个Mode： kCFRunLoopDefaultMode: App的默认Mode，通常主线程是在这个Mode下运行的。 UITrackingRunLoopMode: 界面跟踪Mode，用于scrollView追踪触摸滑动，保证界面滑动时不受其他mode影响。 UIInitializationRunLoopMode: 在刚启动App时进入的第一个Mode，启动完成后就不在使用。 GSEventReceiveRunLoopMode: 接收系统事件的内部Mode，通常用不到 kCFRunLoopCommonModes: 这是一个占位的Mode，没有实际作用 你可以在这里看到更多的苹果内部的Mode，但那些Mode在开发中就很难遇到了。 当RunLoop进行回调时，一般都是通过一个很长的函数调用出去（call out），当你在你的代码中下断点调试时，通常能在调用栈上看到这些函数。下面是这几个函数的整理版本，如果你在调用栈上看到这些长函数名，在这里查找一下就能定位到具体的调用地点了： 1234567891011121314151617181920212223242526272829303132333435363738&#123; ///1、通知Observer，即将进入runloop ///此处有Observer会创建AutoreleasePool：_objc_autoreleasePoolPush(); __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__(kCFRunLoopEntry) do &#123; ///2、通知Observers：即将触发timer回调 __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNTION__(kCFRunLoopBeforeTimers) /// 3. 通知 Observers: 即将触发 Source (非基于port的,Source0) 回调。 __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__(kCFRunLoopBeforeSources); __CFRUNLOOP_IS_CALLING_OUT_TO_A_BLOCK__(block); /// 4. 触发 Source0 (非基于port的) 回调。 __CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE0_PERFORM_FUNCTION__(source0); __CFRUNLOOP_IS_CALLING_OUT_TO_A_BLOCK__(block); /// 5. 通知Observers，即将进入休眠 /// 此处有Observer释放并新建AutoreleasePool: _objc_autoreleasePoolPop(); _objc_autoreleasePoolPush(); __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__(kCFRunLoopBeforeWaiting); /// 6. sleep to wait msg. mach_msg() -&gt; mach_msg_trap(); /// 7. 通知Observers，线程被唤醒 __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__(kCFRunLoopAfterWaiting); /// 8.1 如果是被Timer唤醒的，回调Timer __CFRUNLOOP_IS_CALLING_OUT_TO_A_TIMER_CALLBACK_FUNCTION__(timer); /// 8.2 如果是被dispatch唤醒的，执行所有调用 dispatch_async 等方法放入main queue 的 block __CFRUNLOOP_IS_SERVICING_THE_MAIN_DISPATCH_QUEUE__(dispatched_block); /// 8.3 如果如果Runloop是被 Source1 (基于port的) 的事件唤醒了，处理这个事件 __CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE1_PERFORM_FUNCTION__(source1); &#125; while (...); /// 9. 通知Observers，即将退出RunLoop /// 此处有Observer释放AutoreleasePool: _objc_autoreleasePoolPop(); __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__(kCFRunLoopExit);&#125; AutoreleasePoolApp启动后，苹果会在主线程RunLoop里注册两个 Observer，其回调都是_wrapRunLoopWithAutoreleasePoolHandler()。 第一个Observer监视的事件是Entry(即将进入RunLoop)，其回调内会调用_objc_autoreleasePoolPush() 创建自动释放池。其order是-2147483647，优先级最高，保证创建释放池发生在其它所有回调之前。 第二个Observer监视了两个事件：BeforeWaiting（准备进入休眠）时调用_objc_autoreleasePoolPop() 和 _objc_autoreleasePoolPush()释放旧的池并创建新池；Exit(即将退出Loop)时调用_objc_autoreleasePoolPop()来释放自动释放池。这个Observer的Order是2147483647，优先级最低，保证其释放池子发生在其他所有回调之后。 在主线程执行的代码，通常是写在诸如事件回调、Timer回调内的。这些回调会被RunLoop创建好的AutoreleasePool环绕着，所以不会出现内存泄漏，开发者也不必显示创建Pool了。 事件响应苹果注册了一个Source1（基于mach port的）用来接收系统事件，其回调函数为 __IOHIDEventSystemClientQueueCallBack()。 当一个硬件事件(触摸/锁屏/摇晃等)发生后，首先由IOKit.framework生成一个IOHIDEvent事件并由SpringBoard接收。这个过程的详细情况可以参考这里。SpringBoard只接收按键(锁屏/静音等)，触摸，加速，接近传感器等几种Event，随后用mach port转发给需要的App进程。随后苹果注册的那个Source1就会触发回调，并调用_UIApplicationHandleEventQueue()进行应用内部的分发。 _UIApplicationHandleEventQueue()会把IOHIDEvent处理并包装成UIEvent进行处理或分发，其中包括识别UIGesture/处理屏幕旋转/发送给UIWindow等。通常事件比如 UIButton点击、touchesBegin/Move/End/Cancel 事件都是在这个回调中完成的。 手势识别当上面的 _UIApplicationHandleEventQueue() 识别了一个手势时，其首先会调用Cancel将当前的 touchesBegin/Move/End 系列回调打断。随后系统将对应的 UIGestureRecognizer 标记为待处理。 苹果注册了一个Observer监测BeforeWaiting(Loop即将进入休眠)事件，这个Observer的回调函数是 _UIGestureRecognizerUpdateObserver(), 其内部会获取所有刚被标记为待处理的 GestureRecognizer，并执行GestureRecognizer的回调。 当有 UIGestureRecognizer 的变化(创建/销毁/状态改变)时，这个回调都会进行相应处理。 界面更新当在操作UI时，比如改变了Frame、更新了UIView/CALayer的层次时，或者手动调用了 UIView/CALayer 的 setNeedsLayout/setNeedsDisplay 方法后，这个 UIView/CALayer 方法后，这个 UIView/CALayer 就被标记为待处理，并提交到一个全局的容器去。 苹果注册了一个 Observer 监听 BeforeWaiting(即将进入休眠) 和 Exit(即将退出Loop) 事件，回调去执行一个很长的函数：_ZN2CA11Transaction17observer_callbackEP19__CFRunLoopObservermPv()。这个函数里会遍历所有待处理的 UIView/CALayer 以执行实际的绘制和调整，并更新UI界面。 这个函数内部的调用栈大概是这样的： 1234567891011_ZN2CA11Transaction17observer_callbackEP19__CFRunLoopObservermPv() QuartzCore:CA::Transaction::observer_callback: CA::Transaction::commit(); CA::Context::commit_transaction(); CA::Layer::layout_and_display_if_needed(); CA::Layer::layout_if_needed(); [CALayer layoutSublayers]; [UIView layoutSubviews]; CA::Layer::display_if_needed(); [CALayer display]; [UIView drawRect]; 定时器NSTimer 其实就是CFRunLoopTimerRef，他们之间是 toll-free bridged的。一个NSTimer注册到RunLoop后，RunLoop会为其重复的时间点注册好事件。例如 10:00,10:10,10:20这几个时间点。RunLoop为了节省资源，并不会在非常准确的时间点回调这个Timer。Timer有个属性叫做Tolerance(宽容度), 标记了当时间点到后，容许有多少最大误差。 如果某个时间点被错过了，例如执行了一个很长的任务，则那个时间点的回调也会跳过去，不会延后执行。就比如等公交，如果10:10时我忙着玩手机错过了那个点的公交车，那我只能等10:20这一趟了。 CADisplayLink是一个和屏幕刷新率一致的定时器(但实际实现原理更复杂，和NSTimer并不一样，其内部实际是操作了一个Source)。如果在两次屏幕刷新之间执行了一个长任务，那其中就会有一帧被跳过去 (和NSTimer相似)，造成界面卡顿的感觉。在快速滑动TableView时，即使一帧的卡顿也会让用户有所察觉。Facebook开源的AsyncDisplayLink就是为了解决界面卡顿的问题，其内部也用到了RunLoop。 PerformSelecter当调用 NSObject 的 performSelecter:afterDelay:后，实际上其内部会创建一个Timer并添加到当前线程的RunLoop中。所以如果当前线程没有RunLoop，则这个方法会失效。 当调用performSelector:onThread:时，实际上其会创建一个Timer加到对应的线程去，同样的，如果对应线程没有RunLoop该方法也会失效。 关于GCD实际上RunLoop底层也会用到GCD的东西，（NSTimer是用了XNU内核的mk_timer, 而非GCD驱动的）GCD提供的某些接口也用到了RunLoop，例如dispatch_async()。 当调用dispatch_async(dispatch_get_main_queue(), block)时，libDispatch会向主线程的RunLoop发送消息，RunLoop会被唤醒，并从消息中取的这个block，并在回调 CFRUNLOOP_IS_SERVICING_THE_MAIN_DISPATCH_QUEUE() 里执行这个block。但这个逻辑仅限于dispatch到主线程，dispatch到其他线程仍然是由libDispatch处理的。 关于网络请求iOS中，关于网络请求的接口自下至上有如下几层： 1234CFSocketCFNetwork -&gt;ASIHttpRequestNSURLConnection -&gt;AFNetworkingNSURLSession -&gt;AFNetworking2, Alamofire CFSocket 是最底层的接口，只负责socket通信。 CFNetwork 是基于CFSocket等接口的上层封装，ASIHttpRequest工作于这一层。 NSURLConnection 是基于CFNetwork的更高层的封装，提供面向对象的接口，AFNetworking工作于这一层。 NSURLSession是iOS7中新增的借口，表面上是和NSURLConnection并列的，但底层仍然用到了NSURLConnection的部分功能(比如com.apple.NEURLConnectionLoader线程)，AFNetworking2和Alamofire工作于这一层。 下面主要介绍下NSURLConnnection的工作过程。 通常使用NSURLConnection时，你会传入一个Delegate，当调用了[connection start]后，这个Delegate就会不停收到事件回调。实际上，start这个函数的内部会获取CurrentRunLoop，然后在其中的DefaultMode添加了4个Source0(即需要手动触发的Source)。CFMultiplexerSource是负责各种Delegate回调的，CFHTTPCookieStorage是处理各种Cookie的。 当开始网络传输时，我们可以看到NSURLConnection创建了两个新线程：com.apple.NSURLConnectionLoader和com.apple.CFSocket.private。其中CFSocket线程是处理底层socket连接的。NSURLConnectionLoader这个线程内部会使用RunLoop来接收底层socket事件，并通过之前添加的Source0通知上层的Delegate。NSURLConnectionLoader中的RunLoop通过一些基于mach port的Source接收来自底层CFSocket的通知。当收到通知后，其会在合适的时机向CFMultiplexerSource等Source0发送通知，同时唤醒Delegate线程的RunLoop来让其处理这些通知。CFMultiplexerSource会在Delegate线程的RunLoop对Delegate执行实际的回调。 RunLoop 的实际应用举例AFNetworkingAFURLConnectionOperation 这个类是基于NSURLConnection构建的，其希望能在后台线程接收Delegate回调。为此AFNetworking单独创建了一个线程，并在这个线程中启动了一个RunLoop： 12345678910111213141516171819+(void)networkRequestThreadEntryPoint:(id)__unused object &#123; @autoreleasepool &#123; [[NSThread currentThread] setName:@&quot;AFNetworking&quot;]; NSRunLoop *runloop = [NSRunLoop currentRunLoop]; [runloop addPort:[NSMachPort port] forMode: NSDefaultRunLoopMode]; [runloop run]; &#125;&#125;+(NSThread *)networkingRequestThread &#123; static NSThread *_networkingRequestThread = nil; static dispatch_once_t oncePredicate; dispatch_once(&amp;oncePredicate, ^&#123; _networkingRequestThread = [[NSThread alloc] initWithTarget: self selector: @selector(networkRequestThreadEntryPoint:) object: nil]; [_networkingRequestThread start]; &#125;); return _networkingRequestThread;&#125; RunLoop启动前内部必须要有一个Timer/Observer/Source，所以AFNetWorking在[runloop run]之前先创建了一个新的NSMachPort添加进去了。通常情况下，调用者需要持有这个NSMachPort(mach port)并在外部线程通过这个port发送消息到loop内；但此处添加port只是为了让RunLoop不至于退出，并没有用于实际的发送消息。 12345678910-(void)start &#123; [self.lock lock]; if ([self isCancelled]) &#123; [self performSelector: @selector(cancelConnection) onThread: [[self class] networkRequestThread] withObject: nil waitUntilDone: NO modes: [self.runloopModes allObjects]]; &#125; else if ([self isReady]) &#123; self.state = AFOperationExecutingState; [self performSelector: @selector(operationDidStart) onThread: [[self class] networkRequestThread] withObject: nil waitUntilDone: NO modes: [self.runLoopModes allObjects]]; &#125; [self.lock unlock];&#125; 当需要这个后台线程执行任务时，AFNetworking通过调用[NSObject performSelector:onThread:…]将这个任务扔到了后台线程的RunLoop中。 AsyncDisplayKitAsyncDisplayKit是Facebook推出的用于保持界面流畅性的框架，其原理大致如下： UI线程中一旦出现繁重的任务就会导致界面卡顿，这类任务通常分为3类：排版、绘制、UI对象操作。 排版通常包括计算视图大小、计算文本高度、重新计算子视图的排版等操作。 绘制一般有文本绘制(例如CoreText)、图片绘制(例如预先解压)、元素绘制(Quartz)等操作。UI对象操作通常包括UIView/CALayer等UI对象的创建、设置属性和销毁。 其中前两类操作可以通过各种方法扔到后台线程执行，而最后一类操作只能在主线程完成，并且有时后面的操作需要依赖前面操作的结果(例如TextView创建时可能需要提前计算出文本的大小)。ASDK所做的，就是尽量将能放入后台的任务放入后台，不能的则尽量推迟(例如视图的创建、属性的调整)。 为此，ASDK创建了一个名为ASDisplayNode的对象，并在内部封装了UIView/CALayer，它具有和UIView/CALayer相似的属性，例如 frame、backgroundColor等。所有这些属性都可以在后台线程更改，开发者可以只通过Node来操作其内部的UIView/CALayer，这样就可以将排版和绘制放入了后台线程。但无论怎么操作，这些属性总需要在某个时刻同步到主线程的UIView/CALayer去。 ASDK仿照QuartzCore/UIKit框架的模式，实现了一套类似的界面更新机制：即在主线程的RunLoop中添加一个Observer，监听了kCFRunLoopBeforeWaiting和kCFRunLoopExit事件，在收到回调时，遍历所有之前放入到队列的待处理的任务，然后一一执行。","categories":[{"name":"iOS 深入学习","slug":"iOS-深入学习","permalink":"http://yoursite.com/categories/iOS-深入学习/"}],"tags":[{"name":"RunLoop","slug":"RunLoop","permalink":"http://yoursite.com/tags/RunLoop/"}]},{"title":"总得停下来思考思考","slug":"2017-06-20-sum","date":"2017-06-19T16:00:00.000Z","updated":"2019-07-22T08:47:51.703Z","comments":true,"path":"2017-06-20-sum/","link":"","permalink":"http://yoursite.com/2017-06-20-sum/","excerpt":"","text":"走的有点着急 之前跟女朋友提起过，该总结一下毕业这么久以来的生活、工作，然后想想自己想要的到底是什么。才发现，以前赶路赶的有些着急了。 记得刚毕业那段时间，天天忙着找工作。因为喜欢编程，所以就在大学自学了java。毕业之后就一直在找it行业的工作，放弃了大学四年所学的专业。工作以后，每天来回奔波，看看技术相关的东西，业余时间打打篮球，没有别的。现在回想起来，自己的第一份正式工作，总归还是学到了不少东西。 可是，那个时候总想到大城市看看，觉得趁着自己年轻，是不是得去取取经，长长见识。然后第二年年初，自己一个人就傻头傻脑的跑到了上海。开始寻找自己的机会，谋求一份工作，以为一切都很简单，发现自己还是太简单了。总归，还是找到了一份工作，看着团队的组建，看着自己辛苦加班之后，亲手缔造的产品，总觉得这些都是值得的。 在魔都，看过夜里外滩，看过繁华的南京东路，才发现，其实这些和自己都毫不相干，第二天依旧要挤着地铁去公司，干着自己本分的工作，给自己充充电。要说，在这里学会了什么？唯一的就是，在你一无所有的时候，你除了努力还是得努力。 家，足以让自己安静 可是，却没有停下脚步好好地思考一番，自己适合做什么？得到了什么？还有什么要改进的？只是往前走，一昧的往前走。毕业的时候，还知道自己喜欢编程，然后就奔着这个方向走，到现在开始怀疑自己，如果不干这一行，还能干什么？记得那时候自己信心满满，觉得个人能力也还行，态度摆的也很低。社会却很现实，姿态摆的低虽然好，但是你能做什么？你能给公司带来什么？这些好像才是应该放在第一位的。 前几天回家待了几天，想着在家，远离喧嚣看看能不能静下心来好好地思考总结一下这段时间以来的不足和收获。还好，在家里远离网络，搬个凳子坐在院子里，吹吹风，和家里的老人聊聊天，静静的坐在那里，回顾一下之前快节奏的生活。还是有不少的收获，当自己快要迷失的时候，快没有能量的时候，回家歇一歇总会是一个不错的抉择。因为，总会有人给予关心与呵护，还有鼓励。所以，当我有什么想法的时候，首先会找我老姐吐槽一番，然后神清气爽。 心平气和，接着走 当自己想明白之后，又是动力满满，继续往前走。如今，重新回到上海，继续寻求新的开始，也许前面会坎坎坷坷比较难走，我也会心平气和，一步步迈过去。努力，肩扛着自己的责任，稳！ 初心不改，继续锻造自己，当你能独当一面的时候，你会感激今天的不放弃。正当年少，你没有放弃的理由，改变现状，从容不迫。 感谢有家人和女票的陪伴，努力让自己更好，让你们更好。","categories":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/categories/blog/"}],"tags":[{"name":"总结","slug":"总结","permalink":"http://yoursite.com/tags/总结/"}]},{"title":"iOS开发-渐变色踩的坑","slug":"2017-06-08-secondBlog","date":"2017-06-07T16:00:00.000Z","updated":"2019-07-22T08:47:51.590Z","comments":true,"path":"2017-06-08-secondBlog/","link":"","permalink":"http://yoursite.com/2017-06-08-secondBlog/","excerpt":"","text":"这些坑踩的好疼个人的域名和blog搭建好了有一段时间，但是一直没有抽时间来写自己的blog。所以就抽了一点时间来记录一下，最近项目中遇到的一些坑。言归正传，最近的项目中，UI的设计图里出了一个渐变色的按钮，而且按钮点击的时候还需要一个透明度为0.3的黑色遮盖在渐变色上。然后，坑就开始了。 第一个大坑（hitTest:withEvent:）我实现的大体思路是把渐变色绘制成image设置成按钮的背景图，然后，在button上添加一个view，没点击时，设置为透明色，点击时设置为alpha为0.3的黑色。因为点击button的事件会被view给拦截掉。所以，我就在自己创建的button里重写了如下方法： 123456789#pragma mark - 转换点击- (UIView *)hitTest:(CGPoint)point withEvent:(UIEvent *)event &#123; // 1.判断当前控件能否接收事件 if (self.userInteractionEnabled == NO || self.hidden == YES || self.alpha &lt;= 0.01) return nil; // 2.判断点在不在coverView上 if ([self.coverView pointInside:point withEvent:event]) return self; // 3. 判断点在不在当前控件 if ([self pointInside:point withEvent:event] == NO) return nil;&#125; 第一个判断是如果当前的视图不能交互，被隐藏，或者alpha值＜0.01的话，此次Touch操作初始点所在的视图就返回为nil。 第二个判断是调用 pointInside: withEvent:方法，判断当前touch的点在不在添加到button上的view上，如果在上面，就返回button，让button来响应点击 第三个判断如果当前的点击不在覆盖的view上就返回nil. 刚开始的时候，并没有测试出问题，然后一次偶然的点击触发了一系列的问题。刚开始只是在一个包含我的渐变色按钮的页面点击出现了奔溃，我们并没有往我的按钮那里去想，最后在其他界面点击也会出现奔溃，控制台打印出来的奔溃信息是[UIWindow dealloced];内心很奔溃，我们定位了很久，比较不同的版本，修改按钮为普通按钮，最后终于定位到了上述方法上。触发这个问题的方式就是，触碰按钮的边缘，然后就会100%的复现这个问题，分析原因应该就是我的最后一个判断，处理得太唐突，当点不在button或者coverView上的时候，直接返回了nil。最后利用 12CGPoint subPoint = [subview convertPoint:point fromView:self];UIView *result = [subview hitTest:subPoint withEvent:event]; 处理了一下，就好了。但是最后由于怕有疏忽。所以放弃了这种方式处理。然后就有了第二种坑。 第二个坑（CGColorSpaceRelease(colorSpace)）在一个坑中，我最后放弃了在button上添加遮盖的处理方式，而是在点击button的时候，先是将渐变色绘制成图片，再将遮盖色绘制成图片，最后将两张图片绘制成一张图片，设置为button的背景色。核心代码如下： 123456789101112131415161718192021222324252627282930313233343536#pragma mark --渐变色+ (UIImage *)setGradualChangeColor:(NSArray *)colors startPoint:(CGPoint)startPoint endPoint:(CGPoint)endPoint frame:(CGRect)frame &#123; NSMutableArray *cgColors = [NSMutableArray array]; for(UIColor *c in colors) &#123; [cgColors addObject:(id)c.CGColor]; &#125; UIGraphicsBeginImageContextWithOptions(frame.size, YES, 1); CGContextRef context = UIGraphicsGetCurrentContext(); CGContextSaveGState(context); CGColorSpaceRef colorSpace = CGColorGetColorSpace([[colors lastObject] CGColor]); CGGradientRef gradient = CGGradientCreateWithColors(colorSpace, (CFArrayRef)cgColors, NULL); CGContextDrawLinearGradient(context, gradient, startPoint, endPoint, kCGGradientDrawsBeforeStartLocation | kCGGradientDrawsAfterEndLocation); UIImage *image = UIGraphicsGetImageFromCurrentImageContext(); CGGradientRelease(gradient); CGContextRestoreGState(context);// CGColorSpaceRelease(colorSpace); UIGraphicsEndImageContext(); return image;&#125;#pragma mark - 设置带有阴影的渐变色- (UIImage *)createGraduallyCoverImage:(UIImage *)graduallyImage coverImage:(UIImage *)coverImage &#123; UIGraphicsBeginImageContextWithOptions(self.size, NO, 2); [graduallyImage drawInRect:CGRectMake(0, 0, self.width, self.height)]; [coverImage drawInRect:CGRectMake(0, 0, self.width, self.height)]; UIImage *image = UIGraphicsGetImageFromCurrentImageContext(); UIGraphicsEndImageContext(); return image;&#125; 然后在有渐变色按钮的地方，有一定的概率触发崩溃，当时为了定位这个问题，就多点几次按钮，然后打断点，打开了僵尸对象调试，发现打印的奔溃信息是：Assertion failed: (!state-&gt;is_singleton), function color_space_state_dealloc, file ColorSpaces/CGColorSpace.c, line 127.然后就开始在网上找相关的问题，然后在一篇blog中找到了症结所在。具体的原因就是，第一个方法中我注释掉的那行代码。在苹果的api中指出，如果你需要维持这个实例，retain 它，如果没有 retain ，不要 release 它。所以由于我将其release掉了，就会有一定的几率触发奔溃。处理方式，就是注释掉CGColorSpaceRelease(colorSpace);这行代码，就OK了。 总结由于在以前的开发中很少手动处理hitTest:withEvent:，以及接触绘图这一块，所以在开发中出现了上述的问题，还好在互联网发达的今天，能够快速的在网上找到解决方案。对于不太懂hitTest:withEvent:的，可以看看这一篇文章，作者写的很到位。当时还看了一篇讲解convertPoint: fromView:和convertPoint: toView:几个方法的作用的文章。也可以在网上找找其他的看看。最后，谢谢这些文章的作者，正是有了他们的经验，才为我们这些后来的开发者，提供了宝贵的经验。","categories":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/categories/iOS/"}],"tags":[{"name":"渐变色","slug":"渐变色","permalink":"http://yoursite.com/tags/渐变色/"}]},{"title":"iOS开发-xib添加常用的KeyPath修改属性","slug":"2017-03-18-keyPath","date":"2017-03-17T16:00:00.000Z","updated":"2019-07-22T08:47:51.756Z","comments":true,"path":"2017-03-18-keyPath/","link":"","permalink":"http://yoursite.com/2017-03-18-keyPath/","excerpt":"","text":"###步骤1、点击xib，在xcode右半部分切换到第三项，如图： 2、点击+添加key，选择类型，设置值；常用的有clipsToBounds，layer.cornerRadius设置圆角等","categories":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/categories/iOS/"}],"tags":[{"name":"xib","slug":"xib","permalink":"http://yoursite.com/tags/xib/"}]},{"title":"iOS开发-没有数据时不显示tableView的分割线","slug":"2017-03-16-tableView","date":"2017-03-15T16:00:00.000Z","updated":"2019-07-22T08:47:51.803Z","comments":true,"path":"2017-03-16-tableView/","link":"","permalink":"http://yoursite.com/2017-03-16-tableView/","excerpt":"","text":"#iOS开发中关于没有数据时不显示tableView的分割线 12//可以直接添加如下代码即可self.tableView.tableFooterView = [[UIView alloc]initWithFrame:CGRectZero];","categories":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/categories/iOS/"}],"tags":[{"name":"UITableView","slug":"UITableView","permalink":"http://yoursite.com/tags/UITableView/"}]},{"title":"iOS开发--常见的退出键盘的几种方式","slug":"2017-03-15-keyboard","date":"2017-03-14T16:00:00.000Z","updated":"2019-07-22T08:47:51.710Z","comments":true,"path":"2017-03-15-keyboard/","link":"","permalink":"http://yoursite.com/2017-03-15-keyboard/","excerpt":"","text":"原文来自于http://www.cnblogs.com/GarveyCalvin/p/4167759.html 1、第一种是最常见的resignFirstResponder 1[textField resignFirstResponder]; 2、第二种，点击view结束 1[self.view endEditing:YES]; 3、利用window统一收起键盘（同第二种） 1[[[UIApplication sharedApplication] keyWindow] endEditing:YES]; 4、源自：《iOS开发进阶》 —— 唐巧，直接发送resignFirstResponder 1[[UIApplication sharedApplication] sendAction:@selector(resignFirstResponder) to:nil from:nil forEvent:nil];","categories":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/categories/iOS/"}],"tags":[{"name":"键盘退出","slug":"键盘退出","permalink":"http://yoursite.com/tags/键盘退出/"}]},{"title":"用Jekyll搭建个人的Blog","slug":"2017-03-02-first","date":"2017-03-01T16:00:00.000Z","updated":"2019-07-23T07:42:46.393Z","comments":true,"path":"2017-03-02-first/","link":"","permalink":"http://yoursite.com/2017-03-02-first/","excerpt":"","text":"第一篇blog –纪念搭建我的个人Blog前段时间，我的一个室友提起搭建个人的blog，当时没太在意。偶然间在浏览简书的时候，看见了一篇文章勾起了我的兴趣。然后就开始鼓捣起来，期间也遇到一些坑。现在开始进入正题： 第一步先搭建本地JekyllJekyll是什么？上文给的链接中讲得很清楚，是一个生成静态Blog的简易工具，支持markdown语法，支持自定义样式等。 123456789101112131、先安装rubyGems：//因为之前安装的rubyGems是taobao，由于原作者不维护了，所以就换了一个ruby-china(如果已经是了，先更新一下)$ gem sources --add https://gems.ruby-china.org/ --remove https://ruby.taobao.org /$ gem sources -lhttps://gems.ruby-china.org// 确保只有 gems.ruby-china.org2、使用gem安装Jekyll //由于用的是mac，所以直接打开终端输入下面指令 gem install jekyll 但是提示安装jekyll的一系列依赖工具，所以又挨个安装了jekyll的依赖，但是在安装中出现类似的错误/usr/bin 的“Operation not permitted”，所以就在网上找到了解决办法。按照文章里的操作，顺利解决。接着来： 123456783、使用Jekyll创建你的博客站点jekyll new blog #创建你的站点4、开启Jekyll服务//进入blog目录,记得一定要进入创建的目录，否则服务无法开启cd blog jekyll serve #启动你的http服务 因为Jekyll默认的端口号是4000，所以打开浏览器输入：http://localhost:4000就可以访问自己的blog了。 关于jekyll其他一些命令的用法上文中也有我就直接copy了一下: 12345678910111213141516171819202122再次感谢上文的作者们$ jekyll build# =&gt; 当前文件夹中的内容将会生成到 ./_site 文件夹中。$ jekyll build --destination &lt;destination&gt;# =&gt; 当前文件夹中的内容将会生成到目标文件夹&lt;destination&gt;中。$ jekyll build --source &lt;source&gt; --destination &lt;destination&gt;# =&gt; 指定源文件夹&lt;source&gt;中的内容将会生成到目标文件夹&lt;destination&gt;中。$ jekyll build --watch# =&gt; 当前文件夹中的内容将会生成到 ./_site 文件夹中，# 查看改变，并且自动再生成。$ jekyll serve# =&gt; 一个开发服务器将会运行在 http://localhost:4000/# Auto-regeneration（自动再生成文件）: 开启。使用 `--no-watch` 来关闭。$ jekyll serve --detach# =&gt; 功能和`jekyll serve`命令相同，但是会脱离终端在后台运行。# 如果你想关闭服务器，可以使用`kill -9 1234`命令，&quot;1234&quot; 是进程号（PID）。# 如果你找不到进程号，那么就用`ps aux | grep jekyll`命令来查看，然后关闭服务器。[更多](http://unixhelp.ed.ac.uk/shell/jobz5.html). 让我们再来看看Jekyll的目录： 12345678910111213141516├── _config.yml (配置文件)├── _drafts (drafts（草稿）是未发布的文章)| ├── begin-with-the-crazy-ideas.textile| └── on-simplicity-in-technology.markdown├── _includes (加载这些包含部分到你的布局)| ├── footer.html| └── header.html├── _layouts (包裹在文章外部的模板)| ├── default.html| └── post.html├── _posts (这里都是存放文章)| ├── 2007-10-29-why-every-programmer-should-play-nethack.textile| └── 2009-04-26-barcamp-boston-4-roundup.textile├── _site (生成的页面都会生成在这个目录下)├── .jekyll-metadata (该文件帮助 Jekyll 跟踪哪些文件从上次建立站点开始到现在没有被修改，哪些文件需要在下一次站点建立时重新生成。该文件不会被包含在生成的站点中。)└── index.html (网站的index) Jekyll的主题既然自己的blog搭建好了，当然要更好看一些。你可以自己写HTML5+CSS来定制自己的Jekyll主题，也可以在求助万能的网站，来寻找各种主题。 使用 Github Pages 的服务1、创建我们的仓库把username替换成自己的名字 2、设置我们的仓库3、部署我们的blog我们先把刚刚新建的仓库git clone到本地，然后cd 到仓库的目录下，执行jekyll serve -B 123//克隆下来到本地的git文件夹cd username.github.comjekyll serve -B 注意，启动前确保其他目录下没有jekyll服务，可以 ps aux|grep jekyll 查看进程,有的话,用kill -9 进程号 杀掉其他进程。现在我们打开http://localhost:4000,即可看见我们在Github上创建的主页，理论上和https://username.com/username.github.io/ 访问的应该是一模一样的。接着我们把我们自己做好的blog目录整个都拷贝到这个仓库文件夹中(如果是自己下载的主题：直接将下载的主题文件拷贝替换掉原blog文件下的所有文件，启动一下服务，即可。)，当然，这个仓库之前的文件可以删除了，只留下README即可。把整个文件都push到github上去 123git add --all #添加到暂存区 git commit -m &quot;提交jekyll默认页面&quot; #提交到本地仓库git push origin master #线上的站点是部署在master下面的 注意，在提交前，请确保_config.yml文件里面下面是这样配置的，因为这个是Github Pages的规定，如果选择了其他的模式，会立即收到编译警告的邮件提醒的。 12highlighter: rougemarkdown: kramdown 申请个人域名我的个人域名是在万网申请的。申请好了之后就是和自己的blog绑定（上面链接文章写的比较清楚）：1、我们要绑定的话需要在username.github.com目录下增加一个CNAME文件。 在里面添加你的域名，假设为example.com，然后推送CNAME文件到远程仓库: 12git add CNAMEgit push origin master 在这里遇到比较大的一个坑，当时想了半天CNAME是什么格式的文件，在网上找了半天，也没找到答案。最后才发现自己想错了，直接在终端进入从git上克隆下来的文件夹，然后在终端输入指令vim CNAME输入自己的域名，保存退出，提交就行了。2、到域名服务商增加你的CNAME记录。 添加两条记录，@和www的主机记录，记录类型为CNAME类型，CNAME表示别名记录，该记录可以将多个名字映射到同一台计算机。 记录值请写username.github.io.,值得注意的是io后面还有一个圆点，切记。添加@和www的记录的时候出现了冲突，我直接把冲突给删除了。上文链接文章中也有相关介绍。 申请”小绿锁”HTTPS在这一块我也遇见很多坑，最后看了这篇文章，然后直接在Cloudflare上申请了https。具体的可按照上面操作。 写文章有两个规定先记下： 文章必须新建在./_posts文件夹中 文章名称必须是yyyy-mm-dd-xxxxx-xxx-xxx格式，后缀名可以是.markdown | .html | .textile （不过我还是推荐markdown形式，因为易学、通用、效率高） 总结在最后，再次感谢上面几篇文章的作者，以后我的blog主题的作者，正是有了你们的付出，才让技术没有界限。通过这次的实验，以及动手的操作，才发现未知并不可怕，只要你开动自己的脚步，总能窥探一二。希望以后的日子里，不仅仅忙碌，还能怀揣着酒和故事，带着诗意，去远方。","categories":[{"name":"搭建 blog","slug":"搭建-blog","permalink":"http://yoursite.com/categories/搭建-blog/"}],"tags":[{"name":"jekyll","slug":"jekyll","permalink":"http://yoursite.com/tags/jekyll/"}]}]}