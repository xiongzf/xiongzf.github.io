<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>kafka | KNOWLEDGE IS POWER</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="kafka" />
  
  
  
  
  <meta name="description" content="官网 Kafka is a distributed, partitioned, replicated commit logservice。它提供了类似于 JMS 的特性，但是在实现上完全不同，此外它并不是 JMS 规范的实现。kafka 对消息保存时根据 Topic 进行归类，发送消息者成为 Producer,消息接受者成为 Consumer,此外 kafka 集群有多个 kafka 实例组成，每">
<meta name="keywords" content="kafka">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka">
<meta property="og:url" content="http://yoursite.com/kafka/index.html">
<meta property="og:site_name" content="KNOWLEDGE IS POWER">
<meta property="og:description" content="官网 Kafka is a distributed, partitioned, replicated commit logservice。它提供了类似于 JMS 的特性，但是在实现上完全不同，此外它并不是 JMS 规范的实现。kafka 对消息保存时根据 Topic 进行归类，发送消息者成为 Producer,消息接受者成为 Consumer,此外 kafka 集群有多个 kafka 实例组成，每">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/kafka/1.png">
<meta property="og:image" content="http://yoursite.com/kafka/2.png">
<meta property="og:image" content="http://yoursite.com/kafka/3.png">
<meta property="og:image" content="http://yoursite.com/kafka/4.png">
<meta property="og:image" content="http://yoursite.com/kafka/5.png">
<meta property="og:image" content="http://yoursite.com/kafka/6.png">
<meta property="og:image" content="http://yoursite.com/kafka/7.png">
<meta property="og:updated_time" content="2019-07-30T07:27:21.631Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kafka">
<meta name="twitter:description" content="官网 Kafka is a distributed, partitioned, replicated commit logservice。它提供了类似于 JMS 的特性，但是在实现上完全不同，此外它并不是 JMS 规范的实现。kafka 对消息保存时根据 Topic 进行归类，发送消息者成为 Producer,消息接受者成为 Consumer,此外 kafka 集群有多个 kafka 实例组成，每">
<meta name="twitter:image" content="http://yoursite.com/kafka/1.png">
  
    <link rel="alternate" href="/atom.xml" title="KNOWLEDGE IS POWER" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/css/header-post.css" >
  

  
  
  
    <link rel="stylesheet" href="/css/vdonate.css" >
  

</head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">首页</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">归档</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">分类</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">标签</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">关于</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="请输入关键词..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(无标题)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-kafka" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      kafka
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/kafka/" class="article-date">
	  <time datetime="2019-05-10T03:58:42.000Z" itemprop="datePublished">2019-05-10</time>
	</a>

      
    <a class="article-category-link" href="/categories/java/">java</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		阅读量<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/kafka/1.png" alt=""><br><a href="http://kafka.apache.org/" target="_blank" rel="noopener">官网</a></p>
<p>Kafka is a distributed, partitioned, replicated commit logservice。它提供了类似于 JMS 的特性，但是在实现上完全不同，此外它并不是 JMS 规范的实现。kafka 对消息保存时根据 Topic 进行归类，发送消息者成为 Producer,消息接受者成为 Consumer,此外 kafka 集群有多个 kafka 实例组成，每个实例()成为 broker。无论是 kafka 集群，还是 producer 和 consumer 都依赖于 zookeeper 来保证系统可用性集群保存一些 meta 信息。</p>
<h1 id="Topics-logs"><a href="#Topics-logs" class="headerlink" title="Topics/logs"></a>Topics/logs</h1><p>一个 Topic 可以认为是一类消息，每个 topic 将被分成多个 partition(区),每个 partition 在存储层面是 append log 文件。任何发布到此 partition 的消息都会被直接追加到 log 文件的尾部，每条消息在文件中的位置称为 offset（偏移量），offset 为一个long 型数字，它是唯一标记一条消息。它唯一的标记一条消息。kafka 并没有提供其他额外的索引机制来存储 offset，因为在 kafka 中几乎不允许对消息进行“随机读写”。</p>
<p><img src="/kafka/2.png" alt=""></p>
<p>kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.日志文件将会根据broker中的配置要求,保留一定的时间之后删除;比如log文件保留2天,那么两天后,文件会被清除,无论其中的消息是否被消费.kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支.</p>
<p>对于 consumer 而言,它需要保存消费消息的 offset,对于 offset 的保存和使用,有 consumer 来控制;当consumer正常消费消息时, offset 将会”线性”的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将 offset 重置为任意值..(offset将会保存在zookeeper中,参见下文)</p>
<p>kafka 集群几乎不需要维护任何 consumer 和 producer 状态信息,这些信息有 zookeeper 保存;因此 producer 和 consumer 的实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响.</p>
<p>partitions 的目的有多个.最根本原因是 kafka 基于文件存储.通过分区,可以将日志内容分散到多个上,来避免文件尺寸达到单机磁盘的上限,每个 partiton 都会被当前 server(kafka实例)保存;可以将一个 topic 切分多任意多个 partitions,来消息保存/消费的效率.此外越多的 partitions 意味着可以容纳更多的 consumer,有效提升并发消费的能力.</p>
<h1 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h1><p>一个 Topic 的多个 partitions,被分布在 kafka 集群中的多个 server 上;每个 server (kafka 实例)负责 partitions 中消息的读写操作;此外 kafka 还可以配置 partitions 需要备份的个数(replicas),每个 partition 将会被备份到多台机器上,以提高可用性.</p>
<p>基于 replicated 方案,那么就意味着需要对多个备份进行调度;每个 partition 都有一个为 “leader” ; leader 负责所有的读写操作,如果 leader 失效,那么将会有其他 follower 来接管(成为新的leader);follower 只是单调的和 leader 跟进,同步消息即可.由此可见作为 leader 的 server 承载了全部的请求压力,因此从集群的整体考虑,有多少个 partitions 就意味着有多少个 “leader” , kafka 会将 “leader” 均衡的分散在每个实例上,来确保整体的性能稳定.</p>
<p><strong>Producers</strong><br>Producer 将消息发布到指定的 Topic 中,同时 Producer 也能决定将此消息归属于哪个 partition ;比如基于 “round-robin” 方式或者通过其他的一些算法等.</p>
<p><strong>Consumers</strong><br>本质上 kafka 只支持 Topic.每个 consumer 属于一个 consumer group;反过来说,每个 group 中可以有多个 consumer.发送到 Topic 的消息,只会被订阅此 Topic 的每个 group 中的一个 consumer 消费.</p>
<p>如果所有的 consumer 都具有相同的 group,这种情况和 queue 模式很像;消息将会在 consumers 之间负载均衡.</p>
<p>如果所有的 consumer 都具有不同的 group,那这就是”发布-订阅”;消息将会广播给所有的消费者.</p>
<p>在 kafka 中,一个 partition 中的消息只会被 group 中的一个 consumer 消费;每个 group 中 consumer 消息消费互相独立;我们可以认为一个 group 是一个”订阅”者,一个 Topic 中的每个 partions,只会被一个”订阅者”中的一个 consumer 消费,不过一个 consumer 可以消费多个 partitions 中的消息. kafka 只能保证一个 partition 中的消息被某个 consumer 消费时,消息是顺序的.事实上,从 Topic 角度来说,消息仍不是有序的.</p>
<p>kafka 的原理决定,对于一个 topic,同一个 group 中不能有多于 partitions 个数的 consumer 同时消费,否则将意味着某些 consumer 将无法得到消息.</p>
<p><strong>Guarantees</strong></p>
<pre><code>1) 发送到 partitions 中的消息将会按照它接收的顺序追加到日志中
2) 对于消费者而言,它们消费消息的顺序和日志中消息顺序一致.
3) 如果 Topic 的 &quot;replicationfactor&quot; 为 N,那么允许 N-1 个 kafka 实例失效.
</code></pre><h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><p>1、Messaging   </p>
<pre><code>对于一些常规的消息系统,kafka 是个不错的选择;partitons/replication 和容错,可以使 kafka 具有良好的扩展性和性能优势.

不过到目前为止,我们应该很清楚认识到,kafka 并没有提供 JMS 中的&quot;事务性&quot;&quot;消息传输担保(消息确认机制)&quot;&quot;消息分组&quot;等企业级特性;

kafka 只能使用作为&quot;常规&quot;的消息系统,在一定程度上,尚未确保消息的发送与接收绝对可靠(比如,消息重发,消息发送丢失等)
</code></pre><p> 2、Websit activity tracking</p>
<pre><code>kafka 可以作为&quot;网站活性跟踪&quot;的最佳工具;可以将网页/用户操作等信息发送到kafka中.并实时监控,或者离线统计分析等
</code></pre><p>3、Log Aggregation</p>
<pre><code>kafka 的特性决定它非常适合作为&quot;日志收集中心&quot;;application 可以将操作日志&quot;批量&quot;&quot;异步&quot;的发送到 kafka 集群中,而不是保存在本地或者 DB 中;

kafka 可以批量提交消息/压缩消息等,这对 producer 端而言,几乎感觉不到性能的开支.此时 consumer 端可以使 hadoop 等其他系统化的存储和分析系统.
</code></pre><h1 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h1><p>kafka 的初衷是希望作为一个统一的信息收集平台,能够实时的收集反馈信息,并需要能够支撑较大的数据量,且具备良好的容错能力.</p>
<h2 id="1、持久性"><a href="#1、持久性" class="headerlink" title="1、持久性"></a>1、持久性</h2><p>kafka 使用文件存储消息,这就直接决定 kafka 在性能上严重依赖文件系统的本身特性.且无论任何 OS 下,对文件系统本身的优化几乎没有可能.文件缓存/直接内存映射等是常用的手段.</p>
<p>因为 kafka 是对日志文件进行 append 操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker 会将消息暂时 buffer 起来,当消息的个数(或尺寸)达到一定阀值时,再 flush 到磁盘,这样减少了磁盘 IO 调用的次数.</p>
<h2 id="2、性能"><a href="#2、性能" class="headerlink" title="2、性能"></a>2、性能</h2><p>需要考虑的影响性能点很多,除磁盘 IO 之外,我们还需要考虑网络 IO,这直接关系到 kafka 的吞吐量问题.kafka 并没有提供太多高超的技巧;</p>
<p>对于 producer 端,可以将消息 buffer 起来,当消息的条数达到一定阀值时,批量发送给 broker;</p>
<p>对于 consumer 端也是一样,批量 fetch 多条消息.不过消息量的大小可以通过配置文件来指定.</p>
<p>对于 kafka broker 端,似乎有个 sendfile 系统调用可以潜在的提升网络 IO 的性能:将文件的数据映射到系统内存中,socket 直接读取相应的内存区域即可,而无需进程再次copy 和交换. </p>
<p>其实对于 producer/consumer/broker 三者而言,CPU 的开支应该都不大,因此启用消息压缩机制是一个良好的策略;压缩需要消耗少量的 CPU 资源,不过对于 kafka 而言,网络 IO 更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.kafka 支持 gzip/snappy 等多种压缩方式.</p>
<h2 id="3、生产者"><a href="#3、生产者" class="headerlink" title="3、生产者"></a>3、生产者</h2><p>负载均衡: producer 将会和 Topic 下所有 partition leader 保持 socket 连接;消息由 producer 直接通过 socket 发送到 broker,中间不会经过任何”路由层”.事实上,消息被路由到哪个 partition 上,有 producer 决定.比如可以采用 “random” “key-hash” “轮询”等,如果一个 topic 中有多个partitions,那么在 producer 端实现”消息均衡分发”是必要的.</p>
<p>其中 partition leader 的位置(host:port)注册在 zookeeper 中,producer 作为 zookeeper client,已经注册了 watch 用来监听 partition leader 的变更事件.</p>
<p>异步发送：将多条消息暂且在客户端 buffer 起来，并将他们批量的发送到 broker，小数据 IO 太多，会拖慢整体的网络延迟，批量延迟发送事实上提升了网络效率。不过这也有一定的隐患，比如说当 producer 失效时，那些尚未发送的消息将会丢失。</p>
<h2 id="4、消费者"><a href="#4、消费者" class="headerlink" title="4、消费者"></a>4、消费者</h2><p>consumer 端向 broker 发送 “fetch” 请求,并告知其获取消息的 offset;此后 consumer 将会获得一定条数的消息;consumer 端也可以重置 offset 来重新消费消息.</p>
<p>在 JMS 实现中,Topic 模型基于 push 方式,即 broker 将消息推送给 consumer 端.不过在 kafka 中,采用了 pull 方式,即 consumer 在和 broker 建立连接之后,主动去pull(或者说fetch) 消息;这中模式有些优点,首先 consumer 端可以根据自己的消费能力适时的去 fetch 消息并处理,且可以控制消息消费的进度(offset);此外,消费者可以良好的控制消息消费的数量,batch fetch.</p>
<p>其他 JMS 实现,消息消费的位置是有 prodiver 保留,以便避免重复发送消息或者将没有消费成功的消息重发等,同时还要控制消息的状态.这就要求 JMS broker 需要太多额外的工作.在kafka 中,partition 中的消息只有一个 consumer 在消费,且不存在消息状态的控制,也没有复杂的消息确认机制,可见 kafka broker 端是相当轻量级的.当消息被 consumer 接收之后,consumer 可以在本地保存最后消息的 offset,并间歇性的向 zookeeper 注册 offset.由此可见,consumer 也很轻量级.</p>
<h2 id="5、消息传送机制"><a href="#5、消息传送机制" class="headerlink" title="5、消息传送机制"></a>5、消息传送机制</h2><p>对于 JMS 实现,消息传输担保非常直接:有且只有一次(exactly once).在 kafka 中稍有不同:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1) at most once: 最多一次,这个和 JMS 中&quot;非持久化&quot;消息类似.发送一次,无论成败,将不会重发.</span><br><span class="line">2) at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.</span><br><span class="line">3) exactly once: 消息只会发送一次.</span><br><span class="line"></span><br><span class="line">at most once: 消费者 fetch 消息,然后保存 offset,然后处理消息;当 client 保存 offset 之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后&quot;未处理&quot;的消息将不能被 fetch 到,这就是&quot;at most once&quot;.</span><br><span class="line"></span><br><span class="line">at least once: 消费者 fetch 消息,然后处理消息,然后保存 offset.如果消息处理成功之后,但是在保存 offset 阶段 zookeeper 异常导致保存操作未能执行成功,这就导致接下来再次 fetch 时可能获得上次已经处理过的消息,这就是 &quot;at least once&quot;，原因 offset 没有及时的提交给 zookeeper，zookeeper 恢复正常还是之前 offset 状态.</span><br><span class="line"></span><br><span class="line">exactly once: kafka 中并没有严格的去实现(基于2阶段提交,事务),我们认为这种策略在kafka 中是没有必要的.</span><br><span class="line">通常情况下 &quot;at-least-once&quot; 是我们首选.(相比 at most once 而言,重复接收数据总比丢失数据要好).</span><br></pre></td></tr></table></figure>
<h2 id="6、复制备份"><a href="#6、复制备份" class="headerlink" title="6、复制备份"></a>6、复制备份</h2><p>kafka 将每个 partition 数据复制到多个 server上,任何一个 partition 有一个 leader 和多个 follower(可以没有);备份的个数可以通过 broker 配置文件来设定. leader 处理所有的 read-write 请求, follower 需要和 leader 保持同步. Follower 和 consumer 一样,消费消息并保存在本地日志中; leader 负责跟踪所有的 follower 状态,如果 follower “落后”太多或者失效, leader 将会把它从 replicas 同步列表中删除.当所有的 follower 都将一条消息保存成功,此消息才被认为是 “committed”,那么此时 consumer 才能消费它.即使只有一个 replicas 实例存活,仍然可以保证消息的正常发送和接收,只要 zookeeper 集群存活即可.(不同于其他分布式存储,比如 hbase 需要”多数派”存活才行)</p>
<p>当 leader 失效时,需在 followers 中选取出新的 leader,可能此时 follower 落后于 leader,因此需要选择一个 “up-to-date” 的 follower.选择 follower 时需要兼顾一个问题,就是新 leader 上所已经承载的 partition leader 的个数,如果一个 server 上有过多的 partition leader,意味着此 server 将承受着更多的 IO 压力.在选举新 leader, 需要考虑到”负载均衡”.</p>
<h2 id="7-日志"><a href="#7-日志" class="headerlink" title="7.日志"></a>7.日志</h2><p>如果一个 topic 的名称为 “my_topic”,它有 2 个 partitions, 那么日志将会保存在 my_topic_0 和 my_topic_1 两个目录中;日志文件中保存了一序列 “log entries” (日志条目), 每个 log entry 格式为 “4个字节的数字N表示消息的长度” + “N个字节的消息内容”; 每个日志都有一个 offset 来唯一的标记一条消息, offset 的值为 8 个字节的数字,表示此消息在此 partition 中所处的起始位置. 每个 partition 在物理存储层面,有多个 log file 组成(称为segment). segmentfile 的命名为 “最小offset”.kafka. 例如 “00000000000.kafka”; 其中 “最小offset” 表示此 segment 中起始消息的 offset.<br><img src="/kafka/3.png" alt=""></p>
<p> 其中每个 partiton 中所持有的 segments 列表信息会存储在 zookeeper 中.</p>
<p>当 segment 文件尺寸达到一定阀值时(可以通过配置文件设定,默认1G),将会创建一个新的文件; 当 buffer 中消息的条数达到阀值时将会触发日志信息 flush 到日志文件中, 同时如果 “距离最近一次 flush 的时间差” 达到阀值时, 也会触发 flush 到日志文件. 如果 broker 失效, 极有可能会丢失那些尚未 flush 到文件的消息. 因为意外实现, 仍然会导致 log 文件格式的破坏(文件尾部), 那么就要求当 server 启动是需要检测最后一个 segment 的文件结构是否合法并进行必要的修复.</p>
<p>获取消息时,需要指定 offset 和最大 chunk 尺寸, offset 用来表示消息的起始位置, chunk size 用来表示最大获取消息的总长度(间接的表示消息的条数). 根据 offset, 可以找到此消息所在 segment 文件, 然后根据 segment 的最小 offset 取差值, 得到它在 file 中的相对位置, 直接读取输出即可.</p>
<p>日志文件的删除策略非常简单: 启动一个后台线程定期扫描 log file 列表, 把保存时间超过阀值的文件直接删除(根据文件的创建时间). 为了避免删除文件时仍然有 read 操作(consumer消费), 采取 copy-on-write 方式.</p>
<h2 id="8、分配"><a href="#8、分配" class="headerlink" title="8、分配"></a>8、分配</h2><p>kafka 使用 zookeeper 来存储一些 meta 信息, 并使用了 zookeeper watch 机制来发现 meta 信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等)</p>
<p>1) Broker node registry: 当一个 kafkabroker 启动后, 首先会向 zookeeper 注册自己的节点信息(临时 znode), 同时当 broker 和 zookeeper 断开连接时, 此 znode 也会被删除.</p>
<p>格式: /broker/ids/[0…N]   –&gt;host:port; 其中 [0..N] 表示 broker id, 每个 broker 的配置文件中都需要指定一个数字类型的 id(全局不可重复), znode 的值为此 broker 的 host:port 信息.</p>
<p>2) Broker Topic Registry: 当一个 broker 启动时,会向 zookeeper 注册自己持有的 topic 和 partitions 信息, 仍然是一个临时 znode.</p>
<p>格式: /broker/topics/[topic]/[0…N]  其中 [0..N] 表示 partition 索引号.</p>
<p>3) Consumer and Consumer group: 每个 consumer 被创建时, 会向 zookeeper 注册自己的信息; 此作用主要是为了”负载均衡”.</p>
<p>一个 group 中的多个consumer可以交错的消费一个 topic 的所有partitions; 简而言之, 保证此 topic 的所有 partitions 都能被此 group 所消费, 且消费时为了性能考虑, 让 partition 相对均衡的分散到每个 consumer 上.</p>
<p>4) Consumer id Registry: 每个 consumer 都有一个唯一的 ID(host:uuid, 可以通过配置文件指定, 也可以由系统生成), 此 id 用来标记消费者信息.</p>
<p>格式:/consumers/[group_id]/ids/[consumer_id] 仍然是一个临时的 znode, 此节点的值为 {“topic_name”:#streams…}, 即表示此 consumer 目前所消费的 topic + partitions 列表.</p>
<p>5) Consumer offset Tracking: 用来跟踪每个 consumer 目前所消费的 partition 中最大的 offset.</p>
<p>格式:/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]–&gt;offset_value 此 znode 为持久节点, 可以看出 offset 跟 group_id 有关, 以表明当 group 中一个消费者失效, 其他 consumer 可以继续消费.<br>    6) Partition Owner registry: 用来标记 partition 被哪个 consumer 消费.临时 znode</p>
<p>格式:/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]–&gt;consumer_node_id当consumer启动时,所触发的操作:</p>
<pre><code>A) 首先进行 &quot;Consumer id Registry&quot;;
B) 然后在 &quot;Consumer id Registry&quot; 节点下注册一个 watch 用来监听当前 group 中其他 consumer 的 &quot;leave&quot; 和 &quot;join&quot;; 只要此 znode path 下节点列表变更, 都会触发此 group 下 consumer 的负载均衡. (比如一个 consumer 失效,那么其他 consumer 接管 partitions).
C) 在 &quot;Broker id registry&quot; 节点下, 注册一个 watch 用来监听 broker 的存活情况; 如果 broker 列表变更, 将会触发所有的 groups 下的 consumer 重新 balance.
</code></pre><p><img src="/kafka/4.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1) Producer 端使用 zookeeper 用来&quot;发现&quot; broker 列表,以及和 Topic 下每个 partition leader 建立 socket 连接并发送消息.</span><br><span class="line"></span><br><span class="line">2) Broker 端使用 zookeeper 用来注册 broker 信息, 已经监测 partitionleader 存活性.</span><br><span class="line"></span><br><span class="line">3) Consumer 端使用 zookeeper 用来注册 consumer 信息,其中包括 consumer 消费的 partition 列表等, 同时也用来发现 broker 列表, 并和 partition leader 建立 socket 连接, 并获取消息.</span><br></pre></td></tr></table></figure>
<h1 id="主要配置"><a href="#主要配置" class="headerlink" title="主要配置"></a>主要配置</h1><h2 id="1、Broker-配置"><a href="#1、Broker-配置" class="headerlink" title="1、Broker 配置"></a>1、Broker 配置</h2><p><img src="/kafka/5.png" alt=""></p>
<h2 id="2、Consumer-主要配置"><a href="#2、Consumer-主要配置" class="headerlink" title="2、Consumer 主要配置"></a>2、Consumer 主要配置</h2><p><img src="/kafka/6.png" alt=""></p>
<h2 id="3、Producer-主要配置"><a href="#3、Producer-主要配置" class="headerlink" title="3、Producer 主要配置"></a>3、Producer 主要配置</h2><p><img src="/kafka/7.png" alt=""></p>
<p>以上是关于 kafka 一些基础说明，在其中我们知道如果要 kafka 正常运行，必须配置zookeeper，否则无论是 kafka 集群还是的生存者和消费者都无法正常的工作的，以下是对zookeeper 进行一些简单的介绍：</p>
<h1 id="zookeeper集群"><a href="#zookeeper集群" class="headerlink" title="zookeeper集群"></a>zookeeper集群</h1><p>zookeeper 是一个为分布式应用提供一致性服务的软件，它是开源的 Hadoop 项目的一个子项目，并根据 google 发表的一篇论文来实现的。zookeeper 为分布式系统提供了高效且易于使用的协同服务，它可以为分布式应用提供相当多的服务，诸如统一命名服务，配置管理，状态同步和组服务等。zookeeper 接口简单，我们不必过多地纠结在分布式系统难于处理的同步和一致性问题上，你可以使用 zookeeper 提供的现成 (off-the-shelf) 服务来实现来实现分布式系统额配置管理，组管理，Leader 选举等功能。</p>
<h2 id="zookeeper-集群的安装"><a href="#zookeeper-集群的安装" class="headerlink" title="zookeeper 集群的安装"></a>zookeeper 集群的安装</h2><p>准备三台服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server1:192.168.0.1, server2:192.168.0.2, server3:192.168.0.3.</span><br></pre></td></tr></table></figure>
<h3 id="1-下载zookeeper"><a href="#1-下载zookeeper" class="headerlink" title="1)下载zookeeper"></a>1)下载zookeeper</h3><p> 到 <a href="http://zookeeper.apache.org/releases.html" target="_blank" rel="noopener">http://zookeeper.apache.org/releases.html</a> 去下载最新版本Zookeeper-3.4.5 的安装包 zookeeper-3.4.5.tar.gz. 将文件保存 server1 的~目录下</p>
<h3 id="2-安装zookeeper"><a href="#2-安装zookeeper" class="headerlink" title="2)安装zookeeper"></a>2)安装zookeeper</h3><p>先在服务器分别执行a-c步骤</p>
<p>a)解压  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.5.tar.gz</span><br></pre></td></tr></table></figure>
<p>解压完成后在目录~下会发现多出一个目录 zookeeper-3.4.5, 重新命令为 zookeeper</p>
<p>b）配置</p>
<p>将 <code>conf/zoo_sample.cfg</code> 拷贝一份命名为 zoo.cfg，也放在 conf 目录下。然后按照如下值修改其中的配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit=10</span><br><span class="line"># The number of ticks that can pass between</span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit=5</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line"># do not use /tmp for storage, /tmp here is just</span><br><span class="line"># example sakes.</span><br><span class="line">dataDir=/home/wwb/zookeeper /data</span><br><span class="line">dataLogDir=/home/wwb/zookeeper/logs</span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort=2181</span><br><span class="line">#</span><br><span class="line"># Be sure to read the maintenance section of the</span><br><span class="line"># administrator guide before turning on autopurge.</span><br><span class="line">#http://zookeeper.apache.org/doc/ ... html#sc_maintenance</span><br><span class="line">#</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">#autopurge.snapRetainCount=3</span><br><span class="line"># Purge task interval in hours</span><br><span class="line"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">#autopurge.purgeInterval=1</span><br><span class="line">server.1=192.168.0.1:3888:4888</span><br><span class="line">server.2=192.168.0.2:3888:4888</span><br><span class="line">server.3=192.168.0.3:3888:4888</span><br></pre></td></tr></table></figure>
<ul>
<li><p>tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。</p>
</li>
<li><p>dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。</p>
</li>
<li><p>clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。</p>
</li>
<li><p>initLimit：这个配置项是用来配置 Zookeeper 接受（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5 个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒</p>
</li>
<li><p>syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 2*2000=4 秒</p>
</li>
</ul>
<p>server.A = B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号</p>
<blockquote>
<p>注意:dataDir, dataLogDir 中的 wwb 是当前登录用户名，data，logs 目录开始是不存在，需要使用 mkdir 命令创建相应的目录。并且在该目录下创建文件 myid, serve1, server2, server3 该文件内容分别为 1, 2, 3。<br>针对服务器 server2### 针对服务器 server2, server3 可以将 server1 复制到相应的目录，不过需要注意dataDir, dataLogDir 目录, 并且文件 myid 内容分别为 2, 3。</p>
</blockquote>
<h3 id="3-依次启动server1，server2-server3-的-zookeeper"><a href="#3-依次启动server1，server2-server3-的-zookeeper" class="headerlink" title="3)依次启动server1，server2, server3 的 zookeeper."></a>3)依次启动server1，server2, server3 的 zookeeper.</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/home/wwb/zookeeper/bin/zkServer.sh start,出现类似以下内容</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /home/wwb/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure>
<h3 id="4-测试-zookeeper-是否正常工作"><a href="#4-测试-zookeeper-是否正常工作" class="headerlink" title="4)测试 zookeeper 是否正常工作"></a>4)测试 zookeeper 是否正常工作</h3><p>在 server1 上执行以下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">1、/home/wwb/zookeeper/bin/zkCli.sh -server192.168.0.2:2181   </span><br><span class="line"></span><br><span class="line">//出现类似以下内容</span><br><span class="line"></span><br><span class="line">JLine support is enabled</span><br><span class="line"></span><br><span class="line">2013-11-27 19:59:40,560 - INFO      [main-SendThread(localhost.localdomain:2181):ClientCnxn$SendThread@736]- Session   establishmentcomplete on  localhost.localdomain/127.0.0.1:2181, sessionid =    0x1429cdb49220000, negotiatedtimeout = 30000</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:None path:null</span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 0] [root@localhostzookeeper2]</span><br><span class="line">//  即代表集群构建成功了,如果出现错误那应该是第三部时没有启动好集群</span><br><span class="line"></span><br><span class="line">//先利用</span><br><span class="line">2、ps aux | grep zookeeper</span><br><span class="line"></span><br><span class="line">// 查看是否有相应的进程的，没有话，说明集群启动出现问题，可以在每个服务器上使用</span><br><span class="line"></span><br><span class="line">3、./home/wwb/zookeeper/bin/zkServer.sh stop</span><br><span class="line"></span><br><span class="line">//再依次使用</span><br><span class="line"></span><br><span class="line">4、./home/wwb/zookeeper/binzkServer.sh start</span><br><span class="line"></span><br><span class="line">//这时在执行 4 一般是没有问题，如果还是有问题，那么先 stop 再到 bin 的上级目录执行</span><br><span class="line"></span><br><span class="line">5、./bin/zkServer.shstart</span><br><span class="line"></span><br><span class="line">试试。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：zookeeper 集群时，zookeeper 要求半数以上的机器可用，zookeeper 才能提供服务。</p>
</blockquote>
<h1 id="kafka集群"><a href="#kafka集群" class="headerlink" title="kafka集群"></a>kafka集群</h1><p>(利用上面server1, server2, server3, 下面以 server1 为实例)</p>
<p>1)下载 kafka0.8(<a href="http://kafka.apache.org/downloads.html)" target="_blank" rel="noopener">http://kafka.apache.org/downloads.html)</a>, 保存到服务器 /home/wwb 目录下 kafka-0.8.0-beta1-src.tgz (kafka_2.8.0-0.8.0-beta1.tgz)</p>
<p>2)解压  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka-0.8.0-beta1-src.tgz</span><br></pre></td></tr></table></figure>
<p>产生文件夹 kafka-0.8.0-beta1-src 更改为 kafka01   </p>
<p>3)配置<br> 修改 kafka01/config/.properties, 其中 broker.id, log.dirs, zookeeper.connect 必须根据实际情况进行修改，其他项根据需要自行斟酌。<br>大致如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">broker.id=1  </span><br><span class="line">port=9091  </span><br><span class="line">num.network.threads=2  </span><br><span class="line">num.io.threads=2  </span><br><span class="line">socket.send.buffer.bytes=1048576  </span><br><span class="line">socket.receive.buffer.bytes=1048576  </span><br><span class="line">socket.request.max.bytes=104857600  </span><br><span class="line">log.dir=./logs  </span><br><span class="line">num.partitions=2  </span><br><span class="line">log.flush.interval.messages=10000  </span><br><span class="line">log.flush.interval.ms=1000  </span><br><span class="line">log.retention.hours=168  </span><br><span class="line">#log.retention.bytes=1073741824  </span><br><span class="line">log.segment.bytes=536870912  </span><br><span class="line">num.replica.fetchers=2  </span><br><span class="line">log.cleanup.interval.mins=10  </span><br><span class="line">zookeeper.connect=192.168.0.1:2181,192.168.0.2:2182,192.168.0.3:2183  </span><br><span class="line">zookeeper.connection.timeout.ms=1000000  </span><br><span class="line">kafka.metrics.polling.interval.secs=5  </span><br><span class="line">kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter  </span><br><span class="line">kafka.csv.metrics.dir=/tmp/kafka_metrics  </span><br><span class="line">kafka.csv.metrics.reporter.enabled=false</span><br></pre></td></tr></table></figure>
<p>4）初始化因为 kafka 用 scala 语言编写，因此运行 kafka 需要首先准备 scala 相关环境。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; cd kafka01  </span><br><span class="line">&gt; ./sbt update  </span><br><span class="line">&gt; ./sbt package  </span><br><span class="line">&gt; ./sbt assembly-package-dependency</span><br></pre></td></tr></table></figure>
<p>在第二个命令时可能需要一定时间，由于要下载更新一些依赖包。所以请大家 耐心点。</p>
<p>5) 启动 kafka01</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;JMX_PORT=9997 bin/kafka--start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
<p>a) kafka02 操作步骤与 kafka01 雷同，不同的地方如下<br>    修改 kafka02/config/server.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">broker.id=2</span><br><span class="line">port=9092</span><br><span class="line">##其他配置和kafka-0保持一致</span><br></pre></td></tr></table></figure>
<p>启动kafka02</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">JMX_PORT=9998 bin/kafka-server-start.shconfig/server.properties &amp;  </span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">b) kafka03 操作步骤与 kafka01 雷同，不同的地方如下</span><br><span class="line">   修改 kafka03/config/server.properties</span><br></pre></td></tr></table></figure>
<p>broker.id=3<br>port=9093</p>
<p>##其他配置和kafka-0保持一致<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">启动 kafka03</span><br></pre></td></tr></table></figure></p>
<p>JMX_PORT=9999 bin/kafka–start.shconfig/serverconfig/server.properties &amp;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">6)创建 topic(包含一个分区，三个副本)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>bin/kafka-create-topic.sh–zookeeper 192.168.0.1:2181 –replica 3 –partition 1 –topicmy-replicated-topic<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">7)查看 topic 情况</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>bin/kafka-list-top.sh –zookeeper 192.168.0.1:2181<br>topic: my-replicated-topic  partition: 0 leader: 1  replicas: 1,2,0  isr: 1,2,0<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">8)创建发送者</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>bin/kafka-console-producer.sh–broker-list 192.168.0.1:9091 –topic my-replicated-topic<br>my test message1<br>my test message2<br>ctrl c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">9)创建消费者</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>bin/kafka-console-consumer.sh –zookeeper127.0.0.1:2181 –from-beginning –topic my-replicated-topic<br>…<br>my test message1<br>my test message2<br>ctrl c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">10) 杀掉 server1 上的 broker</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>pkill -9 -f config/.properties<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">11)查看 topic</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>bin/kafka-list-top.sh –zookeeper192.168.0.1:2181<br> topic: my-replicated-topic  partition: 0 leader: 1  replicas: 1,2,0<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">发现 topic 还正常的存在</span><br><span class="line"></span><br><span class="line">12）创建消费者，看是否能查询到消息</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>bin/kafka-console-consumer.sh –zookeeper192.168.0.1:2181 –from-beginning –topic my-replicated-topic<br>…<br>my test message 1<br>my test message 2<br>ctrl c<br><code>`</code></p>
</blockquote>
<p>说明一切都是正常的。</p>
<pre><code>补充说明：
1、public Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt;     
createMessageStreams(Map&lt;String, Integer&gt; topicCountMap)，其中该方法的参数Map 的 key 为 topic 名称，value 为 topic 对应的分区数，
譬如说如果在 kafka 中不存在相应的 topic 时，则会创建一个 topic，分区数为 value，如果存在的话，该处的 value 则不起什么作用

2、关于生产者向指定的分区发送数据，通过设置 partitioner.class 的属性来指定向那个分区发送数据，
如果自己指定必须编写相应的程序，默认是 kafka.producer.DefaultPartitioner,分区程序是基于散列的键。

3、在多个消费者读取同一个 topic 的数据，为了保证每个消费者读取数据的唯一性，
必须将这些消费者 group_id 定义为同一个值，这样就构建了一个类似队列的数据结构，如果定义不同，则类似一种广播结构的。

4、在 consumerapi 中，参数到数字部分，类似Map&lt;String,Integer&gt;, numStream, 指的都是在 topic 不存在的时，会创建一个topic，并且分区个数为Integer, numStream, 
注意如果数字大于 broker 的配置中 num.partitions 属性，会以 num.partitions 为依据创建分区个数的。

5、producerapi，调用 send 时，如果不存在 topic，也会创建 topic，在该方法中没有提供分区个数的参数，在这里分区个数是由服务端 broker 的配置中 num.partitions 属性决定的。
</code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://kafka.apache.org/" target="_blank" rel="noopener">http://kafka.apache.org/</a><br><a href="https://www.jianshu.com/p/4bf007885116" target="_blank" rel="noopener">https://www.jianshu.com/p/4bf007885116</a><br><a href="https://www.cnblogs.com/likehua/p/3999538.html" target="_blank" rel="noopener">https://www.cnblogs.com/likehua/p/3999538.html</a></p>

      
    </div>
    <footer class="article-footer">
      
        <div id="donation_div"></div>

<script src="/js/vdonate.js"></script>
<script>
var a = new Donate({
  title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: '打赏支持', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: 'https://raw.githubusercontent.com/xiongzf/img/master/WechatIMG7.jpeg',
  alipayImage: 'https://raw.githubusercontent.com/xiongzf/img/master/WechatIMG9.jpeg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>本文作者:  </strong>菜鸟先生</a>
          </li>
          <li class="post-copyright-link">
          <strong>本文链接:  </strong>
          <a href="/kafka/" target="_blank" title="kafka">http://yoursite.com/kafka/</a>
          </li>
          <li class="post-copyright-license">
            <strong>版权声明:   </strong>
            本博客所有文章除特别声明外，均采用 <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            许可协议。转载请注明出处
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8zOTY2MC8xNjE4Nw==">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/Dubbo-Admin-新版/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          Dubbo Admin 新版
        
      </div>
    </a>
  
  
    <a href="/Redis/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">Redis</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Topics-logs"><span class="nav-number">1.</span> <span class="nav-text">Topics/logs</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Distribution"><span class="nav-number">2.</span> <span class="nav-text">Distribution</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#使用场景"><span class="nav-number">3.</span> <span class="nav-text">使用场景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#设计原理"><span class="nav-number">4.</span> <span class="nav-text">设计原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、持久性"><span class="nav-number">4.1.</span> <span class="nav-text">1、持久性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、性能"><span class="nav-number">4.2.</span> <span class="nav-text">2、性能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、生产者"><span class="nav-number">4.3.</span> <span class="nav-text">3、生产者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4、消费者"><span class="nav-number">4.4.</span> <span class="nav-text">4、消费者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5、消息传送机制"><span class="nav-number">4.5.</span> <span class="nav-text">5、消息传送机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6、复制备份"><span class="nav-number">4.6.</span> <span class="nav-text">6、复制备份</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-日志"><span class="nav-number">4.7.</span> <span class="nav-text">7.日志</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8、分配"><span class="nav-number">4.8.</span> <span class="nav-text">8、分配</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#主要配置"><span class="nav-number">5.</span> <span class="nav-text">主要配置</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、Broker-配置"><span class="nav-number">5.1.</span> <span class="nav-text">1、Broker 配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、Consumer-主要配置"><span class="nav-number">5.2.</span> <span class="nav-text">2、Consumer 主要配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、Producer-主要配置"><span class="nav-number">5.3.</span> <span class="nav-text">3、Producer 主要配置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#zookeeper集群"><span class="nav-number">6.</span> <span class="nav-text">zookeeper集群</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#zookeeper-集群的安装"><span class="nav-number">6.1.</span> <span class="nav-text">zookeeper 集群的安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-下载zookeeper"><span class="nav-number">6.1.1.</span> <span class="nav-text">1)下载zookeeper</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-安装zookeeper"><span class="nav-number">6.1.2.</span> <span class="nav-text">2)安装zookeeper</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-依次启动server1，server2-server3-的-zookeeper"><span class="nav-number">6.1.3.</span> <span class="nav-text">3)依次启动server1，server2, server3 的 zookeeper.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-测试-zookeeper-是否正常工作"><span class="nav-number">6.1.4.</span> <span class="nav-text">4)测试 zookeeper 是否正常工作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kafka集群"><span class="nav-number">7.</span> <span class="nav-text">kafka集群</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考"><span class="nav-number">8.</span> <span class="nav-text">参考</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2013 - 2019 KNOWLEDGE IS POWER All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				访客数 : <span id="busuanzi_value_site_uv"></span> |  
				访问量 : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>




  <script src="/js/dialog.js"></script>








	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            KNOWLEDGE IS POWER
          </div>
          <div class="panel-body">
            Copyright © 2019 菜鸟先生 All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>